{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1xgudDA0sYtYThNtbp-NZP7_pb__GLPY1","timestamp":1671778493052},{"file_id":"https://github.com/RafsanJany-44/ARC/blob/master/Activity_Recognition_EEG_2022_12_21_(edited).ipynb","timestamp":1671776858250}],"collapsed_sections":["C0Akgb_na7NU","jEe2R0yAoifa","FJybpt_UvCU0","AgMT_U8gvM7F","jRG4cBnKvZU2","K6_icFWdauSI","_Btki9jRvc1Y","6FEsxCdvkg2D","znXNx2bgUvtd","zxxWSX26jsGT","23z3A3f1ol6d","57cQ8dzJX0Lp","Wvhy6ENJf_oS","26iwXg2a75qo","bwOJ36hchWiN","XtgWbvJsEwMt","7rL4KXKM-KRC"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#Starting"],"metadata":{"id":"Habm7FE7rhgS"}},{"cell_type":"code","execution_count":2,"metadata":{"id":"zdFOS9nFlpsU","colab":{"base_uri":"https://localhost:8080/"},"outputId":"276fd55d-f323-4884-c7bf-6af1b33a7583","executionInfo":{"status":"ok","timestamp":1671779023892,"user_tz":-360,"elapsed":32607,"user":{"displayName":"Rafsan Jany","userId":"08721334090885411304"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.8/dist-packages (0.8.1)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from imbalanced-learn) (1.2.0)\n","Requirement already satisfied: scikit-learn>=0.24 in /usr/local/lib/python3.8/dist-packages (from imbalanced-learn) (1.0.2)\n","Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.8/dist-packages (from imbalanced-learn) (1.7.3)\n","Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.8/dist-packages (from imbalanced-learn) (1.21.6)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.24->imbalanced-learn) (3.1.0)\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","\n","def models_check_box(models):\n","  import ipywidgets as widgets\n","  from IPython.display import display\n","  new_keys=[]\n","  for i in models:\n","    i=widgets.Checkbox(\n","      value=False,\n","      description=str(i),\n","      disabled=False,\n","      indent=False\n","      )\n","    display(i)\n","    new_keys.append(i)\n","  return new_keys\n","\n","\n","!pip install imbalanced-learn\n","\n","from imblearn.over_sampling import SMOTE\n","\n","def balance(X_temp, y_temp):\n","  smote = SMOTE()\n","  X_temp, y_temp= smote.fit_resample(X_temp, y_temp)\n","  return pd.concat([pd.DataFrame(X_temp), pd.DataFrame(y_temp)], axis=1)"]},{"cell_type":"code","source":[],"metadata":{"id":"C6TIqVlzwH_z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","#dataset=pd.read_csv(\"/content/drive/MyDrive/EEG_CNU_Activity Recognition/EEG_CNU_Resting, walking, working and Reading_Control_2022.12.05.csv\")\n"," \n","dataset=pd.read_excel(\"/content/drive/MyDrive/Iqram Sir/EEG_CNU_Resting, walking, working and Reading_Control_2022.12.22.xlsx\")\n","\n","classes = np.array(sorted(list(set(dataset.iloc[:, 1]))))\n","target = \"Activity\"\n","result = {}"],"metadata":{"id":"M0AmIUwSmLfj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":317},"id":"4YN_C8yxm1ho","outputId":"e0b9554d-452c-46bc-ba23-15aa6d0c7322","executionInfo":{"status":"ok","timestamp":1671777126368,"user_tz":-360,"elapsed":62,"user":{"displayName":"Rafsan Jany","userId":"08721334090885411304"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["  Activity   Status  Epoch  MeanP_Alpha_Fz  MedianF_Alpha_Fz  MeanF_Alpha_Fz  \\\n","0  Resting  Control      0        0.000008          11.70732        28.29268   \n","1  Resting  Control      1        0.000010          10.73171        28.78049   \n","2  Resting  Control      2        0.000008          13.17073        28.78049   \n","3  Resting  Control      3        0.000011          10.24390        27.80488   \n","4  Resting  Control      4        0.000007          10.73171        23.41463   \n","\n","   Spectral Edge_Alpha_Fz  PeakF_Alpha_Fz  MeanP_Beta_Fz  MedianF_Beta_Fz  \\\n","0                20.00000        10.73171       0.000017         19.51220   \n","1                22.43902        10.24390       0.000023         22.92683   \n","2                23.41463         9.26829       0.000023         22.43902   \n","3                18.53659        10.73171       0.000019         22.43902   \n","4                18.04878        11.70732       0.000010         17.56098   \n","\n","   ...  Relative Power_Alpha_Global  Relative Power_Beta_Global  \\\n","0  ...                     0.358154                    0.639771   \n","1  ...                     0.457695                    0.806208   \n","2  ...                     0.501419                    1.059244   \n","3  ...                     0.497909                    0.710690   \n","4  ...                     0.429825                    0.569204   \n","\n","   Relative Power_Theta_Global  Relative Power_Delta_Global  \\\n","0                     0.749628                     4.031903   \n","1                     0.723662                     3.759249   \n","2                     0.737332                     3.320235   \n","3                     0.907816                     3.653423   \n","4                     0.849345                     4.001597   \n","\n","   Relative Power_Gamma_Global  ∆Relative Power_Alpha_Global  \\\n","0                     0.220545                     -0.273666   \n","1                     0.253186                     -0.071797   \n","2                     0.381769                      0.016875   \n","3                     0.230162                      0.009757   \n","4                     0.150029                     -0.128318   \n","\n","   ∆Relative Power_Beta_Global  ∆Relative Power_Theta_Global  \\\n","0                    -0.164639                     -0.009611   \n","1                     0.052680                     -0.043916   \n","2                     0.383074                     -0.025855   \n","3                    -0.072039                      0.199384   \n","4                    -0.256780                      0.122134   \n","\n","   ∆Relative Power_Delta_Global  ∆Relative Power_Gamma_Global  \n","0                      0.107193                     -0.356230  \n","1                      0.032320                     -0.260950  \n","2                     -0.088237                      0.114385  \n","3                      0.003259                     -0.328157  \n","4                      0.098870                     -0.562065  \n","\n","[5 rows x 259 columns]"],"text/html":["\n","  <div id=\"df-4c920732-178b-4343-82d6-f4d8a97385e6\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Activity</th>\n","      <th>Status</th>\n","      <th>Epoch</th>\n","      <th>MeanP_Alpha_Fz</th>\n","      <th>MedianF_Alpha_Fz</th>\n","      <th>MeanF_Alpha_Fz</th>\n","      <th>Spectral Edge_Alpha_Fz</th>\n","      <th>PeakF_Alpha_Fz</th>\n","      <th>MeanP_Beta_Fz</th>\n","      <th>MedianF_Beta_Fz</th>\n","      <th>...</th>\n","      <th>Relative Power_Alpha_Global</th>\n","      <th>Relative Power_Beta_Global</th>\n","      <th>Relative Power_Theta_Global</th>\n","      <th>Relative Power_Delta_Global</th>\n","      <th>Relative Power_Gamma_Global</th>\n","      <th>∆Relative Power_Alpha_Global</th>\n","      <th>∆Relative Power_Beta_Global</th>\n","      <th>∆Relative Power_Theta_Global</th>\n","      <th>∆Relative Power_Delta_Global</th>\n","      <th>∆Relative Power_Gamma_Global</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Resting</td>\n","      <td>Control</td>\n","      <td>0</td>\n","      <td>0.000008</td>\n","      <td>11.70732</td>\n","      <td>28.29268</td>\n","      <td>20.00000</td>\n","      <td>10.73171</td>\n","      <td>0.000017</td>\n","      <td>19.51220</td>\n","      <td>...</td>\n","      <td>0.358154</td>\n","      <td>0.639771</td>\n","      <td>0.749628</td>\n","      <td>4.031903</td>\n","      <td>0.220545</td>\n","      <td>-0.273666</td>\n","      <td>-0.164639</td>\n","      <td>-0.009611</td>\n","      <td>0.107193</td>\n","      <td>-0.356230</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Resting</td>\n","      <td>Control</td>\n","      <td>1</td>\n","      <td>0.000010</td>\n","      <td>10.73171</td>\n","      <td>28.78049</td>\n","      <td>22.43902</td>\n","      <td>10.24390</td>\n","      <td>0.000023</td>\n","      <td>22.92683</td>\n","      <td>...</td>\n","      <td>0.457695</td>\n","      <td>0.806208</td>\n","      <td>0.723662</td>\n","      <td>3.759249</td>\n","      <td>0.253186</td>\n","      <td>-0.071797</td>\n","      <td>0.052680</td>\n","      <td>-0.043916</td>\n","      <td>0.032320</td>\n","      <td>-0.260950</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Resting</td>\n","      <td>Control</td>\n","      <td>2</td>\n","      <td>0.000008</td>\n","      <td>13.17073</td>\n","      <td>28.78049</td>\n","      <td>23.41463</td>\n","      <td>9.26829</td>\n","      <td>0.000023</td>\n","      <td>22.43902</td>\n","      <td>...</td>\n","      <td>0.501419</td>\n","      <td>1.059244</td>\n","      <td>0.737332</td>\n","      <td>3.320235</td>\n","      <td>0.381769</td>\n","      <td>0.016875</td>\n","      <td>0.383074</td>\n","      <td>-0.025855</td>\n","      <td>-0.088237</td>\n","      <td>0.114385</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Resting</td>\n","      <td>Control</td>\n","      <td>3</td>\n","      <td>0.000011</td>\n","      <td>10.24390</td>\n","      <td>27.80488</td>\n","      <td>18.53659</td>\n","      <td>10.73171</td>\n","      <td>0.000019</td>\n","      <td>22.43902</td>\n","      <td>...</td>\n","      <td>0.497909</td>\n","      <td>0.710690</td>\n","      <td>0.907816</td>\n","      <td>3.653423</td>\n","      <td>0.230162</td>\n","      <td>0.009757</td>\n","      <td>-0.072039</td>\n","      <td>0.199384</td>\n","      <td>0.003259</td>\n","      <td>-0.328157</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Resting</td>\n","      <td>Control</td>\n","      <td>4</td>\n","      <td>0.000007</td>\n","      <td>10.73171</td>\n","      <td>23.41463</td>\n","      <td>18.04878</td>\n","      <td>11.70732</td>\n","      <td>0.000010</td>\n","      <td>17.56098</td>\n","      <td>...</td>\n","      <td>0.429825</td>\n","      <td>0.569204</td>\n","      <td>0.849345</td>\n","      <td>4.001597</td>\n","      <td>0.150029</td>\n","      <td>-0.128318</td>\n","      <td>-0.256780</td>\n","      <td>0.122134</td>\n","      <td>0.098870</td>\n","      <td>-0.562065</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 259 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4c920732-178b-4343-82d6-f4d8a97385e6')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-4c920732-178b-4343-82d6-f4d8a97385e6 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-4c920732-178b-4343-82d6-f4d8a97385e6');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["dataset.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h8Wm0DGf4AJO","outputId":"9748eb2a-8ae7-45af-e78c-9538e0a1ca36","executionInfo":{"status":"ok","timestamp":1671777126369,"user_tz":-360,"elapsed":58,"user":{"displayName":"Rafsan Jany","userId":"08721334090885411304"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1711, 259)"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["dataset[target].value_counts()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AGAp91QUwrWo","executionInfo":{"status":"ok","timestamp":1671777126370,"user_tz":-360,"elapsed":57,"user":{"displayName":"Rafsan Jany","userId":"08721334090885411304"}},"outputId":"2f200e06-4a54-461c-db9b-2793a5dfeb42"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Reading    793\n","Walking    408\n","Working    267\n","Resting    243\n","Name: Activity, dtype: int64"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["set(list(dataset[target]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VS4iUbnyYaDH","outputId":"1ad09485-7ab5-40b5-c118-088479fe251c","executionInfo":{"status":"ok","timestamp":1671777126371,"user_tz":-360,"elapsed":54,"user":{"displayName":"Rafsan Jany","userId":"08721334090885411304"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'Reading', 'Resting', 'Walking', 'Working'}"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["\n","from sklearn.preprocessing import LabelEncoder\n","encoder=LabelEncoder()\n","dataset[target]=encoder.fit_transform(dataset[target])"],"metadata":{"id":"Ljyj9yuIf-tX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["set(list(dataset['Activity']))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"42si00q3SLh5","outputId":"b000eaea-f9a3-45b3-c028-db01f0f7a594","executionInfo":{"status":"ok","timestamp":1671777126374,"user_tz":-360,"elapsed":53,"user":{"displayName":"Rafsan Jany","userId":"08721334090885411304"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{0, 1, 2, 3}"]},"metadata":{},"execution_count":11}]},{"cell_type":"markdown","source":["###Spliting into X and y"],"metadata":{"id":"ZAUQcyHz4wlO"}},{"cell_type":"code","source":["X =  dataset.loc[:,dataset.columns != target]  # removing Activity \n","X =  X.loc[:,X.columns != \"Status\"]            # removing Status\n","X =  X.loc[:,X.columns != \"Epoch\"]             # removing Epoch\n","y = dataset[\"Activity\"]\n","\n","X.head(10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":473},"id":"eBxa1iqT3Ocs","outputId":"7021a50c-448d-459b-d9b9-54b1c4e60c63","executionInfo":{"status":"ok","timestamp":1671777126376,"user_tz":-360,"elapsed":51,"user":{"displayName":"Rafsan Jany","userId":"08721334090885411304"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   MeanP_Alpha_Fz  MedianF_Alpha_Fz  MeanF_Alpha_Fz  Spectral Edge_Alpha_Fz  \\\n","0        0.000008          11.70732        28.29268                20.00000   \n","1        0.000010          10.73171        28.78049                22.43902   \n","2        0.000008          13.17073        28.78049                23.41463   \n","3        0.000011          10.24390        27.80488                18.53659   \n","4        0.000007          10.73171        23.41463                18.04878   \n","5        0.000008          10.24390        23.41463                17.56098   \n","6        0.000005          11.21951        24.39024                17.56098   \n","7        0.000005           9.75610        25.85366                18.53659   \n","8        0.000006          10.24390        24.39024                17.56098   \n","9        0.000014          11.21951        23.41463                18.04878   \n","\n","   PeakF_Alpha_Fz  MeanP_Beta_Fz  MedianF_Beta_Fz  MeanF_Beta_Fz  \\\n","0        10.73171       0.000017         19.51220       38.04878   \n","1        10.24390       0.000023         22.92683       38.53659   \n","2         9.26829       0.000023         22.43902       37.56098   \n","3        10.73171       0.000019         22.43902       38.04878   \n","4        11.70732       0.000010         17.56098       36.09756   \n","5        10.24390       0.000010         18.04878       36.09756   \n","6        12.68293       0.000007         17.07317       38.04878   \n","7         7.80488       0.000007         19.02439       35.60976   \n","8         8.29268       0.000009         17.56098       36.09756   \n","9        12.68293       0.000021         18.04878       35.60976   \n","\n","   Spectral Edge_Beta_Fz  PeakF_Beta_Fz  ...  Relative Power_Alpha_Global  \\\n","0               32.68293       19.02439  ...                     0.358154   \n","1               33.65854       23.41463  ...                     0.457695   \n","2               31.70732       17.56098  ...                     0.501419   \n","3               32.68293       28.29268  ...                     0.497909   \n","4               29.26829       11.70732  ...                     0.429825   \n","5               29.26829       17.07317  ...                     0.494096   \n","6               31.21951       14.14634  ...                     0.527217   \n","7               29.75610       13.17073  ...                     0.475599   \n","8               29.26829       17.56098  ...                     0.482293   \n","9               29.26829       12.68293  ...                     0.659929   \n","\n","   Relative Power_Beta_Global  Relative Power_Theta_Global  \\\n","0                    0.639771                     0.749628   \n","1                    0.806208                     0.723662   \n","2                    1.059244                     0.737332   \n","3                    0.710690                     0.907816   \n","4                    0.569204                     0.849345   \n","5                    0.687221                     0.812251   \n","6                    0.668711                     0.770164   \n","7                    0.719244                     0.764508   \n","8                    0.620810                     0.933737   \n","9                    0.855344                     1.188749   \n","\n","   Relative Power_Delta_Global  Relative Power_Gamma_Global  \\\n","0                     4.031903                     0.220545   \n","1                     3.759249                     0.253186   \n","2                     3.320235                     0.381769   \n","3                     3.653423                     0.230162   \n","4                     4.001597                     0.150029   \n","5                     3.785048                     0.221383   \n","6                     3.853441                     0.180467   \n","7                     3.833454                     0.207195   \n","8                     3.798965                     0.164195   \n","9                     3.079654                     0.216324   \n","\n","   ∆Relative Power_Alpha_Global  ∆Relative Power_Beta_Global  \\\n","0                     -0.273666                    -0.164639   \n","1                     -0.071797                     0.052680   \n","2                      0.016875                     0.383074   \n","3                      0.009757                    -0.072039   \n","4                     -0.128318                    -0.256780   \n","5                      0.002023                    -0.102682   \n","6                      0.069192                    -0.126852   \n","7                     -0.035489                    -0.060870   \n","8                     -0.021913                    -0.189396   \n","9                      0.338331                     0.116839   \n","\n","   ∆Relative Power_Theta_Global  ∆Relative Power_Delta_Global  \\\n","0                     -0.009611                      0.107193   \n","1                     -0.043916                      0.032320   \n","2                     -0.025855                     -0.088237   \n","3                      0.199384                      0.003259   \n","4                      0.122134                      0.098870   \n","5                      0.073126                      0.039404   \n","6                      0.017521                      0.058186   \n","7                      0.010050                      0.052697   \n","8                      0.233631                      0.043226   \n","9                      0.570546                     -0.154303   \n","\n","   ∆Relative Power_Gamma_Global  \n","0                     -0.356230  \n","1                     -0.260950  \n","2                      0.114385  \n","3                     -0.328157  \n","4                     -0.562065  \n","5                     -0.353782  \n","6                     -0.473217  \n","7                     -0.395197  \n","8                     -0.520716  \n","9                     -0.368549  \n","\n","[10 rows x 256 columns]"],"text/html":["\n","  <div id=\"df-f6ed7b3e-2970-455e-a1ad-5b536e3a48c7\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>MeanP_Alpha_Fz</th>\n","      <th>MedianF_Alpha_Fz</th>\n","      <th>MeanF_Alpha_Fz</th>\n","      <th>Spectral Edge_Alpha_Fz</th>\n","      <th>PeakF_Alpha_Fz</th>\n","      <th>MeanP_Beta_Fz</th>\n","      <th>MedianF_Beta_Fz</th>\n","      <th>MeanF_Beta_Fz</th>\n","      <th>Spectral Edge_Beta_Fz</th>\n","      <th>PeakF_Beta_Fz</th>\n","      <th>...</th>\n","      <th>Relative Power_Alpha_Global</th>\n","      <th>Relative Power_Beta_Global</th>\n","      <th>Relative Power_Theta_Global</th>\n","      <th>Relative Power_Delta_Global</th>\n","      <th>Relative Power_Gamma_Global</th>\n","      <th>∆Relative Power_Alpha_Global</th>\n","      <th>∆Relative Power_Beta_Global</th>\n","      <th>∆Relative Power_Theta_Global</th>\n","      <th>∆Relative Power_Delta_Global</th>\n","      <th>∆Relative Power_Gamma_Global</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.000008</td>\n","      <td>11.70732</td>\n","      <td>28.29268</td>\n","      <td>20.00000</td>\n","      <td>10.73171</td>\n","      <td>0.000017</td>\n","      <td>19.51220</td>\n","      <td>38.04878</td>\n","      <td>32.68293</td>\n","      <td>19.02439</td>\n","      <td>...</td>\n","      <td>0.358154</td>\n","      <td>0.639771</td>\n","      <td>0.749628</td>\n","      <td>4.031903</td>\n","      <td>0.220545</td>\n","      <td>-0.273666</td>\n","      <td>-0.164639</td>\n","      <td>-0.009611</td>\n","      <td>0.107193</td>\n","      <td>-0.356230</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.000010</td>\n","      <td>10.73171</td>\n","      <td>28.78049</td>\n","      <td>22.43902</td>\n","      <td>10.24390</td>\n","      <td>0.000023</td>\n","      <td>22.92683</td>\n","      <td>38.53659</td>\n","      <td>33.65854</td>\n","      <td>23.41463</td>\n","      <td>...</td>\n","      <td>0.457695</td>\n","      <td>0.806208</td>\n","      <td>0.723662</td>\n","      <td>3.759249</td>\n","      <td>0.253186</td>\n","      <td>-0.071797</td>\n","      <td>0.052680</td>\n","      <td>-0.043916</td>\n","      <td>0.032320</td>\n","      <td>-0.260950</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.000008</td>\n","      <td>13.17073</td>\n","      <td>28.78049</td>\n","      <td>23.41463</td>\n","      <td>9.26829</td>\n","      <td>0.000023</td>\n","      <td>22.43902</td>\n","      <td>37.56098</td>\n","      <td>31.70732</td>\n","      <td>17.56098</td>\n","      <td>...</td>\n","      <td>0.501419</td>\n","      <td>1.059244</td>\n","      <td>0.737332</td>\n","      <td>3.320235</td>\n","      <td>0.381769</td>\n","      <td>0.016875</td>\n","      <td>0.383074</td>\n","      <td>-0.025855</td>\n","      <td>-0.088237</td>\n","      <td>0.114385</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.000011</td>\n","      <td>10.24390</td>\n","      <td>27.80488</td>\n","      <td>18.53659</td>\n","      <td>10.73171</td>\n","      <td>0.000019</td>\n","      <td>22.43902</td>\n","      <td>38.04878</td>\n","      <td>32.68293</td>\n","      <td>28.29268</td>\n","      <td>...</td>\n","      <td>0.497909</td>\n","      <td>0.710690</td>\n","      <td>0.907816</td>\n","      <td>3.653423</td>\n","      <td>0.230162</td>\n","      <td>0.009757</td>\n","      <td>-0.072039</td>\n","      <td>0.199384</td>\n","      <td>0.003259</td>\n","      <td>-0.328157</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.000007</td>\n","      <td>10.73171</td>\n","      <td>23.41463</td>\n","      <td>18.04878</td>\n","      <td>11.70732</td>\n","      <td>0.000010</td>\n","      <td>17.56098</td>\n","      <td>36.09756</td>\n","      <td>29.26829</td>\n","      <td>11.70732</td>\n","      <td>...</td>\n","      <td>0.429825</td>\n","      <td>0.569204</td>\n","      <td>0.849345</td>\n","      <td>4.001597</td>\n","      <td>0.150029</td>\n","      <td>-0.128318</td>\n","      <td>-0.256780</td>\n","      <td>0.122134</td>\n","      <td>0.098870</td>\n","      <td>-0.562065</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.000008</td>\n","      <td>10.24390</td>\n","      <td>23.41463</td>\n","      <td>17.56098</td>\n","      <td>10.24390</td>\n","      <td>0.000010</td>\n","      <td>18.04878</td>\n","      <td>36.09756</td>\n","      <td>29.26829</td>\n","      <td>17.07317</td>\n","      <td>...</td>\n","      <td>0.494096</td>\n","      <td>0.687221</td>\n","      <td>0.812251</td>\n","      <td>3.785048</td>\n","      <td>0.221383</td>\n","      <td>0.002023</td>\n","      <td>-0.102682</td>\n","      <td>0.073126</td>\n","      <td>0.039404</td>\n","      <td>-0.353782</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0.000005</td>\n","      <td>11.21951</td>\n","      <td>24.39024</td>\n","      <td>17.56098</td>\n","      <td>12.68293</td>\n","      <td>0.000007</td>\n","      <td>17.07317</td>\n","      <td>38.04878</td>\n","      <td>31.21951</td>\n","      <td>14.14634</td>\n","      <td>...</td>\n","      <td>0.527217</td>\n","      <td>0.668711</td>\n","      <td>0.770164</td>\n","      <td>3.853441</td>\n","      <td>0.180467</td>\n","      <td>0.069192</td>\n","      <td>-0.126852</td>\n","      <td>0.017521</td>\n","      <td>0.058186</td>\n","      <td>-0.473217</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0.000005</td>\n","      <td>9.75610</td>\n","      <td>25.85366</td>\n","      <td>18.53659</td>\n","      <td>7.80488</td>\n","      <td>0.000007</td>\n","      <td>19.02439</td>\n","      <td>35.60976</td>\n","      <td>29.75610</td>\n","      <td>13.17073</td>\n","      <td>...</td>\n","      <td>0.475599</td>\n","      <td>0.719244</td>\n","      <td>0.764508</td>\n","      <td>3.833454</td>\n","      <td>0.207195</td>\n","      <td>-0.035489</td>\n","      <td>-0.060870</td>\n","      <td>0.010050</td>\n","      <td>0.052697</td>\n","      <td>-0.395197</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>0.000006</td>\n","      <td>10.24390</td>\n","      <td>24.39024</td>\n","      <td>17.56098</td>\n","      <td>8.29268</td>\n","      <td>0.000009</td>\n","      <td>17.56098</td>\n","      <td>36.09756</td>\n","      <td>29.26829</td>\n","      <td>17.56098</td>\n","      <td>...</td>\n","      <td>0.482293</td>\n","      <td>0.620810</td>\n","      <td>0.933737</td>\n","      <td>3.798965</td>\n","      <td>0.164195</td>\n","      <td>-0.021913</td>\n","      <td>-0.189396</td>\n","      <td>0.233631</td>\n","      <td>0.043226</td>\n","      <td>-0.520716</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0.000014</td>\n","      <td>11.21951</td>\n","      <td>23.41463</td>\n","      <td>18.04878</td>\n","      <td>12.68293</td>\n","      <td>0.000021</td>\n","      <td>18.04878</td>\n","      <td>35.60976</td>\n","      <td>29.26829</td>\n","      <td>12.68293</td>\n","      <td>...</td>\n","      <td>0.659929</td>\n","      <td>0.855344</td>\n","      <td>1.188749</td>\n","      <td>3.079654</td>\n","      <td>0.216324</td>\n","      <td>0.338331</td>\n","      <td>0.116839</td>\n","      <td>0.570546</td>\n","      <td>-0.154303</td>\n","      <td>-0.368549</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>10 rows × 256 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f6ed7b3e-2970-455e-a1ad-5b536e3a48c7')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-f6ed7b3e-2970-455e-a1ad-5b536e3a48c7 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-f6ed7b3e-2970-455e-a1ad-5b536e3a48c7');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","source":["###USing SMOTE for balancing"],"metadata":{"id":"xaboX-SqrcYc"}},{"cell_type":"code","source":["new_dataset =  balance(X,y)"],"metadata":{"id":"hHX2PZjeAPHj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Feature Selection"],"metadata":{"id":"C0Akgb_na7NU"}},{"cell_type":"code","source":["number_of_feat = 20"],"metadata":{"id":"rY2mWiZv80L2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Run only one Method"],"metadata":{"id":"hBJAeCQyG9K1"}},{"cell_type":"markdown","source":["###ANOVA with f classifciation"],"metadata":{"id":"cR3Hrghl7CVj"}},{"cell_type":"code","source":["from sklearn.datasets import make_classification\n","from sklearn.feature_selection import SelectKBest\n","from sklearn.feature_selection import f_classif\n","import pandas as pd\n","\n","\n","\n","fs = SelectKBest(score_func=f_classif, k=5)\n","fit = fs.fit(X,y)\n","dfscores = pd.DataFrame(fit.scores_)\n","dfcolumns = pd.DataFrame(X.columns)\n","\n","featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n","\n","featureScores.columns = ['Best_columns','Score_ANOVA'] \n","\n","lyst = featureScores.nlargest(number_of_feat,'Score_ANOVA')\n","\n","#lyst.to_csv('Filter_Method_ANOVA_with_f_classif.csv')\n","\n","list_of_feat = list(lyst[\"Best_columns\"])"],"metadata":{"id":"jWdiiglz2iV-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###Embedded Method"],"metadata":{"id":"ulApxK0w7JXX"}},{"cell_type":"code","source":["\n","from sklearn.linear_model import LassoCV\n","reg = LassoCV()\n","reg.fit(X, y)\n","print(\"Best alpha using built-in LassoCV: %f\" % reg.alpha_)\n","print(\"Best score using built-in LassoCV: %f\" %reg.score(X,y))\n","coef = pd.Series(reg.coef_, index = X.columns)\n","\n","print(\"Lasso picked \" + str(sum(coef != 0)) + \" variables and eliminated the other \" +  str(sum(coef == 0)) + \" variables\")\n","\n","imp_coef = coef.sort_values()\n","\n","list_of_feat=[]\n","\n","\n","for i in range(coef.shape[0]):\n","  if coef[i]!=0:\n","    list_of_feat.append(dataset.iloc[:0,i+3].name)\n","    \n","df = pd.DataFrame(list_of_feat, columns=['Best_Features'])\n","\n","#df.to_csv(\"Embedded_Method.csv\")\n","\n","list_of_feat = list(df[\"Best_Features\"])\n","if number_of_feat < len(list_of_feat):\n","  list_of_feat = list_of_feat[:number_of_feat]"],"metadata":{"id":"2A4W1e2v5sse","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1671777794596,"user_tz":-360,"elapsed":3638,"user":{"displayName":"Rafsan Jany","userId":"08721334090885411304"}},"outputId":"cc526f69-d250-4a62-cd82-17cba29781f3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.4267169530156707, tolerance: 0.21672448830409385\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.5367691825176735, tolerance: 0.21672448830409385\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.44178979448417977, tolerance: 0.21672448830409385\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.43952068898738617, tolerance: 0.21672448830409385\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.46433912886061535, tolerance: 0.21672448830409385\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.4989548064010023, tolerance: 0.21672448830409385\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.44551548182505485, tolerance: 0.21672448830409385\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.43447831353933, tolerance: 0.21672448830409385\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6854571622635603, tolerance: 0.19155865595325047\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.6359106571626398, tolerance: 0.19155865595325047\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.118580555415747, tolerance: 0.19155865595325047\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.035189381130181, tolerance: 0.19155865595325047\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.44324843964204774, tolerance: 0.19155865595325047\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.320660533885416, tolerance: 0.19155865595325047\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.3528893170340552, tolerance: 0.19155865595325047\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.0475886722929317, tolerance: 0.19155865595325047\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.2859467656206789, tolerance: 0.19155865595325047\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.6886040710332963, tolerance: 0.19155865595325047\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.998050559647595, tolerance: 0.19155865595325047\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5.679900168994209, tolerance: 0.19155865595325047\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5.219082027051854, tolerance: 0.19155865595325047\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.039537952752198, tolerance: 0.19155865595325047\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.9415427907708818, tolerance: 0.19155865595325047\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.002354145654067, tolerance: 0.19155865595325047\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.228428024035793, tolerance: 0.19155865595325047\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.396283604265136, tolerance: 0.19155865595325047\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.8910330314937482, tolerance: 0.19155865595325047\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7.61956106919331, tolerance: 0.19155865595325047\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10.399343404807269, tolerance: 0.19155865595325047\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 12.845211129611243, tolerance: 0.19155865595325047\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.6412599116704314, tolerance: 0.1750899926953981\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.635566985978016, tolerance: 0.1750899926953981\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.149978421512742, tolerance: 0.1750899926953981\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.0463717673933388, tolerance: 0.1750899926953981\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.1249466366007255, tolerance: 0.1750899926953981\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.9639174785226032, tolerance: 0.1750899926953981\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.128761565914374, tolerance: 0.1750899926953981\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.01357223245941, tolerance: 0.1750899926953981\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.9125629880059023, tolerance: 0.1750899926953981\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.772142571907807, tolerance: 0.1750899926953981\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.8057308298861017, tolerance: 0.1750899926953981\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.108965049155017, tolerance: 0.1750899926953981\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.145962788478869, tolerance: 0.1750899926953981\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.8089646126340995, tolerance: 0.1750899926953981\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.5272684802470167, tolerance: 0.1750899926953981\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.9709261281667523, tolerance: 0.1750899926953981\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.522232171109067, tolerance: 0.1750899926953981\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5.373936113512855, tolerance: 0.1750899926953981\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6.8200969666474975, tolerance: 0.1750899926953981\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.819100593515486, tolerance: 0.1750899926953981\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 9.778754823772601, tolerance: 0.1750899926953981\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 9.548775913541704, tolerance: 0.1750899926953981\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.86090235394704, tolerance: 0.1750899926953981\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.140180840642529, tolerance: 0.1750899926953981\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7.644550679078407, tolerance: 0.1750899926953981\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6.9563886319442645, tolerance: 0.1750899926953981\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.21672824403958657, tolerance: 0.1750899926953981\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6587483567900563, tolerance: 0.1750899926953981\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.8016907527025978, tolerance: 0.1750899926953981\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.2918859110511676, tolerance: 0.1750899926953981\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.200606245269455, tolerance: 0.1750899926953981\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.712090984429551, tolerance: 0.1750899926953981\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.7746353418871195, tolerance: 0.1750899926953981\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5.462780333756314, tolerance: 0.1750899926953981\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5.784012395572745, tolerance: 0.1750899926953981\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5.863789293087962, tolerance: 0.1750899926953981\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5.428385278902283, tolerance: 0.1750899926953981\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5.429899369219129, tolerance: 0.1750899926953981\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6.064596863876886, tolerance: 0.1750899926953981\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.503576429383656, tolerance: 0.1750899926953981\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.87546807781564, tolerance: 0.1750899926953981\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.6660131299462364, tolerance: 0.1750899926953981\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.336437450820199, tolerance: 0.1750899926953981\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.2145848850275343, tolerance: 0.1750899926953981\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.0666533712883393, tolerance: 0.1750899926953981\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.053293760534416, tolerance: 0.1750899926953981\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6.054618481903162, tolerance: 0.1750899926953981\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 9.114466884816352, tolerance: 0.1750899926953981\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10.448019029321017, tolerance: 0.1750899926953981\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.11474914630593958, tolerance: 0.10558027757487208\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.19374736821760052, tolerance: 0.10558027757487208\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.13494072588798645, tolerance: 0.10558027757487208\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.22719690201859066, tolerance: 0.10558027757487208\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.19429411930013885, tolerance: 0.10558027757487208\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.19050649603673264, tolerance: 0.10558027757487208\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.256380345892012, tolerance: 0.10558027757487208\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.2911623253594371, tolerance: 0.10558027757487208\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.2708546981477866, tolerance: 0.10558027757487208\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.2694254374995353, tolerance: 0.10558027757487208\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.263341127462013, tolerance: 0.10558027757487208\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.2507549959905191, tolerance: 0.10558027757487208\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.2520277898437371, tolerance: 0.10558027757487208\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.22548068700359636, tolerance: 0.10558027757487208\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.2049915101465558, tolerance: 0.10558027757487208\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.29015633449625966, tolerance: 0.10558027757487208\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.39755466511519444, tolerance: 0.10558027757487208\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.48631634941807533, tolerance: 0.10558027757487208\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.5372703612974874, tolerance: 0.10558027757487208\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.5303664386892706, tolerance: 0.10558027757487208\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.4852303203185784, tolerance: 0.10558027757487208\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.41299196977752217, tolerance: 0.10558027757487208\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.44504031788073917, tolerance: 0.10558027757487208\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6044164916149839, tolerance: 0.10558027757487208\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.5821489079249886, tolerance: 0.10558027757487208\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.640216462648823, tolerance: 0.10558027757487208\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.9526979151553405, tolerance: 0.10558027757487208\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.453510519992392, tolerance: 0.10558027757487208\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.9106893127578815, tolerance: 0.10558027757487208\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.238552191859867, tolerance: 0.10558027757487208\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.4962298619279863, tolerance: 0.10558027757487208\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.7734824898376473, tolerance: 0.10558027757487208\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.9457448973673763, tolerance: 0.10558027757487208\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.461659613569168, tolerance: 0.10558027757487208\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.394426658807788, tolerance: 0.10558027757487208\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.197293579875236, tolerance: 0.10558027757487208\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.7140861379944, tolerance: 0.10558027757487208\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.857260651044385, tolerance: 0.10558027757487208\n","  model = cd_fast.enet_coordinate_descent_gram(\n","/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:633: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.71257207430142, tolerance: 0.10558027757487208\n","  model = cd_fast.enet_coordinate_descent_gram(\n"]},{"output_type":"stream","name":"stdout","text":["Best alpha using built-in LassoCV: 0.026444\n","Best score using built-in LassoCV: 0.462189\n","Lasso picked 76 variables and eliminated the other 180 variables\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.166e+02, tolerance: 2.256e-01\n","  model = cd_fast.enet_coordinate_descent(\n"]}]},{"cell_type":"markdown","source":["###Pearson's with f regression"],"metadata":{"id":"roe4MPHM7NJy"}},{"cell_type":"code","source":["from sklearn.datasets import make_regression\n","from sklearn.feature_selection import SelectKBest\n","from sklearn.feature_selection import f_regression\n","import pandas as pd\n","\n","\n","fs = SelectKBest(score_func=f_regression, k=5)\n","fit = fs.fit(X,y)\n","\n","dfscores = pd.DataFrame(fit.scores_)\n","dfcolumns = pd.DataFrame(dataset.columns)\n","featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n","\n","featureScores.columns = ['Best_columns','Score_pearsons'] \n","\n","\n","lyst = featureScores.nlargest(number_of_feat,'Score_pearsons')\n","\n","#lyst.to_csv('Filter_Method_Pearson’s_with_f_regression.csv')\n","\n","list_of_feat = list(lyst[\"Best_columns\"])"],"metadata":{"id":"o4A0dH566an_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###Sequential Feature Selection"],"metadata":{"id":"kwFK7VeE7RwH"}},{"cell_type":"code","source":["from sklearn.feature_selection import SequentialFeatureSelector\n","from sklearn.neighbors import KNeighborsClassifier\n","knn = KNeighborsClassifier(n_neighbors=3)\n","sfs = SequentialFeatureSelector(knn, n_features_to_select=number_of_feat)\n","sfs.fit(X, y)\n","list_of_feat=[]\n","list_of_feat=list(sfs.get_feature_names_out(X.columns))\n","\n","df = pd.DataFrame(list_of_feat, columns=['Best_Features'])\n","\n","#df.to_csv(\"Filter_Method_Sequential_feat_Selection_KNN.csv\")\n","\n","list_of_feat = list(df[\"Best_Features\"])\n","if number_of_feat < len(list_of_feat):\n","  list_of_feat = list_of_feat[:number_of_feat]"],"metadata":{"id":"sQlorvfS6wed"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###All features"],"metadata":{"id":"swd5ZOVO-8cL"}},{"cell_type":"code","source":["list_of_feat = list(X.columns)"],"metadata":{"id":"KoiMxNN3-_zH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Dataset Spliting"],"metadata":{"id":"k4YDHMuh-wMT"}},{"cell_type":"code","source":["X_new = new_dataset[list_of_feat]\n","y_new = new_dataset[target]"],"metadata":{"id":"MKgy4THrq4v8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_new.shape"],"metadata":{"id":"Fxz-DgDXZtpD","colab":{"base_uri":"https://localhost:8080/"},"outputId":"364cf286-e4e8-41f5-c590-db589ff3900b","executionInfo":{"status":"ok","timestamp":1671777858648,"user_tz":-360,"elapsed":11,"user":{"displayName":"Rafsan Jany","userId":"08721334090885411304"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(3172, 20)"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":["y_new.shape"],"metadata":{"id":"1q9Y_6BAr-es","colab":{"base_uri":"https://localhost:8080/"},"outputId":"74b251c8-e956-4760-83be-c0ff11ef0adb","executionInfo":{"status":"ok","timestamp":1671777858649,"user_tz":-360,"elapsed":11,"user":{"displayName":"Rafsan Jany","userId":"08721334090885411304"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(3172,)"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X_new, y_new, test_size = 0.2, random_state = 0)"],"metadata":{"id":"_CYZE4jgq3w9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","\n","---\n","\n"],"metadata":{"id":"bqYsoblRogp2"}},{"cell_type":"markdown","source":["\n","\n","---\n","\n"],"metadata":{"id":"BydV84Diooxp"}},{"cell_type":"markdown","source":["#ADABOOST"],"metadata":{"id":"jEe2R0yAoifa"}},{"cell_type":"code","source":["from sklearn.ensemble import AdaBoostClassifier\n","\n","ada_defult = AdaBoostClassifier(random_state=0)\n","ada_defult.fit(X_train, y_train)\n","y_pred = ada_defult.predict(X_test)\n","\n","from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n","print(confusion_matrix(y_test, y_pred))\n","print(classification_report(y_test,y_pred))\n","print(\"Accurecy: \",accuracy_score(y_test, y_pred))\n","result[(ada_defult,1,'AdaBoostClassifier')]=accuracy_score(y_test, y_pred)\n"],"metadata":{"id":"Bz_yVJaXod8O","colab":{"base_uri":"https://localhost:8080/"},"outputId":"01f51dd7-e9e0-430f-f5a6-539854bce581","executionInfo":{"status":"ok","timestamp":1671763963130,"user_tz":-360,"elapsed":2800,"user":{"displayName":"","userId":""}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[100  36  25   2]\n"," [ 44  91   4   6]\n"," [ 31  22  74  41]\n"," [  5   5  19 130]]\n","              precision    recall  f1-score   support\n","\n","           0       0.56      0.61      0.58       163\n","           1       0.59      0.63      0.61       145\n","           2       0.61      0.44      0.51       168\n","           3       0.73      0.82      0.77       159\n","\n","    accuracy                           0.62       635\n","   macro avg       0.62      0.62      0.62       635\n","weighted avg       0.62      0.62      0.62       635\n","\n","Accurecy:  0.6220472440944882\n"]}]},{"cell_type":"code","source":["from sklearn.ensemble import AdaBoostClassifier\n","N=90\n","k_range = range (1,N+1)\n","scores={}\n","scores_list = []\n","for k in k_range:\n","  classifier = AdaBoostClassifier(n_estimators=k,random_state=0)\n","  classifier.fit(X_train, y_train)\n","  y_pred=classifier.predict(X_test)\n","  scores[k] = accuracy_score(y_test,y_pred)\n","  scores_list.append(accuracy_score(y_test,y_pred))\n","  print(str(k)+\"/\"+str(N)+\" round completed......................... Accurecy: \"+str(accuracy_score(y_test,y_pred)))\n","\n","\n","\n","%matplotlib inline\n","import matplotlib.pyplot as plt\n","#plot the relationship between K and the testing accuracy\n","plt.figure(figsize = (25,10))\n","plt.plot(k_range,scores_list)\n","plt.xlabel('Value of n_estimators')\n","plt.ylabel ('Testing Accuracy')\n","\n","\n","\n","print(\"The best n_estimators:\")\n","best_estimator=list(scores.keys())[scores_list.index(max(scores_list))]\n","print(best_estimator)"],"metadata":{"id":"_3wRG3rxotzH","colab":{"base_uri":"https://localhost:8080/"},"outputId":"9f3ee36d-74d4-44f4-ab60-1abab7d8044f","executionInfo":{"status":"ok","timestamp":1671765391305,"user_tz":-360,"elapsed":1428182,"user":{"displayName":"","userId":""}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1/200 round completed......................... Accurecy: 0.4015748031496063\n","2/200 round completed......................... Accurecy: 0.48031496062992124\n","3/200 round completed......................... Accurecy: 0.49133858267716535\n","4/200 round completed......................... Accurecy: 0.5228346456692914\n","5/200 round completed......................... Accurecy: 0.5196850393700787\n","6/200 round completed......................... Accurecy: 0.5181102362204725\n","7/200 round completed......................... Accurecy: 0.5291338582677165\n","8/200 round completed......................... Accurecy: 0.5322834645669291\n","9/200 round completed......................... Accurecy: 0.5338582677165354\n","10/200 round completed......................... Accurecy: 0.5228346456692914\n","11/200 round completed......................... Accurecy: 0.5354330708661418\n","12/200 round completed......................... Accurecy: 0.5385826771653544\n","13/200 round completed......................... Accurecy: 0.5322834645669291\n","14/200 round completed......................... Accurecy: 0.552755905511811\n","15/200 round completed......................... Accurecy: 0.552755905511811\n","16/200 round completed......................... Accurecy: 0.5480314960629922\n","17/200 round completed......................... Accurecy: 0.5622047244094488\n","18/200 round completed......................... Accurecy: 0.5858267716535434\n","19/200 round completed......................... Accurecy: 0.5669291338582677\n","20/200 round completed......................... Accurecy: 0.5811023622047244\n","21/200 round completed......................... Accurecy: 0.5826771653543307\n","22/200 round completed......................... Accurecy: 0.5905511811023622\n","23/200 round completed......................... Accurecy: 0.5937007874015748\n","24/200 round completed......................... Accurecy: 0.5811023622047244\n","25/200 round completed......................... Accurecy: 0.5968503937007874\n","26/200 round completed......................... Accurecy: 0.5889763779527559\n","27/200 round completed......................... Accurecy: 0.5952755905511811\n","28/200 round completed......................... Accurecy: 0.5952755905511811\n","29/200 round completed......................... Accurecy: 0.5921259842519685\n","30/200 round completed......................... Accurecy: 0.5937007874015748\n","31/200 round completed......................... Accurecy: 0.5984251968503937\n","32/200 round completed......................... Accurecy: 0.5937007874015748\n","33/200 round completed......................... Accurecy: 0.5984251968503937\n","34/200 round completed......................... Accurecy: 0.6094488188976378\n","35/200 round completed......................... Accurecy: 0.6125984251968504\n","36/200 round completed......................... Accurecy: 0.6094488188976378\n","37/200 round completed......................... Accurecy: 0.6078740157480315\n","38/200 round completed......................... Accurecy: 0.6062992125984252\n","39/200 round completed......................... Accurecy: 0.6031496062992125\n","40/200 round completed......................... Accurecy: 0.6078740157480315\n","41/200 round completed......................... Accurecy: 0.6031496062992125\n","42/200 round completed......................... Accurecy: 0.6094488188976378\n","43/200 round completed......................... Accurecy: 0.6031496062992125\n","44/200 round completed......................... Accurecy: 0.6094488188976378\n","45/200 round completed......................... Accurecy: 0.6141732283464567\n","46/200 round completed......................... Accurecy: 0.6094488188976378\n","47/200 round completed......................... Accurecy: 0.6110236220472441\n","48/200 round completed......................... Accurecy: 0.6094488188976378\n","49/200 round completed......................... Accurecy: 0.6267716535433071\n","50/200 round completed......................... Accurecy: 0.6220472440944882\n","51/200 round completed......................... Accurecy: 0.6236220472440945\n","52/200 round completed......................... Accurecy: 0.6267716535433071\n","53/200 round completed......................... Accurecy: 0.6220472440944882\n","54/200 round completed......................... Accurecy: 0.6204724409448819\n","55/200 round completed......................... Accurecy: 0.6173228346456693\n","56/200 round completed......................... Accurecy: 0.6062992125984252\n","57/200 round completed......................... Accurecy: 0.6141732283464567\n","58/200 round completed......................... Accurecy: 0.6141732283464567\n","59/200 round completed......................... Accurecy: 0.6188976377952756\n","60/200 round completed......................... Accurecy: 0.6062992125984252\n","61/200 round completed......................... Accurecy: 0.6141732283464567\n","62/200 round completed......................... Accurecy: 0.6094488188976378\n","63/200 round completed......................... Accurecy: 0.6125984251968504\n","64/200 round completed......................... Accurecy: 0.6094488188976378\n","65/200 round completed......................... Accurecy: 0.6141732283464567\n","66/200 round completed......................... Accurecy: 0.6251968503937008\n","67/200 round completed......................... Accurecy: 0.6204724409448819\n","68/200 round completed......................... Accurecy: 0.6204724409448819\n","69/200 round completed......................... Accurecy: 0.6204724409448819\n","70/200 round completed......................... Accurecy: 0.6188976377952756\n","71/200 round completed......................... Accurecy: 0.6188976377952756\n","72/200 round completed......................... Accurecy: 0.6157480314960629\n","73/200 round completed......................... Accurecy: 0.6188976377952756\n","74/200 round completed......................... Accurecy: 0.6141732283464567\n","75/200 round completed......................... Accurecy: 0.6220472440944882\n","76/200 round completed......................... Accurecy: 0.6125984251968504\n","77/200 round completed......................... Accurecy: 0.6173228346456693\n","78/200 round completed......................... Accurecy: 0.6236220472440945\n","79/200 round completed......................... Accurecy: 0.6220472440944882\n","80/200 round completed......................... Accurecy: 0.6283464566929133\n","81/200 round completed......................... Accurecy: 0.6157480314960629\n","82/200 round completed......................... Accurecy: 0.6173228346456693\n","83/200 round completed......................... Accurecy: 0.6188976377952756\n","84/200 round completed......................... Accurecy: 0.6188976377952756\n","85/200 round completed......................... Accurecy: 0.6204724409448819\n","86/200 round completed......................... Accurecy: 0.6251968503937008\n","87/200 round completed......................... Accurecy: 0.6283464566929133\n","88/200 round completed......................... Accurecy: 0.6362204724409449\n","89/200 round completed......................... Accurecy: 0.6267716535433071\n","90/200 round completed......................... Accurecy: 0.631496062992126\n","91/200 round completed......................... Accurecy: 0.6267716535433071\n","92/200 round completed......................... Accurecy: 0.6236220472440945\n","93/200 round completed......................... Accurecy: 0.6204724409448819\n","94/200 round completed......................... Accurecy: 0.6236220472440945\n","95/200 round completed......................... Accurecy: 0.6236220472440945\n","96/200 round completed......................... Accurecy: 0.6299212598425197\n","97/200 round completed......................... Accurecy: 0.6299212598425197\n","98/200 round completed......................... Accurecy: 0.6267716535433071\n","99/200 round completed......................... Accurecy: 0.6251968503937008\n","100/200 round completed......................... Accurecy: 0.6251968503937008\n","101/200 round completed......................... Accurecy: 0.6251968503937008\n","102/200 round completed......................... Accurecy: 0.6188976377952756\n","103/200 round completed......................... Accurecy: 0.6141732283464567\n","104/200 round completed......................... Accurecy: 0.6157480314960629\n","105/200 round completed......................... Accurecy: 0.6236220472440945\n","106/200 round completed......................... Accurecy: 0.6251968503937008\n","107/200 round completed......................... Accurecy: 0.6299212598425197\n","108/200 round completed......................... Accurecy: 0.6251968503937008\n","109/200 round completed......................... Accurecy: 0.6299212598425197\n","110/200 round completed......................... Accurecy: 0.6188976377952756\n","111/200 round completed......................... Accurecy: 0.6267716535433071\n","112/200 round completed......................... Accurecy: 0.6204724409448819\n","113/200 round completed......................... Accurecy: 0.6173228346456693\n","114/200 round completed......................... Accurecy: 0.6157480314960629\n","115/200 round completed......................... Accurecy: 0.6204724409448819\n","116/200 round completed......................... Accurecy: 0.6125984251968504\n","117/200 round completed......................... Accurecy: 0.6173228346456693\n","118/200 round completed......................... Accurecy: 0.6188976377952756\n","119/200 round completed......................... Accurecy: 0.6188976377952756\n","120/200 round completed......................... Accurecy: 0.6220472440944882\n","121/200 round completed......................... Accurecy: 0.6141732283464567\n","122/200 round completed......................... Accurecy: 0.6188976377952756\n","123/200 round completed......................... Accurecy: 0.6204724409448819\n","124/200 round completed......................... Accurecy: 0.6283464566929133\n","125/200 round completed......................... Accurecy: 0.6236220472440945\n","126/200 round completed......................... Accurecy: 0.6236220472440945\n","127/200 round completed......................... Accurecy: 0.6220472440944882\n","128/200 round completed......................... Accurecy: 0.6236220472440945\n","129/200 round completed......................... Accurecy: 0.6204724409448819\n","130/200 round completed......................... Accurecy: 0.6220472440944882\n","131/200 round completed......................... Accurecy: 0.6157480314960629\n","132/200 round completed......................... Accurecy: 0.6220472440944882\n","133/200 round completed......................... Accurecy: 0.6188976377952756\n","134/200 round completed......................... Accurecy: 0.6188976377952756\n","135/200 round completed......................... Accurecy: 0.6283464566929133\n","136/200 round completed......................... Accurecy: 0.6220472440944882\n","137/200 round completed......................... Accurecy: 0.6220472440944882\n","138/200 round completed......................... Accurecy: 0.6157480314960629\n","139/200 round completed......................... Accurecy: 0.6125984251968504\n","140/200 round completed......................... Accurecy: 0.6188976377952756\n","141/200 round completed......................... Accurecy: 0.6188976377952756\n","142/200 round completed......................... Accurecy: 0.6173228346456693\n","143/200 round completed......................... Accurecy: 0.6157480314960629\n","144/200 round completed......................... Accurecy: 0.6078740157480315\n","145/200 round completed......................... Accurecy: 0.6141732283464567\n","146/200 round completed......................... Accurecy: 0.6110236220472441\n","147/200 round completed......................... Accurecy: 0.6141732283464567\n","148/200 round completed......................... Accurecy: 0.6141732283464567\n","149/200 round completed......................... Accurecy: 0.6047244094488189\n","150/200 round completed......................... Accurecy: 0.6062992125984252\n","151/200 round completed......................... Accurecy: 0.6078740157480315\n","152/200 round completed......................... Accurecy: 0.6078740157480315\n","153/200 round completed......................... Accurecy: 0.6094488188976378\n","154/200 round completed......................... Accurecy: 0.6173228346456693\n","155/200 round completed......................... Accurecy: 0.6188976377952756\n","156/200 round completed......................... Accurecy: 0.6188976377952756\n","157/200 round completed......................... Accurecy: 0.6220472440944882\n","158/200 round completed......................... Accurecy: 0.6236220472440945\n","159/200 round completed......................... Accurecy: 0.6267716535433071\n","160/200 round completed......................... Accurecy: 0.6188976377952756\n","161/200 round completed......................... Accurecy: 0.6188976377952756\n","162/200 round completed......................... Accurecy: 0.6173228346456693\n","163/200 round completed......................... Accurecy: 0.6125984251968504\n","164/200 round completed......................... Accurecy: 0.6188976377952756\n","165/200 round completed......................... Accurecy: 0.6204724409448819\n","166/200 round completed......................... Accurecy: 0.6251968503937008\n","167/200 round completed......................... Accurecy: 0.6188976377952756\n","168/200 round completed......................... Accurecy: 0.6204724409448819\n","169/200 round completed......................... Accurecy: 0.6204724409448819\n","170/200 round completed......................... Accurecy: 0.6220472440944882\n","171/200 round completed......................... Accurecy: 0.6204724409448819\n","172/200 round completed......................... Accurecy: 0.6047244094488189\n","173/200 round completed......................... Accurecy: 0.6062992125984252\n","174/200 round completed......................... Accurecy: 0.6015748031496063\n","175/200 round completed......................... Accurecy: 0.6094488188976378\n","176/200 round completed......................... Accurecy: 0.6157480314960629\n","177/200 round completed......................... Accurecy: 0.6173228346456693\n","178/200 round completed......................... Accurecy: 0.6157480314960629\n","179/200 round completed......................... Accurecy: 0.6141732283464567\n","180/200 round completed......................... Accurecy: 0.6078740157480315\n","181/200 round completed......................... Accurecy: 0.6062992125984252\n","182/200 round completed......................... Accurecy: 0.6110236220472441\n","183/200 round completed......................... Accurecy: 0.6141732283464567\n","184/200 round completed......................... Accurecy: 0.6204724409448819\n","185/200 round completed......................... Accurecy: 0.6204724409448819\n","186/200 round completed......................... Accurecy: 0.6220472440944882\n","187/200 round completed......................... Accurecy: 0.6267716535433071\n","188/200 round completed......................... Accurecy: 0.6267716535433071\n","189/200 round completed......................... Accurecy: 0.6330708661417322\n","190/200 round completed......................... Accurecy: 0.6299212598425197\n","191/200 round completed......................... Accurecy: 0.6220472440944882\n","192/200 round completed......................... Accurecy: 0.6251968503937008\n","193/200 round completed......................... Accurecy: 0.6220472440944882\n","194/200 round completed......................... Accurecy: 0.6204724409448819\n","195/200 round completed......................... Accurecy: 0.6236220472440945\n","196/200 round completed......................... Accurecy: 0.6204724409448819\n","197/200 round completed......................... Accurecy: 0.6141732283464567\n","198/200 round completed......................... Accurecy: 0.6188976377952756\n","199/200 round completed......................... Accurecy: 0.6157480314960629\n","200/200 round completed......................... Accurecy: 0.6204724409448819\n","The best n_estimators:\n","88\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 1800x720 with 1 Axes>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAABawAAAJNCAYAAADd4TKUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdZXiT59sG8DNJU3d3L3WBKlYoMmRjuAzZcNiYGxuzd2PG/vMxhsMGjOE+nNIWSg1a6m6pu1vkeT+UMkpTJW3Scv2OI1+aJ8ldSJPnue77Pi8WwzAghBBCCCGEEEIIIYQQQqSNLe0BEEIIIYQQQgghhBBCCCEAFawJIYQQQgghhBBCCCGEyAgqWBNCCCGEEEIIIYQQQgiRCVSwJoQQQgghhBBCCCGEECITqGBNCCGEEEIIIYQQQgghRCbISXsAkqKrq8tYWlpKexiEEEIIIYQQQgghhBBCunD37t0yhmH0xN03ZArWlpaWiIqKkvYwCCGEEEIIIYQQQgghhHSBxWLldHYfRYIQQgghhBBCCCGEEEIIkQlUsCaEEEIIIYQQQgghhBAiE6hgTQghhBBCCCGEEEIIIUQmUMGaEEIIIYQQQgghhBBCiEyggjUhhBBCCCGEEEIIIYQQmUAFa0IIIYQQQgghhBBCCCEygQrWhBBCCCGEEEIIIYQQQmQCFawJIYQQQgghhBBCCCGEyAQqWBNCCCGEEEIIIYQQQgiRCVSwJoQQQgghhBBCCCGEECITqGBNCCGEEEIIIYQQQgghRCZQwZoQQgghhBBCCCGEEEKITKCCNSGEEEIIIYQQQgghhBCZQAVrQgghhBBCCCGEEEIIITKBCtaEEEIIIYQQQgghhBBCZAIVrAkhhBBCCCGEEEIIIYTIBCpYE0IIIYQQQgghhBBCCJEJVLAmhBBCCCGEEEIIIYQQIhOoYE0IIYQQQgghhBBCCCFEJlDBmhBCCCGEEEIIIYQQQohMoII1IYQQQgghhBBCCCGEEJlABWtCCCGEEEIIIYQQQgghMoEK1oQQQgghpN/E8Krw4ck4CEWMtIdCCCGEEEIIGQSoYE0IIYQQQvrNL9dScTgiF/dyK6U9FEIIIYQQQsggQAVrQgghhBDSL4qqmxCUWgoAuBRfJOXREEIIIYQQQgYDKlgTQgghhJB+ceJeHkQM4GCohkvxRWAYigUhhBBCCCGEdI0K1oQQQgghROIYhsHRKB58rbSxcowV8qsakVBQI+1hEUIIIYQQQmQcFawJIYQQQojERWRVIKe8AQu9zTDJ0QAcNotiQQghhBBCCCHdooI1IYQQQgiRuCNRPKgqyGGaixG0VeTha6WNSwlUsCaEEEIIedq0CEQUDUd6hQrWhBBCCCFEomqb+Pg3rhAz3I2hJM8BAEx1MUR6SR3SS2qlPDpCCCGEEDJQRCIGC3bcwextoahp4kt7OGSQoII1IYQQQgiRqPOxhWjii7DQ2+zhz55xMgQAXE4oltawCCGEEELIALuWVIwYXhVieFVYsS8S9c0CaQ+JDAJUsCaEEEIIIRJ1JJKHYQaqcDfVePgzQw1FDDfXpBxrQgghhJCnBMMw+D0wHebayvjtheGIzq3Emr+i0MQXSntoRMZRwZoQQgghhEhManEtYnhVWOBlBhaL1e6+qc6GiMuvRl5lQ5fPsfdWFn65ltafwySEEEIIIf3sVnoZ7udV4+XxNpjhbowfFrjjTmY51h+8i2YBFa1J56hgTQghhBBCJOZYFA9ybBZmDzfpcN8U5+5jQe7lVmLzhUT8dC0VN1NK+m2chBBCCCGkf229kQ5DdUXMGdF6Xjh7uCm+nu2KmymleP1wNARCkZRHSGQVFawJIYQQQohEtAhEOHkvH5McDaCjqtDhfktdFTgYquFyJ7EgLQIRPjgRC0N1RVjrqeCjU/GUc0gIIYQQMghFZVcgPKsCa/2toSDHefjzF3zM8dkMJ1xOKMY7x+5DKGKkOEoiq+SkPQBCCCGEEDI03EguQXl9S7tmi4+b6mKIX66nobS2GXpq7Yva24MykFpchz0veUFdiYv52+/ghyup+HSGU38PvUcKqxtx8l4+GKbjhRWXw8ZcT1PoiinUD3XVjXwEp5biWVcjsNms7h+A1uiY0tpmjLbV7efREUIIIUQatgamQ0dFHi/4mHe4b8VoKzTyhfjuUgqUuBx8M8e1Q5QcebpRwZoQQgghhEjE0SgeDNQVMNau8yLkVBdD/HwtDVcTi7HY978LmPSSWmy9kY4Z7saY6GgAAFjqZ479oVl43sMYHmaa/T7+7nxxLhEXu2gaefxuHv5Z6yd2dflQ9uHJWPwbV4SqRj6W+Vl0e3x9swAr9kWiupGP6E8ng8uhTZ+EEELIUBKfX42bKaV4b4o9lOQ5Yo95Zbwtqhv42BGcicW+5nAzlf65HpEddHZICCGEEEKeWHFNE26mlGCepynkuihA2huowVJHGZcS/iv8ikQMPjgRB2UFDj57ZDX1+1MdoK+miA9OxIIv5YzD9JJaXEoowoYAG6R9Na3D7e/VvsitaMCyPRGobuBLdawD6XJCEf6NK4KGEhdbLiajsLqx28d8fyUF+VWNqGsWIIZXNQCjJIQQQshA+j0wHWqKclg2suuJ7A0TbKEgx8bRKN4AjYwMFlSwJoQQQgiRMQzDoKqhRdrD6JUT9/IgYoD5np3HgQAAi8XCFBdDhKaXobqxtbB7KCIXUTmV+PhZp3aRGuqKXGye5YLkolrsDM7s1/F3Z1tgBhTlOFg1xhpcDrvDbZStLnYs80RaSS1e2heBuqcge7umiY9Pz8TDwVANJ18ZBYFIhE9Ox4uNTGkTnVuJ/aHZmOVhDDYLCEktHcARkzaV9S1d/j89rWqa+NQAjBBCnlDbJP/yUZZQV+R2eay6IhfTXY1wJqYATXzhAI2QDAZUsCaEEEIIkTE7gjMx6tsbg2alblZZPfbeyoKPlTYsdVW6PX6qsyEEIgY3kotRWN2ILReTMcZWF3MfdJB/1GQnAzzraoRfrqcho7SuP4bfrdzyBpy5X4DFvubQVpHv9Ljx9vrYungE4vKrsXJ/JBpbhvaF15aLySitbcaWuW6w0VPF25OH4VpSCf6N66qpZhwM1RWxeZYL3M00EZxWNsCjJmV1zRi95Qa+vZQs7aHIFL5QhEk/BOHzc4nSHgohhAxqbZP8K0Zb9ej4BV5mqG0S4FIXsWvk6UMFa0IIIYQQGVLfLMCOoAw0tAgRmV0h7eF0K6+yAUt2hUHEAF/PdunRY9xNNWGoroiLcUX45HQ8BCIRvp7debOdz553gqIcGx+ejINICp3ktwdngMNiYa2/dbfHTnE2xE8LPRCZXYG1B6KG7GqhiKwKHArPxcrRVnB/kC++crQVXEzU8dnZeLE7BHYEZSCluBZfznKBmiIX/nZ6iM2rGnS7CQa709H5aGgRYldwJuLyqqU9HJkRllmOktpm/BOZ26NoG0IIIR21TfIv6WaS/1G+Vtow11amWBDSDhWsCSGEEEJkyOGIXFQ28MFmQeYL1kXVTVi8Kxx1zQIcWOUDW321Hj2OzWZhirMBriYV41pSCd6ZbA9zHeVOj9dXU8THzzohIqsC/0QO7MVMUXUTjkflYZ6XKQzUFXv0mOfdjbFlrhtC0srw6t/3pJ6/LWlNfCE+OBkLUy0lvP3MsIc/l+Ow8e0cN1Q28PH1v0ntHpNeUoffbqTjOTejh001/YfpQsQAt9PLB3T8TzOGYXAkkgcnI3Xoqipgowzkw8uKS/FFUOSyIWIg9QgiQggZrNom+df0YJK/DZvNwnxPU4RmlCO3vKEfR0cGEypYE0IIkSqGYbD+wF1cjCt84udqbBHijX+icSAsRwIjI2TgNfGF2BmciVE2OhhhroXwLNktWJfVNWPJ7jBU1Lfgr1W+cDbW6NXjp7gYgmEAVxMNrBht2e3x871MMcpGB9/8mzSg0SC7QjIhZBi8PM6mV49b4GWGzTOdcS2pBMv3RSCpsKafRjjwtgWmI7O0Hl/PdoWyvFy7+1xMNLBmrDWORuXhdnpr3IdIxODDk7FQkufgsxnOD491N9WEmoIcQtJ6lmP9wYlYHI7Ildwv8hSK4VUhraQOy0Za4IuZLkgsrMHukCxpD0vqhCIGlxOKMdHBALM8THA4Ihdldc3SHhYZYirqW7DmrygEppRIeyiEPJHT0fmY+MNNTPi+4+1oJA/zezHJ32aelylYLOD4XVplTVpRwZoQQohUFVQ34VJCETaeiEVJbVOfn6dZIMTaA1E4E1OAL84lILW4VoKjJGRgHL+bh5LaZmwIsIW3lTbi86vR0CJ7zfuqGlqwdHc48qsasXe5NzweREL0hq+VDl4eb4OfF3lAjtP9KSmLxcKWuW5Q4LKxZFf4gKzAqahvwd/huZjpbgwz7c5XgHdm2UhLfD3bFXF51Zj2SwheOxyNTCnlcEtKclENtt3MwJzhJvAfpif2mDcn2cFCRxmbTsWhsUWIvyNyEZldiY+edYSe2n9NNeU4bIyy1UFIWlm3DQCTi2rwTyQP315MfioaWvaXo1F5UOJy8JybEaa6GGKqsyF+vpaKrLJ6aQ9NqqJzK1FW14wpLoZ4JcAGzQIR9t6iQj6RnOpGPl7cG46ricX4+WqqtIdDSJ/xKhrw4ck4yLHZcDbR6HB73sMYr0+06/XzGmkowd9OD8fu5kEohfg3InuoYE0IIUSqUopaVx3WNAnw+dm+NTriC0XYcCgaIWll2DTdAWqKXGw8EUsnO2RQ4QtF2B6UAQ8zTYyy0YGPlTYEIgbRuVXSHlo7NU18vLg3Apll9dj9ojd8rLT79DwcNgsbpzrARk+1x48x01bGwdW+aBIIsXh3GAqq+jdndu+tLDQJhHgloHerqx+12NccIe9PwIYAG1xPKsbkn4Lx/vH7yKscfFtehSIGH5yIg7oSFx8/59TpcYpcDr6Z44qc8gZ8ciYe315MxigbHcz3NO1wrP8wPeRXNSKjtOuC6bGoPHDYLFQ38nGQdtH0SUOLAOfuF2C6qxHUFLkAgM9nOkNejo0PT8Z2O2kwlF2KL4I8h40Aez3Y6KliuosRDtzJQXXj4Gh8S2RbXbMAy/dFIKWoFtNcDHE/rxrJRUNn1w15ejAMg49Ox4PNAvat8MZvLwzvcPtxgUevV1e3WeBlhsLqJtxKp4bMBJDr/hBCCCGk/yQXta6EXudvjR3BmZiZUIRnnA17/HihiMGbR2JwLakYX8x0xosjLaGnpoC3jtzHwbAcvDTKsp9G/vSKzatCSU0zJjkZSHsoQ8rZmALkVTbi/2Y4g8ViwdNCCyxWa3O70ba60h4egNbIkpX7IpFYUIMdyzwxxm7gx+VgqI4DK32xeFcYluwOx5F1ftBX69uFUVdqmvj48042prkY9jibuzMayly8N8UBK0ZbYVtgBg6G5eB0dAGe9zCGrqpC90/wCBcTdTznZvxE4+kLoYjBr9fTEMOrwi+LPLptpDTKRhcLvcxwJIoHBTk2vpkjvqmmv13rKu2QtFLY6oufvGgRiHAqOh9TnA1Q2yTA7pAsLB9lCUUu58l/safIxbgi1DULsNDb7OHPDNQVsWm6Iz48GYejUTws9DaX4gilg2EYXEoowhg73YeF/FcCbHAhrhB/hWbjtT6sFCSkTWOLEKv/jERsXjV+XzwcPlY6uJZUjKORefh0RucTf7Kior4FN5JLMGe4Cdhs8Y2RydPjdEw+glNL8fnzzjDWVJL4809y0oeWMhdHo3gY18kuLgAIzyxHbZOArkWGOCpYE0IIkarUoloYaSji3Sn2CEotxSdn4uFnowP1BxeNXRGJGLx/PBYXYguxaboDXhxpCQCY5WGCU9EF+O5SMiY5GcCkH06onmZfnEtEDK8KZ18dAydjdWkPZ0gQihhsu5kOB0M1THTUBwCoK3LhZKSOCBnKsf7lehqiciqxdfHwh43zpMHVVAP7V3pj2Z4ILN0djn/WjuxxJ/qeOnAnB7VNArwy3lZiz6mrqoBPZzhh9Vgr/HYjDWdiCiDoxU4Q0YNjPcw0YarV+4iSvhCJWot5P15NRXpJHaY6G+J5954VzDdNd0RiYQ0W+ZjBQkdF7DFm2sqw1FFGSFoZVoy2EnvM9aRiVNS3YL6XGZS5HCzcGYYjkTyakOylI1E8WOoow9tSq93PF3qZ4XR0Pr66kIQAe33o93Fl3GCVUFCDvMpGvD7hv8K0s7EGJjjoY+/tLKwcYwUVBbpsJr3XLBBi3cG7CM+qwM8LPTDVxQgAMNnJAKei8/DBNAfIy8nupneGYfDO0RgEppRCicvBs25G0h4SkaLyumZ8cS4RI8w1sdTPol9eQ0GOg1nDTXAoLBeV9S3QEnNudzOlBGv+igJfyOD7+e6YJ2b3FhkaZPfTkRBCyFMhuagW9oZq4HLY+HauG0prm/HdpeRuH8cwDD45E48T9/Lw1qRhWOv/35Z9FouFr2a5QMQAH5+Ke6q3OUtaTRMf0bwqCB40UaPYFcm4FF+EjNJ6bAiwbbcK1dtSG9G8SrQIRFIcXauEgmrsDM7EAi9TqazwfZynhTZ2v+SFnPIGLNsTLtGt+w0tAuy5lYUAez24mPSumWRPGGsq4Zs5bkj8YipSv5zW41vIxgCwWMCOoEyJj+lxDMMgMLkEM7bewiuH7gEA/lgyAn8sHSF2pbQ4GspcnHttDJb4dn1h6z9MD3cyytEsEIq9/0gUD4bqivC304OvtQ68LbWwIyhDJv4uBoussnpEZFVgvpdZh/8/NpuFb+a4okkgwv+dS5DSCKXnckIR2Cx0WKm3IcAWlQ18avRJ+oQvFOHVv6MRnFqKLXPcMNPD5OF9C7zMUNnAx7WkYimOsHtn7xcgMKUU8nJsbA1Mp/Ppp9zm84moaxbg27lu4PTjavsFXmZoEYpwOia/w32hGWVYd+AuhhmoYYytLt4/fh/n7hf021iIdFHBmhBCiNTwhSJklNbB3rB1u72HmSZWjLbCwbBcRGZ3vqqUYRh8dSEJh8JzsX6cDV6f2HEFpJm2Mt6dYo/AlFKciy3st9/haROaXg6hiMEyPwvcz6vG/tBsaQ9pUMivany4OvZxDMNga2A6rHVVMN21/eolXyttNPFFiMuvHohhdkogFOGDE3HQUpbHpumOUh3Lo0bZ6GLHMk+kFtdi+b6IXjfjSy+pQ3RuZYfbtsAMVNS34NUJkltdLQlGGkqYO8IUR6J4KKnpe5Pa7kRkVWD+9jtYsT8SNU18/LjAHZff9Mc0V6MeF6t7Y6ydHhr5QtzNqexwX2F1I4JTSzHP0/ThBfKGAFsUVDfhdHTHi1ki3vG7PLBZ6HQlmrWeKt6YaId/44pwMCxH7N9FclFNrwpWjS3Cfn2fSsql+CL4Wul02KXhaaGFkdY62BmciSa++MkUQsQRCEV460gMriYW4/PnnbHgkRgeoPUzz0hDEUejeFIaYfcq6lvw+blEuJtqYPNMZyQV1iAwpUTawyJSEphSgtMxBXhlvC2GGTxZTFp3HI3U4WaqgSORvHbfOXdzKrD6zyiYayvjwCpf7HrRC16W2njrSAyuJBT1+fVaBCKU1TVLYuhEwqhgTQghRGqyyurBFzJwMPzvxOedZ4bBVEsJH5yI7XCByDAMglJLMfP329h9qzXDdONU+04LKMtHWcLdVAOfn01AZX1Lv/4uT4uQtFKoyHPw6QwnTHDQx/eXU8CrGHzN4wbSnYxyjP72Bqb/GoKricUdCj6BKSVIKqzB+vE2HVaseFm2NjTsagJnIOy7nY24/Gp8/rwzNJUlG73xpMbb62Pr4hGIzavGqv2RaGzpWWHpt+tpmPRjEGZvC+1w2xqYjpHWOvC06FtDyf60fpwNBEIRdt/K6pfnTyuuxaKdd8CrbMCXs1xw/e3xmDPCtF9XU/lZa0OOzUJIWscmSyfv5UPEAPO9/iu0jhumB1cTDfwRlEG7PHpAIBTh+N08jLfX77IR1lp/azgaqePj0/Fi/y6m/hyC+dvvICyzvMvXaxYIse92FsZ+F4ix3wXiTkbXx0tTekkd0krqMNVFfO+MVyfYoqS2Gcfv5g3wyMhgJBIxOB9bgGd+Dsb52EJ8OM1BbHQRh83CPE9TBKeWorC6f5sH99WXFxJR08jHt3PdMGeEKUw0lbD1Bq2yfhrVNwvw8al42OqrPlET6t6Y72WG5KJaxOe3NieNy6vG8r2RMFBXxKHVvtBWkYeSPAd7l3vDxUQDr/4djaDU0l6/Tl2zAAt23MHYLYFSP9cmHVHBmhBCiNSkPGi4+OhMvbK8HL6a7YqM0npsC0x/+PPI7Aos3BmGl/ZGoLyuBd/Nc8Onzzl1udqPw2bh27luqG7k48sLSf33izxFQtLKMNJGF1wOG5tnuYDNAj46HU8XMF3YGpgGHRV5NPGFWPNXFGZvC8XtB93PGYbB1hvpMNFUwuzhJh0eq6emAGs9FanmWOeWN+CHqymY5GiA6a49b4g6kKY4G+KnhR6IyK7A2gNRnUZLtNkVnIkfrqbieXdj7FvhLfb2+5IRAzT63rHUVcEMd2McDMvpl4m4I5E8sFksnH9tLJb6WQxIvqqaIhcjLLQQktb+YlMkYnA0igc/a+12GdgsFgsbAmyQVVaPC3G0g6Y7IWllKK5pxgKvrnM+uRw2jq7z6/Rv4vPnnZFX2YhFO8OwbE847vOq2j1eIBThSGQuJnwfhM/PJcJWXwVm2spY9Wck7uV2XD0vCy4/WJX3jLP4TP5RNjrwMNPE9qAM8IUUQUPEYxgGN5KL8dxvt/Dq39HgsFjYvtQT68Z1Xtyb52kKEQOckMHJkODUUpy8l4/142zgaKQOLoeN9eOscS+3Cne6mbAiQ8/3V1JQUN2ILXNdoSA3MM2On3c3hoIcG0ejeEguqsGyveFQV+Li0Grfdn0WVBXk8OcKH9jqq2LtX1G9miBtbGltJB6fXw1tFXms2BeJ2Lyq7h9IBgwVrAkhhEhNSlEtOGwWbPVV2/183DA9zB5ugm03M3AmJh/L90Vg/vY7yCytx+fPO+PGu+OwwMusR93KHY3UsX6cDU7cy+tQDCG9k11Wj9yKBvgP0wUAmGgq4f2pDghOLRWbM0eA6NxK3E4vx/pxNrj69jh8O8cVJTVNWLI7HC/sDMPe29m4l1uFdeOsweWIPy3zsdRGZHaFVFaSMgyDTafiIMdmY/Ms536Jg5CU592NsWWuG0LSyrDhUHSnxaUDd7Lx1b9JmO5qiB8XuCPAXl/sTdJNHCXplfG2aGgRYp+EI3laBCKcis7HJEcD6KkpSPS5u+Nvp4v4/BqUP7ItNyK7AjnlDVjgZdbh+GecDGGnr4ptgemdxu2QVkciedBRkccEh+4bpaopcjv9m3hplCVuvjceHz/riISCGsz8/TbW/BWFxIIanInJx+SfgrHxRBx0VeVxcJUvDq/xw9+rfaGvpoCX9kYgXsrRRuJcTiiCh5kmjDTEN2dmsVh4NcAWeZWNOBtDOamkozsZ5Zj7RyhW7o9CXbMAPy5wx6U3/Ttdtd/GQkcFftbaOBqVJ1OfYQ0tAmw6FQdrXZV2sVjzvcygp6aA3x9ZTEKGvujcSuwPzcYyP4sB3XWmocTFNBdDnI7Jx9Ld4VCQY+PwGj8Ya3b8rNZQ5uLAKh+YP5ggFRcv9rgmvhBrD0QhKqcCPy30wPGXR0JLhYtleyKQVFjTH78S6QMqWBNCCJGa5KJaWOmqiJ2t/+Q5J6grcfHGPzGIzq3CxqkOCH5/PF4aZdnr2f1XJ9jCWlcF7x5rbcwhSxcGg0lbwd/fTu/hz5b6WWCEuSa+OJfYrtA02CUX1WDm1ltPnL/6e2A6NJW5WOxrDi6HjUU+5rjx7nh8+pwT0kpqsfl8InRVFcQW5Nr4WGmjtknwcEfCQDpxLx+30suwcap9pwUdWbLAywxfzHTGtaRivHUkpkOR/1gUD5+cScBEB338vHA45DqZJJB19oZqeMbJAPtvZ6G2SXLNJm8kF6O8vgULvLteidsfxj74XLmV/l8syNEoHtQU5DDNxajD8Ww2C68E2CC5qBbXk4dOruqu4Eys+StKYhNU5XXNuJZUjNnDTSSyWl6Ry8HqsdYIfj8Ab08ehrCMckz/NQRv/BMDeQ4bO5d54vSG0RhjpwsWiwV9dUUcWuMHdUUulu0JR2px559j4ZnlWLYnHD9eTe3xeOqaBVi8KwxHI3ufBZxf1YjYvOpuC4sTHfXhYKiGTafi4PPVtQ63MVtuyGQxnvQvgVCEN/6Jxgu7wlBQ1YSvZrvg+jvjehWhtNDbDLkVDYiQoSiCH6+kIq+yEd/McYUi97/zbUUuB2vGWuF2ejmiJbhjoq3B76Kdd/D64WhklNZJ7LlJ3zEMgysJRXjtcDQM1RXx3hT7AR/DAi8z1Da19iY5tNoP5jrKnR6ro6rQuvpaTQHL90Zgz62sTnsPtDZEvYeQtDJ8N88dM9yNYaShhL9X+0GJy8GyPeFIL6H3oSwYnGfphBBChoTU4lrYd9K4Q1tFHtuWjMAH0xwQsjEAL4+3gbK8XJ9eR5HLwa8vDIemkjxeOxyNZ3+7hetJHbOESdeC08pgpq0Ei0dOGNtiV+qaBdh8PlGKo5OsfbeycT+v+okadiYV1uBaUglWjraCisJ/711FLgcrx1gh6L0AfPKcE35e6NHuovBx3lLKsS6tbcbm84nwtNDCEl+LAX3tJ/HiSEtsmu6A87GF2Hgi9uEE1bn7Bdh4IhZjbHXx+5IRAxJ10Z9enWCLmiYBDoblSuw5j0blwUBdod2k1EBxMdGAljIXwamtBeuaJj7+jSvEDA9jKMmL//uY4WYMc21lbA0cGrmqu4Iz8dW/SbiaWIzQjI553n1xKjofAhHToenbk1JVkMPrE+0QsjEAH0xzwK8vDMfFN8biGWfDDjsxTDSV8PcaX3A5bCzeFY7MxwpS93lVWLYnHAt3hiE0oxx/3ExHQVXPcn0PheUgNKMcG0/G9jpa4XJ8axzIFOeuC9YsFuthju9ER/0Ot9omAX7qRZGdDH5CEYN3jt3HmZgCvDHRDjffG48lvhad7pTqzFRnI6gpyPVpwqU/3OdVYe/tLCz2NYevtU6H+5f4WkBTmSuxVdZ3Msox70GDX15FI64lFWPyj3OdBWYAACAASURBVEF499h96o8iJQzDICStFLO2hWLtgbvgctjYung41BS5Az4WP2sdfPqcE/5Z69dhN644+uqK+HuNH9zMNLD5fCICvr+JwxG57XbcCYQivPlPDK4lleDLWS7tGhGbaSvj7zW+AFhYsjsMOeX1/fFrkV4Y3GfqhBBCBq36ZgFyKxpgb9h5p2k/ax2sH2cDdQmcJLmYaODfN8bil0UeaGgRYNWfUZjzRyhC0yVTFBjq+EIR7mSUY6ydXodixDADNbwy3hanYwqGRAf5+mYBzse2bv1uK2j0xe+B6VBVkMNLIy3F3q+iIIdVY6wwxk63y+cx1VKCsYbigK/A+uJ8IhpbhPh2jmuP4ndkyVp/G7w1aRiO383Dp2fjcSWhCG8diYGXhTZ2vujZ5QTBYOFmqomxdrrYcyuz01VEvVFc04SbKSWYO8JUKivPOWwWRtvqIiStFAzD4Pz9QjTxRV3uPpDjsLF+nA3u86pwO31w56o+GlWjqczF0agnz7VlmNYMcA8zzXa9IiRJU1ke68fZ4Hl34y4/Jyx0VPD3Gl8wDIMlu8PBq2hAanEt1h2IwszfbyM+vxofTXfElbf8wTDAzuDMbl+7iS/ErpAs+FlrY6S1Dt47fh8XejHJeCmhCA6GarDSVen2WA8zTXwzxxXfzHHrcFs1xgrXk0uQWEDbyJ8GIhGDTSfjcCamAO9Ptcdbk4f1+TtFSZ6DGR7G+De+EDUS3C3TF3yhCBtPxEJXVQEfTHMQe4yKghxWjLLCtaSSJ4pNiOFVYenucLywKwx5Dxr8Br47HsHvB2DFaCucvV+ACT/cxKdn4p94pxvpuajsigc9CiJQWtOELXNdcfUtf6k1oGazWVg5xgq2+j3//jLWVMKh1a1xVIYaivjwZBwm/RiE09H5EAhFeP9ELC7EFeLjZx2x1K/jYgxrPVUcWu2LFoEIi3eF93jylPSPvi1VI4QQQp5Q27bgrgrWksZhszDTwwTTXY1w/G4efr2ehsW7wzHKRgdb5rrBTLvzrWZPu+jcKtQ1C+DfSXH1lQAbXIgrxIcn4jDZqfuc1EcZqCtgqZ8FNJVlIzP4Qlwh6luEGGuni1vpZSitbe51nm9maR0uxBVinb8NNJSfbMKFxWLB20oboRnlYBim33OkRSIGR6J4OHe/AG9NGga7fip09bfXJ9qikS/E9qAMHAzLhbuZJvYs9+rzTg1Z9GqALRbuDMM/EblYPtrqiZ7r+N08iBh0WSDub/52ejgfW4jU4jocieLB3kAN7qYaXT5mrqcJfr2ehl+vp2GUjc4TT64UVDXiTEwB1vpb93hb/5Nqi6qZ5GiAXxYNx1cXkvB3RC6qGlqe6HPxSmIxUovr8PVsVwmOtu9s9dVwYJUvXtgVhhlbb6G6kQ9VeTm8NWkYVo6xfLiCb/ZwExyOyMWGANsuP3uPRfFQVteM314YDjdTDby0NwJv/BMNRS4bEx27/h4qrW1GZHYFXp9g98S/10sjLbEzOBO/30zH74tls1krkQyGYfD5uQQcieLh9Qm2eGW8bfcP6sZCLzP8HZ6Lc/cLpLabqVkgxP8upSC5qBY7lnl2uVBk+ShL7ArJxO+B6dgq5v0uFDE4H1uAqGzxsSG8ygbcTCmFtor8w6JhW8FfV1UBnzznhNVjrfDbjXT8HZ6Lo1E8vDFxGF4e33kDS9IzoelluNjJQozs8nqEpJVBV1Ue/zfDCS/4mg9Yg8X+MMpWFydtdHAjuQTfX0nFm0disPl8IsrrW/DO5GFYPda608faG/73XbV4VxhOvjK6X/uaHI7IRRNfiJdGWg66BSL9beicsRNCCBlU2vJ4HQawYN2Gy2HjBR9zzB5ugr/Dc/HTtVQs3h2Go+tGDoqcXmkISSsFh83CSBvxBWsFOQ6+n++O1w9H40Jc72I0KhtasCMoE2v8rbFyjBVUFaR7enIsigdrPRVsmu6Iab+E4GpiMRb7mvfqOf64mQF5DhurxjxZEbGNj5U2zsQUIKe8AZY9WA3YFwzD4GZKKb6/koKEghoMN9cc1BeILBYLG6fag8UCYvOqsG2xp1S2tPYnX2sdeFtqYUdwJhb7WvQ55oRhGByL4sHHSrvf3l89MfZBQ9fdIZm4z6vCx886djtBoyDHwesT7bDpVBw+OROPL2e59HlSRyRi8NaRGIRnVcDBSA0B9vp9ep7eOPsgqmasnS62Lh4OLoeN+V6m2B+ajTMxBXhplGWvn/M+rwrfX0lByIMYpxnuHTPApcXJWB1/rfTBu8fuY5G3Odb5W0PrsULAy+NbGyXvuZXV6UpPvlCE7UGZ8LTQgp+1NlgsFvau8MbS3eF4+eA97Fnu9TAXXZxrScVgGHSbX90TGspcLBtpge1BGcgorYONXvdb18ngwzAMvr2YjD/v5GDNWCu8NXmYRJ7XzVQD9gZqOBqVN+AFa4FQhJP38vHL9TTkVzVinqdptxE5GspcLPWzwI7gDLxdWgfrB+93hmFwOaEIP1xJRVpJHdQU5cRGpCjKsfH25GFdnu8ZaSjh69muWOdvjY9Px2PLpWQs9jWHhtLQ+g4fSM0CId46GoOqBn67mLo2SlwO3p9qj+WjLIfMxD6LxcJERwME2OvjQlwhtgdlYNlIi3bNRDvjYqKB/Su8MX/7HWwPysCm6Y79Msb8qkZsPp8IL0ttLO/D9/1QNzTeiYQQQgadlOJaKHE5MNOS3qrmtixhTwstLNkdjiW7wnFk3cher6Z9GgSnlcHDTLPLiwUPM00Evx/Q6+dOLqrBD1dS8ePVVOwPzcYr423arbgZSBmldYjMrsQH0xzgYKgGCx1lXEoo6lXBOq+yAaei87HUz0Ji7yWfBznWEVkV/VJQvJNRju+vpOBuTiXMtJXww3x3zBpuMmArTPtLa9FafMFrqNgQYIvl+yJxKjoPC717N7HSJjK7EtnlDXhNAqtNn4SRhhLs9FVx7G4euBwWZg836dHjXvAxA6+yAX/czIAil9OjQrc4R6N4CM+qAIfNwrEoXr8XrC+3RdVYamPnMq+Hn3nOxhpwMVHHkUherwrWKUW1+OFKCq4kFkNLmYuPpjti2UjpfJZ2xd1ME1ffHtfp/dZ6qpjuaoSDYTl4eZz4XSqno/ORX9XYboJCXZGLv1b6YNHOMKz5Kwp/rvARm8MLAJfii2ChoyyxSfNVY6yw73YW/riZge/nu0vkOYls+eV6GnYEZ2Kpnzk2Te/bZ4w4LBYLC7zNsPl8IlKKagdk56FIxOB8XCF+vpqKzLJ6uJtq4Js5rhjbTURZm0ff79/Nc0NwWhm+v5yCuPxq2Oip4PfFIzDNxfCJV4ta6Khg1RgrhKSVIbGgBiNtxP89k+6duJuP4ppmHFzl220U3VDDZrMww90YM9yNe/U4TwttPOdm/PC76PHJ1SfFMAw+PhUHhgG+eoLJ9qGMCtaEEEKkIqWoFsMMVGVi65O7mSb2rfDGi3sisHR3OP5Z6yfxk5LOMAyD9JI6mY5dqKxvQWxeFd6Y2D/FLAdDdex60QvRuZX44UoqvryQhF0hmXhlvG2nK9VcTNR7tVU+p7weJppK3WbzHovKA4fNwpwRJmCxWJjqbIg9t7JQ3cjv8cqencGZYLGAtf6dbzfsLVt9VWiryCMiu6LXzdP4QhHu5lRCIOzYlK6RL8Sfodm4lV4GA3UFfDnLBQu8zAZ9Q8KnybhhenA10cAfNzP6nD99JJIHVQU5THN98tWmT2qsnR7SSuowydEAOqo9m/BhsVh4f4o9GluE2HMrC8ryHLzzjH2vXrekpglf/ZsEXyttOBmr42BYDsrrmns8BnEEQhHu5VahRSDqcF9+VQM+OZ0AVxMN7F3u3aGx5AIvM3x6JgHx+dVwMek6FoVX0YDvr6Tg7P0CsREbg9GGAFucjy3E/tBsvDGp/XePUMTgj5sZcDJSx3j79quoNZXlcXC1LxbuuIOV+yPxzVw3aD/2XcEXiRCaUYaVo60kViDQVVXAIm9zHAzLwZuT7GDax8n4pMIalNe1iL3PUle5z89LulfXLEAsrwoiMf1bI7LK8euNdMzzNMUXz0u+sDTLwxjfXkzC9qDWz/HHKXDZGGGuJZFJ5MCUEmy5mIzkotbG5zuWeeIZJ4Ne/U56agp4waf1/Z5VVo+onEqYainhf/PcMHu4iUT7IDgbt37+JRRUU8G6jwRCEbYHZcDdTBOjbenfsDc2BNji7P0C7AvNxts92FUhEIqQX9UIC53uF5eciy1EYEopPnnOiWIpO0EFa0IIIVKRUlSLiY79v926p7wttbH7JS+s2B+JZXvDcWi134BsPfzrTg4+O5uAY+tHwttSOk1NunM7owwMgy63V0vCcHMtHFzt+3C172dnEzo91lhDEUfWjezRCd7xu3l499h9vOBjjm/mdJ7lKhCKcOJeHgLs9aGvpggAmOJiiB3BmbiRXIzZwzteRD6upLYJ/0TyMGe4KYw1JRcvw2Kx4GWhhYisnjdeFIoYnL2fj5+upiG3oqHT48TlSJLBg8ViYUOALdYfvIvDkTwsE9NEqCu1TXz8G1eIWcONZWIb8CRHfey9nYUXfHq3WpzFYuGzGU5oFgjx2410KHI52BDQ83zZz84moFkgwjdzXMEXMth3OxunYwr6FOsjEjH4N74QP15NRWZpfafHORur48+VPmK3xc90N8GXF5JwNIrXZcG6tomPBTvuoLKhBev8bbB+nLXM9AN4Eo5G6pjkqI99oVlYPdaq3Rb2i/GFyCyrx++LR4gtsumqKuDQaj8s2HEHrx+O7vQ1prtKNipl3ThrHArPwY6gTGye5dLrx6cU1WL6ryFgxBRMgdY+HPM9TfHaRDuYSPD75WnXxBfiYFgOtt3MQEW9+MkCAJjhbowtc936ZaGFjqoCnnE2xKnofJyKzhd7jJ2+Kt6ePAxTXQz7XDC/l1uJFfsiYamjjF8WeeA5N+M+F8HX+lvjcEQucisasHmmMxZ6m/fLZLeemgL01RSQQE1N++xcbAFyKxr6vPvoaWZvqIbJTgbYfzsLa/2tu40t/ORMPP6J5OHHBe5dXjdU1rfg87MJcDfVoCiQLkj/rJQQQshTp6yuGeX1LbA3VJf2UNoZbauLHUs9sfZAFFbsi8CBVb5ic94kJb+qEd9dSgYA3E4vk9mCdUhqGdQV5bptfiYpI210cHz9SCQW1qChRdjh/qoGPt45GoMlu8NxdN1IGGoodvpc52ML8P7x+9BU5uJwRC5mehjDr5Mt4jdTSlFa24wFXv+dYHqYasJAXQGX4ot6VLDeE5IFgVDUL9nPPlbauJJYjKLqpi5/58dzJJ2M1PH74hHQV++4UpSF1sJQf77PSf+b4myA0bY62HIxGZMdDbp8fzzufGwhGvlCqTZbfNQoW10EvxcAc53erzZisVj4cpYrmvgi/O9yChS5nB4VnC/FF+FifBHem2L/MI/V3UwTx6J4WDnasscX+AzDPGzwlFRYg2EGqvhlkYfYySsWWjMyO5sk0lDmYqqzIU5H52PTdMdOj/vf5RQU1TThxMujMMJcq0fjHCw2BNhi9rZQHArPwVr/1s9UhmHwe2AGrPVUusyfNtRQxL9vjEVSofgil6qCHByNJHsOYqShhLkjTHEkiofXJthCX73nf4cA8HtgOpS5HOx60Qvcxwp/IhGDi/FF+Ds8Fyfv5WOxr3m3TSlJ1/hCEY5G8fDr9TQU1zRjrJ0uVo62gqpix+9DeQ4briYa/borcMtct04LV/mVjfjtRhpePnQPriYaeOeZYRg3TK/XxcetN9KhpczFhdfHPvH3vrGmEgLfHQ8tZfkOO0QkzcVEAwkF1f36GkOVSMRgW2AG7A3UMKmbZrREvFcDbHE1sRgHw3Kwflzn5/ehGWU4HMGDpjIX7xy9DwU5TqcTo19eSEJ1Ix8HV/sO+vi9/kRXJ4QQQgZcW8NFexmMwQhw0Mevi4bj1cPRWPVnJPav8OmXVadtuWUiBjDRVEJkds9Xzg4khmEQnFaK0ba6Et3i2R0Wi/VwG6g4f63yxdLd4Vi8OwxH1orPHb+aWIw3/4mBp4UWti/1xOxtofjwZBwuvjFW7P/p0SgedFUVEODw38p/NpuFKc6GOBrFQ0OLoMsVqFUNLTgYloPn3Iz7JWfax+pBjnV2BZ4Xk8PX+n9Vhh+upCA2T7I5kkS2sVgsfD3bFVN+DsbHp+Ox60XPHhcyjkbxYKevCg8zzX4eZc/1pVjdhsNm4X/z3NDEF2Lz+UQoctldNjKrbuTj0zPxcDBUaxfjs8DLFB+dikdsXjXce/BvE5rRmuF6L7cKFjrK+HmhB2a49331YusYzHD2fgGuJBaL/ZuPyq7AgbAcLB9lOeSK1UDrrpvRtjrYFZKFF0daQpHLwY3kEiQV1uD7+e7d/tuqKsgN+ETw+nE2OBrFw+5bWb1q0pVdVo/zsQVY42+NUbbi82V9rXWwxt8av11Pw4GwHByJ5GH5aEus8x8aq+oHilDE4ExMPn6+1rr7yNNCCz8vHC71uImu3q/elq0rvE9F5+Pna6lYvi8S3pZaePcZ+05z2h+XUFCNG8kleGfyMIlNUktyJ1lXnI3VEZRaiia+kHaC9dKVxCKkldThl0UedC7YR+5mmhhrp4vdIVlYPspS7HuwiS/EppNxsNBRxsmXR2Htgbt4/XA0FLlsTHBoP1EQklaKE/fy8GqArcQnTocaCigkhBAy4JLbCtYD0FimL6a5GuGH+e4Iz6rAJ6fj++U12nLL3p1ij0mO+riXUwW+sGPOqbRllNahsLqp3+NAesvDTBN7l3ujoKoRy/aEo6qh/Tbe4NRSbDh0D87G6ti73Bs6qgr4erYrssrq8duNtA7PV1rbjBvJJZg7wqRDV/upzoZo4osQnFra5Zh2BmeivkXYqxiC3nAyUoeKPAeRYmJBIrIqsHBHGF7aG4GK+hZ8P98dl9/0x7NuRnSB8pSw0FHB25OH4VpSMS7GF/XoMWnFtYjOrcJCb7MhtU1YjsPGL4uGY4KDPj4+HY9PTsejpKZJ7LFbLiWjrK4Z381za/e3P8PdGIpcNo5G8bp9vc3nE7F4VzgKqprwzRxXXHt7nESalo6y0YGJphKORnYcQ7NAiA9OxsFYQwnv9jKvezDZEGCL0tpmHIvigWEYbA1Mh6mWEmZ69K551kCx1FXBDPfWJl2VXcRLPO6PmxngcthYPabr3gcmmkr4dq4brr09DpOdDLA9KANjvwvEb9fTUNcseNLhPxVW7o/E20fvQ01RDvuWe+P4+pFSL1b3BIfNwjxPU9x4Zzw2z3JBTnkDFu4Mw7cXk3v0+G2BGVBTkMOLgzB+wNlYHUIR8/D6Qdoq6lvw9b9JCPj+Jn68koKaJr60hyRW22empY4ynnOTzc/MwWJDgC3K6ppxRMz3MdDalDW7vAHfzHaFjqoC9q3whqOROtYfvIdbaWUPj2toEWDTqThY66rg1Qn9c70wlFDBmhBCyIBLKaqBjoq8TG9lnTXcBAs8zXApvkjiheTHc8t8rHTQyBciPl/2tjsGp7aeZPW0c/xA8rHSxu4XvZFZVo8X90Y8vGAIyyzH2gNRsNZTwZ8rfR42Hhtjp4t5nqbYEZSJxMeyEE9F50EgYjBfTCyCj5U2NJW5uNRFETC5qAY7gzMxZ7hJv03EyHHYGPFYjnVcXjVe3BuBBTvuILu8HptnOuPGO+Mxz7NvzffI4LZytBVcTNTx6ZkEVDd0fwF9NIoHOTYLs4abDMDoBpa8HBvblozAEl9zHI7Ihf//AvHNv0ntiojhmeX4OzwXq8ZYwc20/SpqdUUuprsY4WxMARrFRBO1Ccssx55bWVjkbYab743HCz7mHSa9+orNZmG+lyluZ5SB91gO/bbADKSX1OHL2S5DOtJnpLUORphrYntQJoLTyhCdW4V142wk9m/cH14Zb4uGFiH2hWb36PiCqkacjM7DIm+zHp8XWemq4NcXhuPiG2PhZ62DH66mwv+7QOwOyUQTv/P369MusaAGQamleG2CLc69OgYBDvqDbrJOXo6NZX4WCHovAHNHmGJHcAbu5lR2+Zj0kjr8G1+IZSMtBqQ/i6Q92nhRmmqa+Pjxwd/arpBMaChx8euNdIzdEohtN9PR0CJbk0ZBqaWIz6/By+NtKHbiCflaacPLQgs7gjI6NFJOKKjGzuBMLPAyfbhDRl2Ri79W+sBaVwVr/op6eO7+09VU8Coa8c0cV9ot0AOy+01PCCFkyEoprsMwGYwDedx4ez3UNgtwn1cl0edtyy37dq4bOGwWvK1at3L3pqHeQAlJK4W1rorMdq8eY6eLP5aMQGJBDVbsi8Tt9DKs2h8JE00lHFzt22Gb9EfTHaGpzMUHJ2MhFLV2tmIYBkciefC00IKtvmqH15DjsDHZ0QDXk0o6nKQCrduLPzgRB3UlLj5+zql/ftEHfK20kVJci8jsCqw/cBcztt5CbF4VNk13QNB7AVg20rJfmh6RwUGOw8a3c9xQ2dC6+qsrfKEIJ+/lY5KjAXRVZXfy8Ekocjn4cpYrrr8zDtNdjLAzJBNjvwvET1dTUVbXjA9PxsFMWwlvTR4m9vHzvcxQ2yzApYRCsfc38YX48GQczLWV8dkM5365+Jzn2Zqdf/xu3sOfpRbXYtvNdMzyMEaAvew0L+4PLBYLr06wRX5VI14/HA19NQXM9+y+n4A02Ruq4ZkHTbpqe7DycmdwJhgGWNtFNmpnHAzVsetFL5x6ZRScjNTx5YUkjP/fTRwKz5HJXVvSdjSKB3kOGytHWw363UdK8hx8PtMZRuqK+OBErNjzkzbbgzKgIMfuUxNZWWCqpQR1RTmpNV5sbBFie1AG/L8LxK/X0zDWThdX3vTH6Q2jcf61MRhhronvLqXA/7ub2H87C80C2Zg0+j0wHcYaij3qwUK6xmKxsGGCLQqqm3D6kcaoAqEIH5yIg5ayfIcYKC0VeRxY5QsjTUWs3B+Jg2E52HMrC4t9zXsc5fO0oysaQgghA0okYpBWXCuzcSCPGmWjCzYLCH5kK9eTasstWz/O5mFumb6aIqx0VWQux7pZIERYZoVMrq5+1ERHA/z6wnBE51Ziye5w6Kop4O81fmKLcFoq8vhshjNi86qx73YWAOBebhUySuvbNVt83FQXQ9Q2CxCa0fG98NedbMTwqvDZDCdoq/RvjmhbvuX87XdwK70Mb06yQ8j7AVjrb9PvTY/I4OBiooE1Y61xJIqH0HTxn10iEYM/Q7NRXt+CBd5D/0LWQkcFPy70wOU3/THGVhe/XE/DyG+uI7OsHl/Pdu00m97XShvm2so4Gpkn9v7fbqQh68Fz9Nffn6mWMsbY6uL43TyIRAyEIgYbT8RCVUEOn/TzBJmsCLDXh5OROqob+Vgz1npQrEp7dYItapoE2Hc7u8vjSmubcTgiF7OHm8DkCfKAh5tr4eBqXxxe4wcTLSV8dCoeE38IQoyEJ9wHs2aBEKdj8jHZ2QBa/fxdPVBUFeTw5WwXpJXU4Y+bGWKPyatswOnofLzgYw6dQTo52dbXJEEKOxEDk0vg/79AfHsxGR5mmjj/2hj8sdQTdg8W3riYaGDfCh8cXz8SNnoq+L9ziZjwfRCOROZCIMVJo/DMckRmV2KtvzUtZJCQ8cP04GKijj+CMh4uetl3Oxtx+dX4/Hlnsb0E9NQU8PdqP2iryOPj0/HQVVXAB9McBnrogxa9cwkhhAwoXmUDGlqEcBgEBWsNZS7czTQRktZ1dnFPdZVb5mOpjcjsSogenADJgrvZlWjkC2Uuv1qc6a5G+GmhB/ystXFotS8M1BU7PfY5NyNMdNDHD1dSwatowNFIHpTlOXi2i3y/0ba6UJHn4HJC+1iQvMoG/O9yCsbb64ltiiZpHuaaGDdMD+v8rRHyfgDenDTsYeQJIW3enGQHCx1lfHgqrl08AMMwuJ5UjGd/u4UvLyTBw0wT/oPg71tShhmoYfsyT5x7dQzG2+tj3TjrLj/f2GwWFniZ4k5mOXLL20dyJBbUYEdQJuZ5mmJMP0/qzfcyQ35VI25nlOFgWA6ic6vw6QynQVt86i0Wi4VN0x0x0loHi33NpT2cHnEz1cQ0F0P8dC0VZ2LyOz1uz60s8IUivDy+96urxRlpo4Pj60di33JvNPKF+O5Sz/KNnwZXE4tR1cDHQjHRX4PZBAcDPO9ujK2BaUgr7pjxvCMoEywW2jWVHYycjdWRXFQ7oEXgJr4QG0/EQkOJi2PrR2L/Ch+4mIhvCO5lqY1/1vrhwCof6KrKY+OJOEz+KRhn7xdI5dx+a2A6dFXlschncHxmDgYsFgsbxtsiq6weF+IKkVvegB+upmCSowGmuxp2+jhDDUUcWu2LkdY6+H6+O9TpvL3HqGBNCCFkQKXIeMPFx/nb6eE+r6pHebDd6Sq3zNtKG9WNfKSWyEZDGaB1ZTmXwxoUzYgAYKaHCf5ZOxKmWl3Hl7BYLGye5QI2C3j/eCzOxxbgWVcjqHaRA6vI5SDAQR9XEorbRYm0NeX8cpbLgORgKshx8OdKH3w43XHIrBAjkqfI5eCbOa7IKW/Az9dam4yGppdh7h+hWPVnFOqbBfh5oQdOvDzqqcw6dzXVwK4XvfDhNMduj53raQoWCzh2979GS0IRgw9OxkJTmYuPpnf/HE/qGScDaChxsS0wA99dSob/MD3M8hh6ueNdGWOni8Nr/QZVXvePCzzgbamNt4/eF9sDobqBj4NhOZjuagRrvY5xVH3FYrEQ4KCPl0ZaIDSj42TL0+poVB6MNRQx2la2d431xacznKCiIIcPTsa1K46W1DThSBQPc0eYwkij7yv4ZYGziTqaBSJklNYP2Gsev5uHktpm/N8M54c73LrCYrEw1k4PpzeMxs5lnpDnsPH64WhM/zUEVxOLwTADU7i+z6tCSFoZVo0ZHDtSBpMpzoaw1VfFtsB0bDoVBzk2G5tnOXd7DWCmrYzDa/3gP+zpmN2C0wAAIABJREFUWSQgCU/fGSohhJAeaxYIkV5SJ9HnbCtY2w2CDGsA8B+mCxED3BYTBSFObF4VLicUdbgdicztMrfM16r1RLgnOda1TfyH/479KSStFCPMtQZVgaCnjDWVsHGaA+5klqO+RYgF3t2vuJrqYojy+hZEPYhuOXu/AIEppXhvin23RXJCBtooG10s9DLDrpBMLNh+B4t3h6Ogqglfz27NdJ413ISaMPWAkYYS/O30cPxu3iNbgLMQm1eNz2Y4D8jEkSKXg1kexriTWQ4RA3w1QBNk5MkoyXOwd7k3XE008Nrhe7iZUtLu/v2h2ahrFmBDgG0nz/Bk2iZbjj8y2dKdxIKah+/znmhoEeB6UrHY857rScUy0wCyoKoRIWmlmOdpOiQ/93RVFfDJs064m1OJQ+E5D3+++1YWBEIR1vchH13WDHTjRb5QhO1BGXA308Ro294t3GCxWHjG2RAX3xiLXxZ5oIkvxJq/ojB7W+iA9Kv5PTAd6opyWOpHq6sljc1m4ZXxNkguqsWt9DJsnOYw6CeDZNnQuwIlhBAiMW/+E4PLCUU49cpouJtpSuQ5k4trYaat1OVqVlnibqoJNQU5hKSVYrqrUZfHFlY3Yva20E4v9ow1FDvNLTPVUoKhuiIisirw4kjLLl/n63+TcSyKh/Ovj4GDoXqPfo/euptTgYSCGmycOnRz1pb6WuDc/QJUN/LhZaHV7fHj7fUhL8fGpYQi2Bmo4fNzifAw0+z2/4sQadk03RE3U0uQUVqHT55zwhJfc1pt1QcLvc3wyqF7CEkrhY2eKn64koqJDvp4zq3r7wRJWuRjjgNhOXhvir3MNsElHakqyOHPlT5YvCsM6w7cxb4V3hhlo4v6ZgH2hWZhkqP+w34WktY22XLsbh7emDSs20LtxbhCvHzoHuYMN8H38927bUpY1yzAsj3hiM7tPCf7w2kOWCcDxdLjd/PAMK3xOkPVnBEmOB2Tjy2XUjDR0QBKXA4OhuVghrsxLHVVpD28J2atqwIFOTYSCmowZ0T/v97ZmALkVTbisxndr57tDJvNwkwPk/9n777j6qzP/4+/P+ewN4QVAgkEyCJ7kKGJSdxaV61aZx3R1tHWbmtrh/Xrt/qzte1XO6x11FGNdVfrjiauJCSSPSBAcoAM9jjMc879+wMSSdiEAwRez8eDh8l9f+77XCiJhzef+7p0zrTRenFDof70fo6uenStVv94meLDO29ddzye/nyv3tl+UN89NZ2WcV5y/owEPbwqV9Eh/rqSlitedWKkBQCAAffW1gP679YDstuMfvLiZr3+7ZPl2w+Pju86UKOJcd755swbfOw2LUobpdW7S2VZVpdvWl9s3YH31A2ZHQ7fGxsV1OmbR2OMMlOi9HleWZev42x06bXsIrk8ln7y4ha9dPOift8t1Ohy6ycvbtGYiEBds3Bcv957KLHZjP55/Xw1ezw9+mYkxN9HS9Kj9fbWA6qqa1Z1fbPuu3j6sNytheEhPMhX73zvFPnZbQzlPA6nTo5VZJCvVmY5VNPgks1IvxngXc6TR4fp8ztPVWyod0IOeE94oK+eumG+LvvbZ1rxZJaeuiFTG/ZWqLKu2Wu7qw87/MOWj3NLdUoXj6JblqWHVuUq2M+ul74okr+vXfde1PnXeH2TWyueXK/NhVW6/2vTlZHQ/n3dj17YrDe3Hhj0wNrjsfTCBocWpY4a1j/sMcbo3oum6YwHV+uuV7YqY0y46prcumWpd7/GBoqP3abJo8MGZIe1x2Ppzx/malJ8qE6dFHvc9/O12/T1zLE6KS1aSx/4UI+sztMvzuv/obn/3lCon7+yVcsnxXr975aRzMdu02u3nSx/H1u3P9jD8aElCACgnar6Zv3i1a2aPDpM/3f5LO08UKNHVucd930bXW7llzpPiIGLbS2ZEKOiynrllXbeN8/jsbQyq1ALxkdpcXqMMhLC2310t9NhXkqUDtU0al955/0m39yyX84mt65ZOE6bHJV68tOCvn5anfrLh3uUe6hW91w0dVi2A2kr0M/eq+EnZ2bEq7iqQS99UaRblqaeML3YMXKFB/oSVh8nfx+7Lpw1Rm9uOaA1OS2PACdEDPwjwITVJ66oYL8jA4GvfWy9/vZRnk5KG6VZY7t/uud4tP1hS1c+3FWibcXV+uX5Gbp1War+tW6f7v7P9g577ja63Prm0xu0Nr9cv790hi6dm9The55zp4/WJkel9lfVe+vT65HP88rkKK/XZT1o/XWiS4oK0g/OmKD3dx7SXz7M1RlT4obV+5SMhDBtK672ei/ot7Yd0J4Sp25ZltavgWRSVJAumJGgZ9ftVVltY7/dV5L+s7lYP/73Jp2cFq0/Xzlbfj5Efd4U7O8zImeADDT+DQNAF1btPKQF976v1zcVD3YpA+q+t3aqtLZR9108TedMG61zpsXrj+/nKK/k+PpZ7znklNtjacIJ9uZ5SXrLrqQ1u0s6XbM2v1z7yuuO6xuiw32s13bR3+6FrEKlRAfr1+dnaPmkWD3wzi45ugi4pZbHdi9/5HPd8MT6bvtJ5hys0cOrcnXhzAQtm3j8u0qGm9Mmx8luM0qNCdaty9m9AowUh/9unz02QlfNH75PnsB7YsMC9MyK+QoL9FWZs2lAdkAe/mHLu9sOqsLZ1OGaw7urx0QE6qJZY/TDMybq+pNS9PgnBXrgnV1HrW12e3Tbs19o9e4S3ffV6bqgi+GfZ02NlyS9s+1g/31CfbAyy6HQAB+dmRE/qHUMlGsXJWt6Yria3ZZuG2bvUzISwlXT4JKj3Hs/BLEsSw+vylVKdLDO7aYVYF/csixVjS6PHvskv9/u+e72g7r9uWzNGRepR66ZQ+svDBsE1gDQiU9yS/XNpzeozNmo259v6eU8EqzNK9Oza/fphpNTND2xpW/1r87PUICPTT89Zvp4b+06WC1JJ9wO66SoICWPCtKanM4HL76Q5VCov4/Oyuj7m9u0mBBFBPlqfSeBdV5JrdYVlOuSuYkyxrQ8ki7pZ69s7XS3SX2TW9c/sV7rCsr1wa5DuvnpDWpyeTpc6/FY+smLmxXi76O7vtL/jyoOB5HBfvrzlbP1yDVz5e/DNwTASDEpPkx/uGymHrpiNo8Ao88SIgL1wrcW6v8un6WFHQxg9obL5iWpye3RK9lFHZ7/PK9cG/ZW6JunjJev3SZjjO76ymRdMX+sHl61Rw99kCNJcnssfX/lJr27/aB+fX5Gt8OKU2NClB4bore2Dt7756r6Zv136wFdMDNhxIR4PnabHrl6rh65es6R9/HDxeHWM95sC3L4aYObT0n1Ssu3tNhQnZURr39+uldV9c3Hfb/Vu0t06zMblTEmXI9dO09BfsP7yUiMLATWANCB9QXlWvFkllJGBeuDHyxtmfD+7BftJrwPNw3Nbv30pS1KigrU906fcOR4bGiAfnbuZK3NL9fz3TxW2pVdB2rlazdKOQGHvyxOj9FneWUdhr3VDc16c+t+nT8z4bgevbfZjOYlR2ldQceB9QsbCmW3GX1tdqIkaUxEoH505kSt3l2iV7PbPwXQ0OzWTU9laX1BuR68bKb+58JpWrWrRN/51xdyudt/Hk+v3auN+yp111emaFSIf58/j+HuzIx4pcaEDHYZAAbYhbPGDEorEAwvCRGBOm9GwoD1QJ8UH6bpieF6fr2jwx9uHx4edmmbgYTGGN1zwdSWAYzv7NbfV+fpjhc36/VNxfrp2ZP0jUXJPXrts6bGa21+mco72d3tba9tKlajy6PL5o6swWjx4QE6YxjuKJ8YHyq7zWhbcbVX7n/4aYOE8ABdOKvzpweO163L0lTT6NLTn+89rvt8nlemm57KUlpsiP55XSZDFjHsEFgDwDE2OSp13ePrNTo8QE+vmK+kqCA9eX2m0uNC9M2nNuizPWWDXaLXPPRBrvJKnbr3omntfkJ/6dwkLRw/Sve+uUMHqxs6vL6qrll/ej9Hf3wvR1V17XcN7DpQrdSYkH4Z3jjQFqdHq67JrQ17K9qde31TsRqaPUd9s9dXmclR2ltW1+7fscvt0YsbCrV0Qoxiw77sY3r1wmTNGhuhX7++7ah+eC2P7W7UmpxS3XfxdJ0/I0FXzB+rX3xlit7adkA/eGGT3G12yxdX1uu+/+7U4vRoXeTFN+kAAGBgXTI3STsP1Ghr0dFBX7ajUh/nlurGxSntdiDbbEb3f226zp02Wv/z5g69sKFQ3z01vVdDFM/MiJfHkt7bPjhtQV7IcmhSfKimjjlxhn2jcwG+dqXHhnhth/WXTxukerUH9NQx4Vo6MUb/+DhfdU2uPt1ja1GVbnhivRIjg/TUDZkKDyKsxvBz4iUGAOBFO/ZX65rH1iky2FfP3DhfMaEtu0wPT3gfGxWkG55c32FoeaLbsb9af/1ojy6enajF6e0nyRtjdO9Xp6nJ5dEvX9121Dlno0sPfZCjxfd/oN+/u1sPvrdbJ9//gR76IEfOxi/fiO06UHPCDn9ZmDpKPjajNTnt+1ivzCrUxLhQTU8MP+7XyWztY73umLYgH+0u0aGaRl1yTChutxndd/F01Ta6dM8bOyS1hNu3P5et93Yc0m8uyDgqSL/+5BT9+KyJejW7WD97uaXFi2VZuuuVrfJY0r0XTRuwXV8AAMD7zp+RIH8fW7vhiw99kKvwQF9duaDjvuw+dpsevGymLs9M0g/PmKDbT0vv1etmJIQpMTJQbw1CW70d+6u1ubBKl81L4n3NMDKldfCiNxx+2mAgBnTetixN5c4m/Wtd759cbXJ59MMXNik0wFfPrJjPU5EYtgisAaBV7qFaXfXoWgX52fXsigUaHX70Y79HT3hfpy2F3uufNtDcHkt3vLhZ4YG++vm5kztdlxIdrNtPm6C3th3QW1v3q6HZrX98nK8l96/SA+/sVmZKlN78zmL997uLNT9llB54Z7eW3L9Kj67JU0lNo4qrGk7YwDo0wFezx0Zq9TGB9a4DNdrkqNSl/fQNUUZCmIL87Fp/TFuQlVkORYf46dTJ7QchTogL1c1L0/TyF0VatfOQfvziZr2xZb9+ds5kXb0wud36W5am6TvL0/Tceofu/s92vb55v97feUg/OGOCkqKCjvtzAAAAQ0d4oK/OnhqvV7KLjgxf3nmgWu/tOKjrTkpWiH/nfW/9fGz6369O123L03v9PscYo7My4vVxTqlqGo6/X29vrMxyyM9u04VdDIbEiScjIVyHahp1qKbjpz376vDTBis6eNrAG+YmR2l+SpQeWb1Hja6uB6If65HVe7TzQI1+c+FUxbV56hIYbgisAUDSvrI6Xfno5zLG6JnWNiAdaTvh/erH1g7J0PpQdYO293LnwROfFmhTYZV+eX6GIoP9uly7YnGKpowO089f2aplD3yo3/xnuybGh+qlWxbp0W/M05SEME0eHaZHvzFXL92ySJNGh+qeN3Zo+e8+lHTiDVxsa3F6tLYWVR/VemNllkO+dqMLZyb0y2v42G2aMy7yqB3WpbWNen/HIV00a0yn7VRuXZaq1Jhg3fRUll7aWKTvnz5BNy4Z3+nrfO/0CbpxcYqe+LRAP1iZrRmJ4brupJR++RwAAMDQcuncJNU0uI4MEX941R4F+9l1bQ/7UffVWVPj1eT2aNWu9k+oeUtdk0uvfFGk0zPiun1fixPLl4MX+3eX9cOrWp42uKqTpw284bblaTpY3agXN3Q8ELUje0pq9acPcnXu9NE6fUqcF6sDBh+BNQBIeuCdXaprdOuZFfM1vpthagkRgfrXjQsU4GPX+Q9/rO8/n619ZXUDVGn3vvPcF/raXz/t8YCbqvpm/eHd3Vo6MUbnTR/d7Xpfu033XTxd1fUuxYcH6NkV8/XsjQs0e2xku7Wzx0bqmRUL9OyN85UeG6IAX5umjjn+thmDZfGEllYpH+eWSmp5JO/lL4p02uS4fn0cb15ylHYdrFFlXct/w5c3Fsnlsbrske3vY9d9F0+XMUY3L03Vt5endfkaxhjdec5kXbNwnOw2o//96nSvTEMHAACDb8H4UUqKCtTz6x3KL3Xqjc3FumrhOEUEeTfQnT02UjGh/np7q/fbgjS5PHrq871a+v8+VEVds66cP7KGLY4EU1oD695uzunK3jKn3t1+UN9Y1PXTBv3t5LRozUgM118/2tPhMPRjeTyWfvrSFgX62vWr8zIGoEJgcA3cn0YAGKI8Hktrckp0ekZcj9tVjB0VpP9+d7H++tEePfFpgV7bVKzL5iXp28vTFR8+eI9mZRWU6/O8lp25j3+Srx+cMbHba/75aYFqGl360ZkTe/yo57TEcG246zSF+Pv06JpFqdF68eZRqm92txvmeCKZNiZcEUG+Wr27VBfMHKP3dxxUubNJl/Zzr7vMlChZlpRVUKFTJ8dqZZZDs8ZGKD2u66/PuclR2vSLMxTo17NHGY0xuvuCqfrp2ZN7fA0AADjx2GxGl8xJ0u/f3a1fvLpVvnabVpzc+ZNY/fm6Z0yJ08tftLQj8Ua7BbfH0stfFOkP7+1WYUW95iVH6v8un6X540f1+2thcIUF+GrcqKB+Hbz47w2Fshnp8kzv965uyxijW5el6aanNuj1zcW6aFZil+ufW+/Quvxy3f+16UfmLAHDGTusAYx424qrVVHXrCUdDBrsSmSwn356zmSt/vEyXZ45ViuzHDrl/63SPf/ZflTLiOPl8Vg9XvvQqlxFBftp6cQYPfFpgaq76RfobHTpsU/ytXxSrDISerfzOTTAt1e9DI0xJ3RYLbUMODwpLVprckpkWZZWZjkUHxbQ66+d7sxMipCv3Wh9QbmyHZXKOVTb5e7qtvoSPBNWAwAw/H1tTqKMkdbklOrr85IGLPQ6a2q86prcWpNT2qfrXW6PnI2udh+1jS69uWW/znjwI/3whU2KDPLTE9fN08pvLiSsHsYy+nHwottj6d8bCrVkQky7+UUD4bTJcZoYF6o/r9rT5fd8B6sb9L9v7tCi1FG6ZE7XwTYwXJzYyQEA9IPDQ/ROSovu0/VxYQH6zYVTddOS8frDezl67JN8/WvdPt1wcopWLBmvsADfPtf2+qZi3f2f7frn9ZmaPDqsy7Vbi6r04a4S/fCMCTplQqzOe+hjPfXZXt26rPPWEP9at08Vdc1drsHRlqRH643N+7U6p1Qf7S7RLUvT+r2VRoCvXTMSI7Q2v1zVDc0K9LXrKz1o1wIAANCZhIhALU6P0ae5pbrplNQBe90F40cpLMBHb2090Ku+u85Glx7/JF+PrM5TdYOr03XpsSH661WzdWZGfL8MwMbQlpEQrje3HFB1Q/NxfZ8lSWtySrS/qkF3fWVKP1XXOzab0S3LUvXd57J18zMb9KMzJyottv0Tlb94daua3B7de9E0vsYxYhBYAxjxVu8u0ZTRYce9yyQpKki/u3SGbl46Xg++m6M/fZCrJz/bq2+eMl7XLkru9e7i0tpG3fXqVlXWNeuOFzfrpVtO6jIYfXhVrkL9fXT1wmSFB/rqlAkxeuzjfF1/UkqHO2gbmt16ZHWeFo4fpTnj2vefRscWt+6mvvOlLfJYLbuVvGFeSpT+vjpPuYdqdc600Qo9zjfkAAAA/3PhVO0rr9OYiIHbTeprt+m0KXF6b8dBNbs9nQ6QPqyh2a2nP9+rv3y4R2XOJp02OU6ZKR2/V02MDNKZGfHM4RhB2vaxXnCcO+lXZjkUFeyn0yYP3gDD86YnaG9Znf720R69u/2gLpw1Rt87bYKSooIkSW9t3a+3tx3UHWdPUnJ08KDVCQw0AmsAI1pto0sb91Xohn7s4ZcWG6qHr5ytm4uq9Lt3dun+t3bpsY8LdNuyVF0+f6z8fXrWfuHu17fL2ejSd09N1x/fz9ETnxbohpNTOlybe6hGb207oFuWpio8sCXYvG15mi7562d6bv0+XXdS++te3FioQzWNevCymX3/ZEeghIhApcWGKPdQreanRHntjWNmSpT+8uEe1Ta6dOlcHv0DAADHLykq6EgQNpDOyojXSxuLtDavXCend/xUY7PboxeyCvWn93N0oLpBJ6dF6wdnTNCsDgZ7Y+TKaA2stx1nYF3ubNK72w/q6gXJ8vMZvG65NpvRd05N11ULxumvH+3Rk58W6PXW+UjfWJisu17dpoyEMK3o5PtAYLiihzWAEW1tXpma3ZaWdPLG+XhMHROux6/L1L+/tVCpMcH61evbtfyBj5RVUN7ttR/sPKjXNhXr1mVpuv20dC2fFKsH3t4lR3ldh+v//OEeBfjYdX2bYHpecpQyU6L0yOo8NbmOnjztcnv014/2aGZShBal0uOvtxa3fr1c1s/DFtuaMy5SxkjJo4KUmRLltdcBAADwtiUTYhToa9db2/a3O9cyNLFQp/3+I9358haNiQzUv25coKdXzCesRjuxoQGKCfXvcPDiweoG/eY/2/XU53u7vc8rXxSp2W3p0nlDY2NIVLCf7mydj3TZvCQ9t86h0x9crXJnk+67eLp8unkyARhu+IoHMKKt3l2iAF+b5iR7783w3OQoPXfTAj11Q6Z87UbXPr5e2Y7KTtfXNrr085e3Kj02RDcvTZUxRr+5cKpsRvrZK1tlWUcP5HCU1+nV7GJdnjlWo0KObmty27I07a9q0EsbC486/tqmYjnK63XbsjT6oPXB5ZljdcHMBJ091Xt9pcMCfHXL0lTdcfYk/hsBAIATWoCvXcsmxejtbQePDJezLEtvbd2vs/+4Wt97fpOC/Xz0+LXz9O9vLdRCNlSgC1MTwrS9zeDFcmeT7n1zh5bcv0r/+Dhfv3ptm7YWtQ+0Dzs8PH1GYrgmxXc9J2igxYUF6J4Lp2nVD5fqivljdde5kzV1TPhglwUMOAJrACPampxSLRg/qsdtOvrKGKPF6TF67qaFigr20zX/WNvhrgBJeuDtXdpf3aDfXjz9SF1jIgL147MmafXuEr2SXXTU+r9+tEd2Y3TTkvZtTRanR2t6Yrj+8tEeudwtu6w9Hkt//nCPJsWH6tTJsf38mY4ME+JC9cevz+qwN3h/+tGZk3SWF0NxAACAgXJmRrxKahq1cV+FPtpdogse/kTfenqj3B5LD18xW//59slaNimWH9SjWxkJ4co5VKvS2kY9+O5uLbl/lf6+Jk/nThut1287WZFBfvrJi5uPfP9zrC1FVdp5oEaXzPXe05LHKykqSPdeNE3XdtDaERgJCKwBjFiO8jrllTq1pHWI3kCIDw/QMyvmK9jfR1f/Y51yDtYcdX7D3go9+VmBrlkwrt0gxKsWjNOssRG6+/XtKqttlNTy2NsLWYW6eE6i4sMD2r2eMUa3LkvT3rI6vbGl5RHMt7cdUO6hWt3K7moAAAAMkOWTYuVnt2nFP7P0jcfWqdzZpAcumaG3b1+ic6ePlo3BieihjIQwuT2WFt+3Sn98P0eL06P1zu1L9PvLZmpaYrjuviBD24qr9Y+P8zu8fmWWQ/4+Np03I2GAKwfQUwTWAEasj3NLJUlLJvR//+quJEUF6dkbF8huM7ry0bUqKHVKkppcHt3x4mbFhwXoR2dNaned3WZ038XTVdvo0j1v7JAk/X11ntyWpZtPSe309U6fHKcJcSF6eFWuPB5LD63KVUp0sM6Zxs5dAAAADIzQAF+dOTVefnabfnNBhj74wVJ9bU4ivXnRa3PGRSrIz67MlCi9ftvJ+stVc5QeF3rk/NlT43X6lDg9+N5u7S1zHnVtQ7Nbr2YX65xpo48Mqwcw9PB/BgAj1urdJRodHqDUmJABf+2U6GA9s2K+mt0eXfnoWhVW1OkvH+5RzqFa3XPhVIX4+3R43YS4UN28NE0vf1GkV74o0jNr9+n8GQkaO6rzae82W8su690Ha/XzV7dqW3G1bj4lVXZ2sQAAAGAA/fGymVp756m6emGy/HyII9A3sWEB2vqrM/Xk9Zmalti+v7MxRr+5YKp8bTbd+fKWo2YAvbX1gGoaXLpk7tAYtgigY/wfAsCI5HJ79EluqRanRw9aW4wJcaF66ob5qm5o1tcf+VwPr8rVeTMSdOrkuC6vu3VZqlJjgnX789mqb3brlqWd764+7NxpozVuVJCeXbtPCeEBunDWmP76NAAAAIAesdkMLenQL7prIRMfHqCfnD1Jn+SW6d8bvhxA//x6h5KiArUghcGewFBGYA1gRNpcVKXqBpeWTBi4/tUdmTomXE9en6kKZ5OC/O365XlTur3G38eu+y6eLkk6KyP+qMffOuNjt+lbrW1DvnlKKjtaAAAAAAxrV2SO1bzkSN3zxg6V1DRqX1mdPssr06VzkuiZDgxxHT9zDgDD3OrdJTJGOil1YPtXd2T22Ei99u2T5fZYig7x79E1c5Oj9OLNi5Qe1/N2JpfOTVJ0iL+WTRzckB4AAAAAvM1mM/rfr07XOX9co1+/vk3jo4NljHTxHNqBAEMdgTWAEWlNTqmmjwlXZLDfYJciSX3qoz1nXGSv1tttRqdP6brdCAAAAAAMF2mxIfr28jT97t3dCvKza3F6jBIiAge7LADd4JlwACNOVX2zsh2VWpzOTmMAAAAAGM6+eUqqJsaFqq7JrcvmJg12OQB6wKuBtTHmLGPMLmNMrjHmjk7WXGqM2W6M2WaMebbN8W8YY3JaP77hzToBjCyf7SmT22MNev9qAAAAAIB3+fnY9Ievz9TlmWN12pTYwS4HQA94rSWIMcYu6WFJp0sqlLTeGPOaZVnb26xJl/RTSSdZllVhjIltPR4l6ZeS5kqyJG1ovbbCW/UCGDlW55Qo2M+uWWMjBrsUAAAAAICXTR4dpv/96rTBLgNAD3lzh3WmpFzLsvIsy2qS9JykC45Zc6Okhw8H0ZZlHWo9fqakdy3LKm89966ks7xYK4ARwrIsrd5dooWp0fK10xUJAAAAAABgKPFmWjNGkqPN7wtbj7U1QdIEY8wnxpjPjTFn9eJaGWNuMsZkGWOySkpK+rF0AMPV3rKAJbN5AAAgAElEQVQ6FVbUa8mE6MEuBQAAAAAAAMcY7O2FPpLSJS2VdLmkvxtjevyMvmVZj1iWNdeyrLkxMfSiBdC91TktP9xawsBFAAAAAACAIcebgXWRpLbjVxNbj7VVKOk1y7KaLcvKl7RbLQF2T64FMMK53B41uty9umb17lIlRQVq3KggL1UFAAAAAACAvvJmYL1eUroxJsUY4yfp65JeO2bNK2rZXS1jTLRaWoTkSXpb0hnGmEhjTKSkM1qPAYAkye2xdMWja3XBQ5+ooblnofXB6gZ9kluqxekxMsZ4uUIAAAAAAAD0ltcCa8uyXJJuU0vQvEPSSsuythlj7jbGnN+67G1JZcaY7ZJWSfqRZVlllmWVS/qNWkLv9ZLubj0GAJKkpz4r0Lr8cu08UKM/r8rt0TW/eHWrPJalmxaP925xAAAAAAAA6BMfb97csqw3Jb15zLFftPm1Jen7rR/HXvuYpMe8WR+AE1NRZb3uf3uXTpkQo6hgP/35wz06Z/poTYoP6/Sat7bu19vbDuqOsycpOTp4AKsFAAAAAABATw320EUAJ4Cf/Huz/rtl/2CXIUmyLEs/f3mLJOl/Lpqqu74yRWGBvrrjxS1ye6wOr6mqb9Zdr25TRkKYVpycMpDlAgAAAAAAoBcIrAF0qcLZpOezHPr9u7vV8lDE4HptU7FW7SrRD8+YqMTIIEUF++mX501RtqNS//ysoMNrfvvfHSp3Num+i6fLx85fewAAAAAAAEMVyQ2ALm0rrpYk5RyqVbajclBrKXc26devb9eMpAh9Y1HykePnz0jQ0okx+n9v71JhRd1R13y2p0z/WufQipNTNHVM+ABXDAAAAAAAgN7wag9rACe+bcVVkiR/H5tWZhVq1tjIbq9pcnn0j4/z5Wx0dXh++eRYze7BfY51zxvbVV3frPsunia7zRw5bozRPRdO1RkPrtZdr2zVY9fOkzFGDc1u3fnyFo2NCtLtp03o9esBAAAAAABgYBFYA+jStuJqjYkI1ILxo/T6pmLd9ZXJCvLr+q+O59fv031v7ZTNtITJbXksS39fk6fHr52nRWnRPa5j9e4SvbSxSN9entbhcMXEyCD96MyJ+vXr2/XapmJdMHOM/vR+jvJLnXpmxXwF+tl7/FoAAAAAAAAYHATWALq0rbhKUxLCdNm8JL24sVD/3XJAF89J7HR9s9ujv36Up1ljI/TSzYvaBdblziZ9/ZHPtOKfWXrqhkzNGRfVbQ11TS7d+fIWjY8J1q3L0jpdd83CZL2aXaxfv75d0SH++tvqPF0yJ1En9SIYBwAAAAAAwOChhzUwwjS7PartpFXHseqaXMordSojIUzzkiOVPCpIK7McXV7zyhdFKqqs123L0tqF1ZIUFeynp1fMV1xYgK59bL22FFZ1W8fv39mtwop6/far0xXg2/lOabvN6L6Lp6u6vlnXPLZOkUG++tm5k7v/RAEAAAAAADAkEFgDI0hJTaPO/MNqXfvYuh6t37G/WpYlZSSEyxijS+YmaW1+uQpKnR2ud3ss/eXDPZo8OkzLJ8V2et/Y0AA9s2K+woN8dfVja7XzQHWH63YeqNaN/8zSox/n64r5Y5WZ0v1u7InxobplaarcHku/PC9DEUF+PfpcAQAAAAAAMPgIrIERosLZpKseXau8Eqc27KtQVV1zt9dsK24JkjMSWnpGf21OomxGemFDx7us/7t1v/JKnbp1WWqHu6vbSogI1LMrFijAx66rHl2rPSW1R87llzr1nX99obP/uEaf7ynT90+foF98ZUpPP1XdftoEvfu9JTpvRkKPrwEAAAAAAMDgI7AGRoCq+mZd/dha5Zc59Z3labIsKWtvebfXbSuqVlSwn0aHB0iS4sICtHRirP69oVAut+eotZZl6eFVezQ+JlhnTx3do7rGjgrSMzfOlyRd+fe1WptXpjte3KzTfv+R3t1+UN86JVVrfrJM3zk1vctWIMey2YzS40J7vB4AAAAAAABDA4E1MMw5G1267vF12nWgRn+9arZuWZYmP7tN6/J7EFjvr1JGQthRu6UvnZuog9WNWpNTetTaD3Ye0o791br5lFTZbV3vrm4rNSZET6+YrwaXW5c98rle2likqxeM00c/XqqfnDWJlh4AAAAAAAAjiM9gFwDAexqa3VrxZJayHZV6+IrZWj4pTpI0PTFc6wq6DqybXB7tPlCr605OPur48klxGhXsp5VZDi1r7VNtWZYeWpWrMRGBunDWmF7XOSk+TM+smK//bN6vqxaM05iIwF7fAwAAAAAAACc+dlgDw1Sjy61vPrVBn+eX6XeXztDZ075s05GZEqUthVWqa3J1en3OoRo1uT3KSAg/6rifj00XzRqj93YcVFltoyTpsz1l+mJfpb51ynj52vv210pGQrh+ctYkwmoAAAAAAIARjMAaGIYsy9J3/5Wtj3aX6N6LpumiWYlHnZ+XEiWXx1L2vspO73HswMW2LpmbpGa3pZe/KJIkPbQqVzGh/rpkblI/fhYAAAAAAAAYaQisgWFofUGF3tp2QD86c6Iuzxzb7vyccZEyRlrbRR/r7cXVCvazK2VUcLtzE+NDNSMpQiuzHNq4r0Kf7inTjYtTejUYEQAAAAAAADgWgTUwDK3McijE30fXnZTc4fmwAF9NGR2m9V30sd5WXKXJo8Nk62SA4mVzk7T7YK1++MImRQT56sr54/qjdAAAAAAAAIxgBNbAMFPT0Kw3Nu/XeTNGK8iv87mq85KjtHFfhZpcnnbnPB5L24urO2wHcthXZoxWgK9NeSVOXbcoRcH+zHAFAAAAAADA8SGwBoaZNzbvV32zW5d20096fkqUGpo92lpc1e5cQZlTziZ3u4GLbYUF+Oq86QkKDfDRtYuSj7dsAAAAAAAAgMAaGG6ez3IoPTZEM5Miulw3NzlKkrSugz7WhwcuTulih7Uk/fqCDL19+xKFB/n2sVoAAAAAAADgSwTWwDCSc7BGX+yr1KVzk2RMx72nD4sJ9df4mGCt7ySw9rUbTYgL7fIeQX4+SogIPK6aAQAAAAAAgMMIrIFhZGWWQz42o4tmj+nR+szkKK0vKJfHYx11fFtxlSbEhcrPh78iAAAAAAAAMHBIo4Bhotnt0Usbi3Tq5FhFh/j36JrMlChVN7i062DNkWOW1f3ARQAAAAAAAMAbCKyBYeKDnYdU5mzSZfO6HrbY1rwO+lgfqG5QmbOpy4GLAAAAAAAAgDcQWAMDbMf+aj23bl+/33fleodiQ/21JD2mx9ckRgYqITxA6wq+DKy3FbUMXGSHNQAAAAAAAAYagTUwwJ74pEB3vrxFDc3ufrvnweoGrdp1SBfPSZSPved/rI0xmpcSpXX55bKslj7W24qrZYw0eTSBNQAAAAAAAAYWgTUwwBwVdfJYUkGZs9/u+eLGQnks6dK5PW8HclhmSpRKahq1t6xOUsvAxZToYAX7+/RbfQAAAAAAAEBPEFgDA8xR0RIM5x6q7Zf7WZalF7IKlZkcpZTo4F5fn3lMH+ttxdX0rwYAAAAAAMCgILAGBpDL7dH+ygZJ/RdYry+oUH6pU5fMTezT9WmxIYoK9tO6gnJVOJtUVFlP/2oAAAAAAAAMCgJrYAAdqG6Qy9PSK7q/AuuVWQ4F+9l17vTRfbreGKO54yK1Lr9c2/czcBEAAAAAAACDh8AaGECO8npJUrCfvV8C69pGl97YvF/nzUhQkF/fe05npkRpX3mdPth5SJJoCQIAAAAAAIBBQWANDKDD/atPSotWXqlT7tbd1n2xp6RWtz+Xrfpmty7pw7DFtjJTWvpYr1zvUEJ4gKKC/Y7rfgAAAAAAAEBf9H1LJoBeKyyvk81IiyfE6J3tB1VYUadxo3o3KLGwok5/fC9HL24sVICvXT84fYJmj404rrqmjA5TsJ9dNY0uzR8/6rjuBQAAAAAAAPQVgTUwgAor6jU6PFCT40MltfSx7mlgfaimQQ9/kKtn1+2TMUbXLkrRLctSFR3if9x1+dhtmj0uUmtySulfDQAAAAAAgEFDYA0MIEdFnRIjA5UWGyKpJbA+dXJct9c9/fle3fPGdjW7LV06N0nfXp6mhIjAfq0tMzmKwBoAAAAAAACDisAaGECO8nqdnB6tiCA/RYf49WjwomVZ+v27uzV5dJgevHSmkqN710Kkp86bkaD1eytoCQIAAAAAAIBBw9BFYIA0utw6WNOgxMiWndGpMSHKLek+sHaU16vc2aSLZyd6LayWpOToYP3z+kyFB/p67TUAAAAAAACArhBYAwOkqKJeliUlRQZJktJiQ5R7qFaWZXV5XXZhpSRpZtLxDVYEAAAAAAAAhjoCa2CAFFbUS5KSor4MrGsaXCqpaezyuux9lfL3sWli66BGAAAAAAAAYLgisAYGiKOiTpKUFNXSEqTt4MWubCqs1LQx4fK188cVAAAAAAAAwxsJGDBAHOX18rUbxYYGSGoTWHfRx7rZ7dHWoiragQAAAAAAAGBEILAGBoijok5jIgJltxlJUnxYgEL8fbrcYb1zf40aXR7NILAGAAAAAADACEBgDQyQwvK6I/2rJckYo9SY4C4DawYuAgAAAAAAYCQhsAYGiKOiXomRQUcdS40N6Tqw3lep6BA/JUYGers8AAAAAAAAYNARWAMDwNnoUrmz6cjAxcPSYkN0qKZR1Q3NHV6X7ajQjMQIGWMGokwAAAAAAABgUBFYAwOgsKJektrtsE6LaR282MEu6+qGZu0pcdIOBAAAAAAAACMGgTUwABzldZKkpMj2O6yljgPrzY4qSdLMsQTWAAAAAAAAGBkIrIEB4KhoDayjjt5hPTYqSH52m/Z0EFhvah24OD2RwBoAAAAAAAAjA4E1MAAc5fUK9LVrVLDfUcd97DYlRwd1uMP6i32VGh8TrPBA34EqEwAAAAAAABhUBNbAACisqFNSVGCHwxPTYkOUW3J0YG1ZlrIdlfSvBgAAAAAAwIhCYA0MAEdFfbuBi4elxYTIUV6nhmb3kWPFVQ0qrW0ksAYAAAAAAMCIQmANeJllWSosr2s3cPGw1NgQeSwpv9R55Fj2vpb+1QTWAAAAAAAAGEkIrAEvq6pvVk2jq93AxcPSYkMk6ag+1tmOCvn52DQpPmxAagQAAAAAAACGAgJrwMsc5fWS1GlLkNSYEBlzdGC9yVGljIQw+fnwRxQAAAAAAAAjB2kY4GWFFXWSpKSojluCBPjalRgZeGTwosvt0ZaiKtqBAAAAAAAAYMQhsAa8zNEaWHe2w1pqGby4p3WH9e6DtapvdhNYAwAAAAAAYMQhsAa8zFFer7AAH4UH+na6Ji02RHmlTrk9lrIdDFwEAAAAAADAyERgDXiZo6Ku04GLh6XFhqjJ5ZGjvE7ZjgpFBftpbDfXAAAAAAAAAMMNgTXgZY7yOiV10Q5EagmspZbBi5scVZqRGC5jzECUBwAAAAAAAAwZBNaAF1mWpcKKeiVGdjxw8bC0mFBJ0qbCSu0+VKMZtAMBAAAAAADACERgDXhRSW2jGl2ebluChAf5KjrEX69kF8my6F8NAAAAAACAkYnAGvAiR3m9JCkpqusd1pKUFht8ZD2BNQAAAAAAAEYiAmvAiwor6iSp2x7W0pd9rJNHBSkiyM+rdQEAAAAAAABDEYE14EWO8pbAOrEngXVMS2DN7moAAAAAAACMVATWgBcVVtQrOsRPgX72btemxbYMXiSwBgAAAAAAwEhFYA14kaOirke7qyVpbnKkrl2UrHOnJ3i5KgAAAAAAAGBo8hnsAoDhzFFerxk93DEd4GvXr87P8HJFAAAAAAAAwNDFDmvAS9weS8WV9UqKDBzsUgAAAAAAAIATAoE14CX7q+rl8lhKiupZSxAAAAAAAABgpCOwBryksKJekpTIDmsAAAAAAACgRwisAS9xlNdJkpJ6OHQRAAAAAAAAGOkIrAEvcVTUyxgpIYId1gAAAAAAAEBPEFgDXlJYXqfRYQHy8+GPGQAAAAAAANATJGmAlzgq6pTIwEUAAAAAAACgxwisAS9xlNczcBEAAAAAAADoBQJrwAvKaht1oLpBE+NCB7sUAAAAAAAA4IRBYA14wabCSknSzKSIQa4EAAAAAAAAOHEQWANekL2vUjYjTR0TPtilAAAAAAAAACcMAmvAC7ILqzQhLlTB/j6DXQoAAAAAAABwwiCwBvqZZVna5KikHQgAAAAAAADQSwTWQD/LL3Wqqr6ZwBoAAAAAAADoJQJroJ8dGbg4lsAaAAAAAAAA6A0Ca6CfZe+rVJCfXemxoYNdCgAAAAAAAHBCIbAG+lm2o1LTxoTLbjODXQoAAAAAAABwQiGwBvpRo8ut7furaQcCAAAAAAAA9AGBNdCPthdXq9ltaWYigTUAAAAAAADQWwTWQD/a5GDgIgAAAAAAANBXBNZAP8p2VCouzF+jwwMHuxQAAAAAAADghENgDfSjbEelZtAOBAAAAAAAAOgTAmugn1TWNamgrI52IAAAAAAAAEAfEVgD/ST7cP/qJAJrAAAAAAAAoC8IrIF+ku2olDHStDHhg10KAAAAAAAAcEIisAb6ySZHpdJjQxQa4DvYpQAAAAAAAAAnJAJroB9YlqVsRyXtQAAAAAAAAIDj4DPYBQBDRZPLo7P/uFqFFfUdnl+cHqO/XT1Hdptpd25feZ0q6po1g8AaAAAAAAAA6DMCa6DVvnKn9pQ4dcaUOKXEBB91rqy2Sf/eUKinPivQtSeltLuWgYsAAAAAAADA8SOwBlrllTglSbcuS2u3U9qyLJXUNOr+t3fp9Ix4jYkIPOp8tqNSAb42TYwLHbB6AQAAAAAAgOHGqz2sjTFnGWN2GWNyjTF3dHD+WmNMiTEmu/VjRZtz7jbHX/NmnYAkFZS1BNbJ0cHtzhlj9D8XTZUk/fzlLbIs66jz2Y5KTRsTLh87beEBAAAAAACAvvJaumaMsUt6WNLZkqZIutwYM6WDpc9bljWz9ePRNsfr2xw/31t1AofllzoVHeKn8EDfDs8nRgbph2dM1KpdJXptU/GR400uj7YVV9MOBAAAAAAAADhO3twOmikp17KsPMuymiQ9J+kCL74ecFzySpxKHtV+d3Vb31iUrBlJEfr169tV7mySJO08UK0ml0czkyIHokwAAAAAAABg2PJmYD1GkqPN7wtbjx3rYmPMZmPMv40xSW2OBxhjsowxnxtjLvRinYCklh3WKR20A2nLbjO67+Jpqq5v1j1vbJf05cDFGUnhXq8RAAAAAAAAGM4Gu+Hu65KSLcuaLuldSU+2OTfOsqy5kq6Q9AdjTOqxFxtjbmoNtbNKSkoGpmIMS7WNLh2qaVRKTNeBtSRNig/TzUtT9dLGIq3eXaJsR6WiQ/zbDWIEAAAAAAAA0DveDKyLJLXdMZ3YeuwIy7LKLMtqbP3to5LmtDlX1PrPPEkfSpp17AtYlvWIZVlzLcuaGxMT07/VY0QpKG0ZuDi+mx3Wh926LE3jY4J158tbtL6gXDOTImSM8WaJAAAAAAAAwLDnzcB6vaR0Y0yKMcZP0tclvdZ2gTFmdJvfni9pR+vxSGOMf+uvoyWdJGm7F2vFCJfXGlinRIf0aH2Ar12//ep0FVbUy1Fer5m0AwEAAAAAAACOm9cCa8uyXJJuk/S2WoLolZZlbTPG3G2MOb912XeMMduMMZskfUfSta3HJ0vKaj2+StJvLcsisIbXFJQ6ZYw0blRQj6/JTInSFfPHShIDFwEAAAAAAIB+4OPNm1uW9aakN4859os2v/6ppJ92cN2nkqZ5szagrfxSpxLCAxXga+/VdT8/d7JmJkZoYeooL1UGAAAAAAAAjBxeDayBE0VeqVMpPexf3VaQn48unZfU/UIAAAAAAAAA3fJmD2vghGBZlvJLavsUWAMAAAAAAADoPwTWGPHKnU2qbnARWAMAAAAAAACDjMAaI15+qVOSlBJDYA0AAAAAAAAMJgJrjHiHA+vx7LAGAAAAAAAABhWBNUa8/FKnfGxGYyICB7sUAAAAAAAAYEQjsMaIl1/q1NhRQfKx88cBAAAAAAAAGEwkdBjx8kudtAMBAAAAAAAAhgACa4xoHo+l/FKnUgisAQAAAAAAgEFHYI0RbX91gxpdHqVEhwx2KQAAAAAAAMCIR2CNEa2g1ClJ7LAGAAAAAAAAhgACa4xoeQTWAAAAAAAAwJBBYI0RLb/EqUBfu+LC/Ae7FAAAAAAAAGDEI7DGiJZfWquU6GAZYwa7FAAAAAAAAGDEI7DGiJZf6lRKDO1AAAAAAAAAgKGAwBojVpPLI0dFvcbTvxoAAAAAAAAYEgisMWI5Kurk9lgMXAQAAAAAAACGCAJrDFtujyWX29Pp+YJSpyQpmcAaAAAAAAAAGBIIrDEsHaxu0OkPfqSbn9nY6Zr81sCaliAAAAAAAADA0EBgjWGnrLZRVz66VnklTr27/aA2OSo7XJdX6lRkkK8igvwGuEIAAAAAAAAAHek2sDbG/M4YkzEQxQDHq6quWVf/Y50KK+r02LVzFR7oq4dW5Xa4Nr/ESf9qAAAAAAAAYAjpyQ7rHZIeMcasNcZ8yxgT7u2igL6oaWjWNY+vU+6hWj1y9VwtnxSnaxcl693tB7XzQHW79fmlTqVEhwxCpQAAAAAAAAA60m1gbVnWo5ZlnSTpGknJkjYbY541xizzdnFAT9U3uXXDE1naVlSlh6+crSUTYiRJ152UrGA/u/68as9R6+uaXDpQ3aDxMeywBgAAAAAAAIaKHvWwNsbYJU1q/SiVtEnS940xz3mxNqBHGprduumpLGXtLdeDl83U6VPijpyLCPLTVQvG6T+bi1XQOmRRkgpK6yRJyaMIrAEAAAAAAIChoic9rB+UtFPSOZLutSxrjmVZ91mWdZ6kWd4uEOiKx2Pptmc3ak1Oqe7/2gydNyOh3ZobFqfIx27TXz78cpd1fmt4TQ9rAAAAAAAAYOjoyQ7rzZJmWpb1Tcuy1h1zLtMLNQE9lrW3Qu/tOKQ7z5mkr81J7HBNbGiAvj4vSS99UajiynpJUn5prSQpOTpowGoFAAAAAAAA0LWeBNaVknwO/8YYE2GMuVCSLMuq8lZhQE+syy+TJF06N6nLdd88JVWWJT2yOk+SlFfq1OjwAAX5+XR5HQAAAAAAAICB05PA+pdtg2nLsiol/dJ7JWEkq210qdnt6fH6tfnlmhQfqoggvy7XjYkI1EWzxuhf6/appKZR+aVO2oEAAAAAAAAAQ0xPAuuO1rAtFf2qpKZRv3ptm2bf/a5++9+dPbrG5fZo494KzUuO6tH6m5emqtnt0T8+ziewBgAAAAAAAIagngTPWcaY30t6uPX3t0ra4L2SMJJU1TXrb6v36PFPCtTk9igyyE9vbT2gn587WcaYLq/dvr9azia3MlN6FliPjwnROdNG68lPC1Tf7CawBgAAAAAAAIaYnuyw/rakJknPt340qiW0BvqsttGl/3s/Ryff/4H+/OEenT4lTu99/xR999Q0FVXWq6Csrtt7rMsvl6QeB9aSdOuyNNU3uyWJwBoAAAAAAAAYYrrdYW1ZllPSHQNQC0aI9QXl+tZTG1TmbNJpk+P0gzMmaPLoMEnS4T3Va3JKug2U1+WXa9yoIMWFBfT4tSePDtNpk2P13o5DBNYAAAAAAADAENNtYG2MiZH0Y0kZko4kg5ZlLfdiXRimNjkqdd3j6xUb6q9HvzFXs8ZGHnU+OTpYY6OCtHp3qa5ZmNzpfSzL0vqCcp06Oa7XNfz83CmaFB+m5FEE1gAAAAAAAMBQ0pOWIM9I2ikpRdKvJRVIWu/FmjBMbS+u1jWPrVNksK+euXF+u7D6sMXp0fpsT6maXJ5O75V7qFYVdc29agdyWHJ0sH545kTZbF33yAYAAAAAAAAwsHoSWI+yLOsfkpoty/rIsqzrJbG7Gr2Se6hGV/9jrYL87Hp2xQKNDg/sdO3i9Bg5m9z6Yl9Fp2vWFbT2r07ufWANAAAAAAAAYGjqSWDd3PrP/caYc40xsySREqLHCkqduuLva2WM0TMr5ispKqjL9YvSRsluM1qTU9rpmnX55YoN9de4UV3fCwAAAAAAAMCJoyeB9T3GmHBJP5D0Q0mPSvqeV6vCsFFUWa8rH12rZrdHz6yYr/ExId1eExbgq1lJEVqTU9LhecuytC6/XPNSomQMbT0AAAAAAACA4aLLwNoYY5eUbllWlWVZWy3LWmZZ1hzLsl4boPpwAjtY3aAr/v65qhua9dQN8zUxPrTH1y5Oj9HmoiqVO5vanSusqNf+qgbN70P/agAAAAAAAABDV5eBtWVZbkmXD1AtGGbu/s92ldQ06onrMjV1THivrl08IVqWJX2S274tyLr8lv7V8+hfDQAAAAAAAAwrPWkJ8okx5iFjzGJjzOzDH16vDCc0l9uj1btLdN70BM0ZF9nr62ckRigswKfDtiDrC8oVFuCjiXE937ENAAAAAAAAYOjz6cGama3/vLvNMUvS8v4vB8PFpsJK1TS4tGRCTJ+ut9uMTk6P1pqcUlmWdVSv6nX55ZqXHCWbjf7VAAAAAAAAwHDSbWBtWdaygSgEw8vq3aUyRjopbVSf77E4PUZvbjmgPSW1Sott2U1dUtOovFKnLpuX1F+lAgAAAAAAABgiug2sjTG/6Oi4ZVl3d3QckKQ1OSWanhihiCC/Pt9jcXq0JOmj3aVHAuv1Ba39qxm4CAAAAAAAAAw7Pelh7Wzz4ZZ0tqRkL9aEE1xVfbOyHZVa0ho491ViZJDGxwQf1cd6XX65An3tmprQuyGOAAAAAAAAAIa+nrQE+V3b3xtjHpD0ttcqwgnv09xSeSz1uX91W0vSY/Tc+n1qdLnl72PXuvxyzRobIT+fnvysBQAAAAAAAMCJpC+pX5CkxP4uBP+/vXuPsuws7wP9e7v6qiu6tLBAd2hhCCgI9wg8SDJ38CXIDtjIeDIQO4swC2IIjicQsmwisnwNeBns4JCgATsGjH0hJSQAACAASURBVC8EjQ0GjAGJm1ELBEIC1EIWg4SgqyVQl0TduuqbP+qUKDXV3QXdp07tXc+zVq065zt77/NW7712nf711+/XH1fv3pvjtmzMY8980BEf65Idp2Zqdj7X3fat7JuazRe/sS8XaQcCAAAAAL20kh7WNyRpg6djSbYn0b+aZbXWcvXN4/nRh52STWNHPgv6Ceedkk1jlY/uHs/0/vm0llx0jsAaAAAAAProsIF1kp9a8nh/km+21vYPqR467ra7vpM7vj2ZFz/pYUfleMdu2ZgfOfukXHPz3myoysYNlQvPOumoHBsAAAAAWFtWMgX29CR3t9a+2lq7I8m2qnr8kOuio66+eWGBxCNdcHGpS3Zsz0137sv7v/CNPOaME7Nt89hROzYAAAAAsHasJLB+U5J7lzy/bzAG3+Oa3eM56+RjcvYpxx61Y/7YYPHGW/fep381AAAAAPTYSgLraq0t9rBOa20+K2slwjozs38+n/zKXbn0/KM3uzpJHnX6CTn52M1J9K8GAAAAgD5bSWB9a1X9clVtGny9LMmtwy6M0fi193whL3n7ZzKzf/773vez/9+3ct/MXC7Zsf2o1rRhQ+Xih5+aqmTn2QJrAAAAAOirlcyUfnGSNyT5j0lakg8ledEwi2J0PrZ7b27de1/m5lr+4PkXZuPYSv5NY8HVu8cztqHyow875ajX9fKn7chTH3laTjxm01E/NgAAAACwNhw2sG6t7Uly+SrUwhowPjGdM07alr+98Rv5lT//XF7/c4/N2IZa0b7X7N6bC898UE7YevRD5fO2H5fzth931I8LAAAAAKwdh50+W1Vvq6oHLXl+UlVdOdyyGIXJmblMTO/P8x9/Vn71mY/Ie67/el797huypIX5Qd1930xuuOOeXHr+0W0HAgAAAACsHytpCXJBa+3bi09aa9+qqguHWBMjsmdiKkmy/bgt+dmdZ2Zqdi5v/PtbsnXTWH79nz0qVQefaf3xW/amteSSHUd3wUUAAAAAYP1YSWC9oapOaq19K0mq6uQV7kfHjE9MJ0lOO2FrkuQVTz8/kzNz+R8f+8ds3TSWf/+sRxw0tL765vGcuG1TLjjjQcu+DgAAAABwOCsJnl+X5JNV9edJKslzk/zGUKtiJPYsBtbHb0mSVFVe/ZOPzOTsXP7oo1/Jlo0b8rKn7siGA3pat9Zyze69ufjhp6643zUAAAAAwIFWsujiH1fVriRPGQz989baTcMti1FYnGG9fRBYJwuh9Wsve3SmZufz+x/anQ/e9M38u2eenyc/4rT7Z1vfsufefGPflHYgAAAAAMAROeyii0nSWruptfYHSd6X5DlVdeNwy2IU9kxMZWxD5eRjNj9gfMOGyu8+94L83vP+ae6d3p9ffOuuPOdNn8gnvrI3SXL17oXvFwusAQAAAIAjcNgZ1lX1kCTPS/L8JI9J8ptJLh9yXYzA+MR0Tj1u8/e0/EgWQuufufCM/NQFD8m7dn0tb/zQLXn+f/+HPPHhp2Tf5P6ct/3YnHHSMSOoGgAAAADoi4POsK6qF1XVh5N8JMkpSX4pyZ2ttf/UWrthlepjFe2ZmM5px2895DabxjbkFx5/dj7yq0/Kf/zJR+aLd07khjvuyaU7tq9SlQAAAABAXx1qhvUfJPlkkue31nYlSVW1VamKkdizbzo/dOKhA+tFWzeN5V9dcl4uv+is/PXnvp6nPPK0IVcHAAAAAPTdoQLr05P8bJLXVdUPJXlXkk2rUhUjMX7vdC4448Tva5/jtmzM5RedNaSKAAAAAID15KAtQVprd7XW/qi19mNJnprk20m+WVVfrKrfWLUKWRVz8y133Tud047fMupSAAAAAIB16qCB9VKttdtba69rre1MclmSqeGWxWq7677pzLdku8AaAAAAABiRQ7UEWVZr7eYkVwyhFkZoz77pJMn2wyy6CAAAAAAwLCuaYU3/jU8sBtZmWAMAAAAAoyGwJsl3A2s9rAEAAACAUTlsS5Cqetwyw/ck+Wprbf/RL4lR2DOx0JbcDGsAAAAAYFRW0sP6vyZ5XJLPJ6kkj05yY5ITq+r/aq19YIj1sUrGJ6ZzwtaN2bppbNSlAAAAAADr1Epagnw9yYWttZ2ttR9JcmGSW5M8PcnvDLM4Vs+eiemcdoIFFwEAAACA0VlJYH1+a+3GxSettZuS/HBr7dbhlcVq2zMxne3HaQcCAAAAAIzOSlqC3FhVb0ryzsHz5yW5qaq2JJkdWmWsqvGJ6Vx41oNGXQYAAAAAsI6tZIb1C5PckuTlg69bB2OzSZ48rMJYPa217JmYymkWXAQAAAAARuiwM6xba5NJXjf4OtC9R70iVt290/szNTuf7QJrAAAAAGCEDhtYV9UTk7wmydlLt2+tnTe8slhNeyamkySnHW/RRQAAAABgdFbSw/otSf5tkuuSzA23HEZhz76FwNoMawAAAABglFYSWN/TWnvf0CthZMbvXZxhLbAGAAAAAEZnJYH1h6vqd5P8VZLpxcHW2meGVhWras++qSRmWAMAAAAAo7WSwPrxg+87l4y1JE85+uUwCuP3Tmfzxg05cdumUZcCAAAAAKxjhw2sW2tPXo1CGJ3xfdPZftyWVNWoSwEAAAAA1rGDBtZV9X+01v5nVb1iuddba68fXlmspj0T09qBAAAAAAAjd6gZ1scOvh+/zGttCLUwIuMT0zn7lGNGXQYAAAAAsM4dNLBurf23wcO/a619fOlrVfXEoVbFqtozMZWd55w06jIAAAAAgHVuwwq2eeMKx+igmf3z+dZ3ZnPa8VtHXQoAAAAAsM4dqof1jyb535NsP6CP9QlJxoZdGKtj773TSZLTTtDDGgAAAAAYrUP1sN6c5LjBNkv7WO9L8txhFsXq2TOxEFhvP05gDQAAAACM1qF6WH80yUer6q2tta8mSVVtSHJca23fahXIcI1PmGENAAAAAKwNK+lh/ZtVdUJVHZvkC0luqqpfHXJdrJI9E1NJku3HC6wBAAAAgNFaSWD9qMGM6p9O8r4k5yb5F0OtilUzPjGdquRULUEAAAAAgBFbSWC9qao2ZSGwvqq1NpukDbcsVsueiemcfMzmbBpbyaUAAAAAADA8K0kp/1uS25Icm+Tqqjo7Cwsv0gN79k1rBwIAAAAArAkHXXRxUWvtDUnesGToq1X15OGVxGoav1dgDQAAAACsDYedYV1VD66qt1TV+wbPH5XkBUOvjFUxvm9KYA0AAAAArAkraQny1iTvT/KQwfObk7x8WAWxelprGb93Oqcdv3XUpQAAAAAAHDywrqrFdiGnttbelWQ+SVpr+5PMrUJtDNm3vzOb2blmhjUAAAAAsCYcaob1pwff76uqU5K0JKmqJyS5ZyUHr6pnVdWXq+qWqnrlMq+/sKrGq+r6wde/WvLaC6pq9+BLC5Ih2DMxnSQ5TWANAAAAAKwBh1p0sQbfX5HkqiQPq6qPJ9me5LmHO3BVjSX5wyRPT3J7kmur6qrW2k0HbPpnrbWXHrDvyUl+PcnOLATl1w32/dYKfiZWaFxgDQAAAACsIYcKrLdX1SsGj9+d5L1ZCLGnkzwtyecPc+yLktzSWrs1SarqnUkuS3JgYL2cZyb5YGvt7sG+H0zyrCTvWMG+rNCeiakk0RIEAAAAAFgTDtUSZCzJcUmOT3JsFsLtsSTHDMYO56FJvrbk+e2DsQM9p6o+X1V/UVVnfj/7VtWLqmpXVe0aHx9fQUksdf8M6xMsuggAAAAAjN6hZljf2Vq7Ysjv//8meUdrbbqq/nWStyV5ykp3bq29Ocmbk2Tnzp1tOCX2156J6WzbNJZjN4+NuhQAAAAAgEPOsK5DvLYSdyQ5c8nzMwZj92ut3dVamx48/R9JfmSl+3Lk9kxM57QTtqTqSE81AAAAAMCRO1Rg/dQjPPa1SXZU1blVtTnJ5VlYvPF+VXX6kqfPTvLFweP3J3lGVZ1UVSclecZgjKNofGLKgosAAAAAwJpx0JYgiwse/qBaa/ur6qVZCJrHklzZWruxqq5Isqu1dlWSX66qZyfZn+TuJC9cfO+qem0WQu8kueJI6+F77ZmYzg//0ErakQMAAAAADN+helgfsdbae5O894CxX1vy+FVJXnWQfa9McuUw61vvxiemc+mO7aMuAwAAAAAgyaFbgtBjU7NzmZjan+1aggAAAAAAa4TAep3as29hrUuBNQAAAACwVgis16nxe6eSxKKLAAAAAMCaIbBep8ywBgAAAADWGoH1OjV+70JgfdrxW0dcCQAAAADAAoH1OrVn33Q2VHLysZtHXQoAAAAAQBKB9bq1Z2Iqpx63JWMbatSlAAAAAAAkEVivW+MT0/pXAwAAAABrisB6ndozMZ3TBNYAAAAAwBoisF6nxiemLbgIAAAAAKwpAut1aG6+Ze+9WoIAAAAAAGuLwHoduvu+mcy35LQTBNYAAAAAwNohsF6HbrpzX5Lk7FOOHXElAAAAAADfJbBeh665eTybN27IReecPOpSAAAAAADuJ7Beh67ZvTcXnXNytm0eG3UpAAAAAAD3E1ivM9+4Zypf/uZELtlx6qhLAQAAAAB4AIH1OnPN7vEkySU7to+4EgAAAACABxJYrzPX7N6bU4/bkkeefvyoSwEAAAAAeACB9ToyP9/ysVv25tIdp6aqRl0OAAAAAMADCKzXkRu/vi933zeTS87XvxoAAAAAWHsE1uvI1YP+1Rc/XP9qAAAAAGDtEVivI9fsHs+jTj8h24/fMupSAAAAAAC+h8B6nbhven+u++q3tAMBAAAAANYsgfU68alb78rsXMulO7QDAQAAAADWJoH1OnHN7r3ZumlDdp5z0qhLAQAAAABYlsB6nbh693iecN4p2bJxbNSlAAAAAAAsS2C9Dtz+re/k1vH7col2IAAAAADAGiawXgeu2b03SXLpDgsuAgAAAABrl8B6Hbhm93hOP3FrHn7acaMuBQAAAADgoATWPTc33/Kx3XtzyY5TU1WjLgcAAAAA4KAE1j33udu/nX1T+/WvBgAAAADWPIF1z11z895UJRc/XP9qAAAAAGBtE1j33DW7x3PBQ0/MScduHnUpAAAAAACHJLDusX1Ts/ns176tHQgAAAAA0AkC6x77xC13ZW6+5ZId2oEAAAAAAGufwLrHbrjj29m4ofK4s08adSkAAAAAAIclsO6x+6bncszmsWwac5oBAAAAgLVPktljU7Nz2bppbNRlAAAAAACsiMC6xyZn57Jts8AaAAAAAOgGgXWPTc7MZZsZ1gAAAABARwise2xq/7yWIAAAAABAZwise2zKDGsAAAAAoEME1j2mhzUAAAAA0CUC6x6bnJ3L1k1OMQAAAADQDdLMHpucmdPDGgAAAADoDIF1j03N6mENAAAAAHSHwLrHBNYAAAAAQJcIrHuqtWbRRQAAAACgUwTWPTUzN5/5Fj2sAQAAAIDOEFj31NTMfBKBNQAAAADQHQLrnpqcnUsSPawBAAAAgM4QWPfU/YH1ZqcYAAAAAOgGaWZPTZlhDQAAAAB0jMC6pxZnWOthDQAAAAB0hcC6p6ZmzLAGAAAAALpFYN1TZlgDAAAAAF0jsO6p7y66KLAGAAAAALpBYN1Tk1qCAAAAAAAdI7Duqan980m0BAEAAAAAukNg3VP3L7qoJQgAAAAA0BEC6566f9HFjU4xAAAAANAN0syempydy+axDdk45hQDAAAAAN0gzeypyZm5bNnk9AIAAAAA3SHR7Kmp2blss+AiAAAAANAhAuuempqds+AiAAAAANApAuuemjTDGgAAAADoGIF1T03OzmerwBoAAAAA6BCBdU9NzZhhDQAAAAB0i8C6pyZn57J1k9MLAAAAAHSHRLOnJi26CAAAAAB0jMC6p6Zm5/SwBgAAAAA6RWDdU1OzelgDAAAAAN0isO6pSYsuAgAAAAAdI7DuodaaHtYAAAAAQOcIrHtoZm4+8y16WAMAAAAAnSKw7qGpmfkkAmsAAAAAoFsE1j00tX8uSfSwBgAAAAA6RWDdQ5Mzg8B6s9MLAAAAAHSHRLOHJmfNsAYAAAAAukdg3UOLgbUe1gAAAABAlwise2hqRmANAAAAAHSPwLqHtAQBAAAAALpIYN1DU7PzSZJtmwXWAAAAAEB3CKx7yAxrAAAAAKCLBNY9ZNFFAAAAAKCLBNY9tLjoopYgAAAAAECXCKx76P4Z1hudXgAAAACgOySaPTQ5O5dNY5WNY04vAAAAANAdEs0empqd078aAAAAAOgcgXUPTc3OZZvAGgAAAADoGIF1D03OzFlwEQAAAADoHIF1D02aYQ0AAAAAdJDAuocmZ+ezRWANAAAAAHSMwLqHpmbmsm2TUwsAAAAAdItUs4em9msJAgAAAAB0j8C6hyy6CAAAAAB00VAD66p6VlV9uapuqapXHmK751RVq6qdg+fnVNVkVV0/+PqjYdbZN5Ozc9lqhjUAAAAA0DEbh3XgqhpL8odJnp7k9iTXVtVVrbWbDtju+CQvS/IPBxziK621xw6rvj6bmtUSBAAAAADonmHOsL4oyS2ttVtbazNJ3pnksmW2e22S304yNcRa1pXJGYE1AAAAANA9wwysH5rka0ue3z4Yu19VPS7Jma21v1lm/3Or6rNV9dGqumS5N6iqF1XVrqraNT4+ftQK77LWmpYgAAAAAEAnjWzRxarakOT1SX5lmZfvTHJWa+3CJK9I8vaqOuHAjVprb26t7Wyt7dy+fftwC+6I2bmW+RaLLgIAAAAAnTPMwPqOJGcueX7GYGzR8UkeneQjVXVbkickuaqqdrbWpltrdyVJa+26JF9Jcv4Qa+2Nydm5JDHDGgAAAADonGEG1tcm2VFV51bV5iSXJ7lq8cXW2j2ttVNba+e01s5J8qkkz26t7aqq7YNFG1NV5yXZkeTWIdbaG1ODwFoPawAAAACgazYO68Cttf1V9dIk708yluTK1tqNVXVFkl2ttasOsfulSa6oqtkk80le3Fq7e1i19snkzCCw3jyybi8AAAAAAD+QoQXWSdJae2+S9x4w9msH2fZJSx7/ZZK/HGZtfTVphjUAAAAA0FGm4fbMYmC9RWANAAAAAHSMwLpn9LAGAAAAALpKYN0zAmsAAAAAoKsE1j0zOTOfJNm2WWANAAAAAHSLwLpnLLoIAAAAAHSVwLpnFgPrrQJrAAAAAKBjBNY9MzWzGFg7tQAAAABAt0g1e2bKDGsAAAAAoKME1j0zOTuXTWOVTWNOLQAAAADQLVLNnpmcnTO7GgAAAADoJIF1z0zNzmWbwBoAAAAA6CCBdc9Mzsxl22aBNQAAAADQPQLrnpmcncvWjQJrAAAAAKB7BNY9MzU7n61mWAMAAAAAHSSw7pnJ2bls2+S0AgAAAADdI9nsGYsuAgAAAABdJbDuGYsuAgAAAABdJbDumcnZuWw1wxoAAAAA6CCBdc9MCawBAAAAgI4SWPfM1Oy8HtYAAAAAQCcJrHuktZZJiy4CAAAAAB0lsO6R2bmWuflm0UUAAAAAoJME1j0yOTuXJHpYAwAAAACdJLDukalBYK0lCAAAAADQRQLrHpmcGQTWm51WAAAAAKB7JJs9MrV/0BJkoxnWAAAAAED3CKx7ZHGG9VaLLgIAAAAAHSSw7pFJPawBAAAAgA4TWPeIRRcBAAAAgC4TWPfI5Mx8kmSbliAAAAAAQAcJrHtESxAAAAAAoMsE1j2y2BJkyyanFQAAAADoHslmj+hhDQAAAAB0mcC6RyZnFgLrrQJrAAAAAKCDBNY9Mjk7l01jlU1jTisAAAAA0D2SzR6ZnJ0zuxoAAAAA6CyBdY9Mzc7pXw0AAAAAdJbAukemZufNsAYAAAAAOktg3SOTM2ZYAwAAAADdJbDukcnZuWzdLLAGAAAAALpJYN0jk7Nz2bbJKQUAAAAAukm62SMWXQQAAAAAukxg3SOTM3PZpiUIAAAAANBRAusemdo/l60bBdYAAAAAQDcJrHtkcmbeoosAAAAAQGcJrHtED2sAAAAAoMsE1j3RWsukwBoAAAAA6DCBdU/MzrXMzTeLLgIAAAAAnSWw7onJ2bkkyVYzrAEAAACAjhJY98T0/YG1UwoAAAAAdJN0sycWZ1jrYQ0AAAAAdJXAuicE1gAAAABA1wmse2JyZtASxKKLAAAAAEBHCax7wgxrAAAAAKDrBNY9MSWwBgAAAAA6TmDdE1Oz80mSrQJrAAAAAKCjBNY9sdjD2gxrAAAAAKCrBNY9sdjDeutmpxQAAAAA6CbpZk/oYQ0AAAAAdJ3AuicWW4LoYQ0AAAAAdJXAuicmZ+eyaayyacwpBQAAAAC6SbrZE1Oz82ZXAwAAAACdJrDuicnZOYE1AAAAANBpAuuemJqds+AiAAAAANBpAuuemJwRWAMAAAAA3Saw7onJ2bls3SywBgAAAAC6S2DdE5Ozc9m2yekEAAAAALpLwtkT03pYAwAAAAAdJ7DuicnZuWwVWAMAAAAAHSaw7olJM6wBAAAAgI4TWPfE5My8RRcBAAAAgE4TWPfElBnWAAAAAEDHCax7QksQAAAAAKDrBNY9MDs3n7n5lm1aggAAAAAAHSaw7oHJ2bkkyZaNTicAAAAA0F0Szh6YmlkIrM2wBgAAAAC6TGDdA4szrPWwBgAAAAC6TGDdAwJrAAAAAKAPBNY9MDloCbJVSxAAAAAAoMME1j0wNTufxAxrAAAAAKDbBNY9MDVoCbJVYA0AAAAAdJjAugf0sAYAAAAA+kBg3QOLPawF1gAAAABAlwmse2BxhvXWzU4nAAAAANBdEs4emNISBAAAAADoAYF1D1h0EQAAAADoA4F1D0zOzmXjhsqmMacTAAAAAOguCWcPTM7MawcCAAAAAHSewLoHJmfnsnWzwBoAAAAA6DaBdQ9Mzc6ZYQ0AAAAAdJ7AugcmZwTWAAAAAED3Cax7YGq/liAAAAAAQPcJrHtgcmYuWzc6lQAAAABAt0k5e2Bqdi7bzLAGAAAAADpOYN0DkxZdBAAAAAB6QGDdAwJrAAAAAKAPhhpYV9WzqurLVXVLVb3yENs9p6paVe1cMvaqwX5frqpnDrPOrtuycSwnbNs06jIAAAAAAI7IxmEduKrGkvxhkqcnuT3JtVV1VWvtpgO2Oz7Jy5L8w5KxRyW5PMk/SfKQJH9XVee31uaGVW+X/d0rfmzUJQAAAAAAHLFhzrC+KMktrbVbW2szSd6Z5LJltnttkt9OMrVk7LIk72ytTbfW/jHJLYPjAQAAAADQU8MMrB+a5GtLnt8+GLtfVT0uyZmttb/5fvcFAAAAAKBfRrboYlVtSPL6JL9yBMd4UVXtqqpd4+PjR684AAAAAABW3TAD6zuSnLnk+RmDsUXHJ3l0ko9U1W1JnpDkqsHCi4fbN0nSWntza21na23n9u3bj3L5AAAAAACspmEG1tcm2VFV51bV5iwsonjV4outtXtaa6e21s5prZ2T5FNJnt1a2zXY7vKq2lJV5ybZkeTTQ6wVAAAAAIAR2zisA7fW9lfVS5O8P8lYkitbazdW1RVJdrXWrjrEvjdW1buS3JRkf5KXtNbmhlUrAAAAAACjV621UddwVOzcubPt2rVr1GUAAAAAAHAIVXVda23ncq+NbNFFAAAAAABYSmANAAAAAMCaILAGAAAAAGBNEFgDAAAAALAmCKwBAAAAAFgTBNYAAAAAAKwJAmsAAAAAANYEgTUAAAAAAGuCwBoAAAAAgDVBYA0AAAAAwJogsAYAAAAAYE0QWAMAAAAAsCYIrAEAAAAAWBME1gAAAAAArAkCawAAAAAA1gSBNQAAAAAAa0K11kZdw1FRVeNJvjrqOobs1CR7R10E65brj1Fx7TEqrj1GyfXHqLj2GBXXHqPk+mNU1vO1d3ZrbftyL/QmsF4PqmpXa23nqOtgfXL9MSquPUbFtccouf4YFdceo+LaY5Rcf4yKa295WoIAAAAAALAmCKwBAAAAAFgTBNbd8uZRF8C65vpjVFx7jIprj1Fy/TEqrj1GxbXHKLn+GBXX3jL0sAYAAAAAYE0wwxoAAAAAgDVBYA0AAAAAwJogsO6IqnpWVX25qm6pqleOuh76q6rOrKoPV9VNVXVjVb1sMP6aqrqjqq4ffP3EqGuln6rqtqq6YXCd7RqMnVxVH6yq3YPvJ426Tvqlqh6x5P52fVXtq6qXu/cxDFV1ZVXtqaovLBlb9j5XC94w+Az4+ap63Ogqpw8Ocv39blV9aXCNvbuqHjQYP6eqJpfcA/9odJXTdQe59g76e7aqXjW49325qp45mqrpg4Nce3+25Lq7raquH4y773HUHCJf8bnvMPSw7oCqGktyc5KnJ7k9ybVJfr61dtNIC6OXqur0JKe31j5TVccnuS7JTyf5uST3ttb+y0gLpPeq6rYkO1tre5eM/U6Su1trvzX4R7uTWmv/flQ10m+D37t3JHl8kn8Z9z6Osqq6NMm9Sf64tfbowdiy97lBePNvkvxEFq7J32+tPX5UtdN9B7n+npHk71tr+6vqt5NkcP2dk+SvF7eDI3GQa+81Web3bFU9Ksk7klyU5CFJ/i7J+a21uVUtml5Y7to74PXXJbmntXaF+x5H0yHylRfG575DMsO6Gy5Kcktr7dbW2kySdya5bMQ10VOttTtba58ZPJ5I8sUkDx1tVZDLkrxt8PhtWfglD8Py1CRfaa19ddSF0E+ttauT3H3A8MHuc5dl4S/YrbX2qSQPGvzlB34gy11/rbUPtNb2D55+KskZq14YvXeQe9/BXJbkna216dbaPya5JQt/L4bv26GuvaqqLEzOeseqFsW6cIh8xee+wxBYd8NDk3xtyfPbI0BkFQz+dfnCJP8wGHrp4L+lXKklA0PUknygqq6rqhcNxh7cWrtz8PgbSR48mtJYJy7PA//S4t7HajjYfc7nQFbbLyZ535Ln51bVZ6vqo1V1yaiKoteW+z3r3sdquSTJN1tru5eMue9x1B2QgvwAOgAAB/RJREFUr/jcdxgCa2BZVXVckr9M8vLW2r4kb0rysCSPTXJnkteNsDz67eLW2uOS/HiSlwz+C9/92kIvK/2sGIqq2pzk2Un+fDDk3seqc59jVKrq1Un2J/nTwdCdSc5qrV2Y5BVJ3l5VJ4yqPnrJ71lG7efzwIkK7nscdcvkK/fzuW95AutuuCPJmUuenzEYg6Goqk1ZuJn+aWvtr5KktfbN1tpca20+yX+P/5LHkLTW7hh835Pk3Vm41r65+F+hBt/3jK5Ceu7Hk3ymtfbNxL2PVXWw+5zPgayKqnphkp9K8guDvzxn0I7hrsHj65J8Jcn5IyuS3jnE71n3PoauqjYm+edJ/mxxzH2Po225fCU+9x2WwLobrk2yo6rOHcz8ujzJVSOuiZ4a9PB6S5IvttZev2R8ad+kn0nyhQP3hSNVVccOFqNIVR2b5BlZuNauSvKCwWYvSPKe0VTIOvCAWTbufayig93nrkryfw5WjX9CFhaFunO5A8APqqqeleT/TvLs1tp3loxvHyxEm6o6L8mOJLeOpkr66BC/Z69KcnlVbamqc7Nw7X16teuj956W5EuttdsXB9z3OJoOlq/E577D2jjqAji8wWrdL03y/iRjSa5srd044rLorycm+RdJbqiq6wdj/yHJz1fVY7PwX1VuS/KvR1MePffgJO9e+L2ejUne3lr726q6Nsm7quqXknw1CwujwFE1+EeSp+eB97ffce/jaKuqdyR5UpJTq+r2JL+e5Ley/H3uvVlYKf6WJN9J8i9XvWB65SDX36uSbEnywcHv4E+11l6c5NIkV1TVbJL5JC9ura100Tx4gINce09a7vdsa+3GqnpXkpuy0KbmJa21uVHUTfctd+211t6S7123JHHf4+g6WL7ic99h1OB/ewEAAAAAwEhpCQIAAAAAwJogsAYAAAAAYE0QWAMAAAAAsCYIrAEAAAAAWBME1gAAAAAArAkCawAAAAAA1gSBNQAAvVBVH66qZx4w9vKqetMh9vlIVe0ccl3vqKrPV9W/Heb7HPCeL6+qY5Y8f29VPegoHPexVfUTR3ocAAA4GIE1AAB98Y4klx8wdvlgfCSq6oeS/G+ttQtaa7+3im/98iT3B9attZ9orX37KBz3sUm+r8C6qjYehfcFAGCdEFgDANAXf5HkJ6tqc5JU1TlJHpLkmqp6U1Xtqqobq+o/LbdzVd275PFzq+qtg8fbq+ovq+rawdcTl9l3a1X9P1V1Q1V9tqqePHjpA0keWlXXV9UlB+zz1qp6Q1V9oqpurarnHuqHq6pfHbz/5xd/hqo6tqr+pqo+V1VfqKrnVdUvD37uD1fVhwfb3VZVp1bVOVX1pcF731xVf1pVT6uqj1fV7qq6aLD9RVX1ycHP8omqesTgz/WKJM8b/DzPq6qTq+p/DWr6VFVdMNj/NVX1J1X18SR/UlX/pKo+Pdjv81W141A/KwAA65fZDgAA9EJr7e6q+nSSH0/ynizMrn5Xa61V1asHr48l+VBVXdBa+/wKD/37SX6vtfaxqjoryfuTPPKAbV6yUEJ7TFX9cJIPVNX5SZ6d5K9ba489yLFPT3Jxkh9OclUWQvfvUVXPSLIjyUVJKslVVXVpku1Jvt5a+8nBdie21u6pqlckeXJrbe8yh3t4kp9N8otJrk3y/EENz07yH5L8dJIvJbmktba/qp6W5Ddaa8+pql9LsrO19tLB+70xyWdbaz9dVU9J8sdZmIWdJI9KcnFrbXKw3e+31v50EHyPHeTPAwCAdU5gDQBAnyy2BVkMrH9pMP5zVfWiLHz+PT0LYepKA+unJXlUVS0+P6Gqjmut3btkm4uTvDFJWmtfqqqvJjk/yb7DHPt/tdbmk9xUVQ8+xHbPGHx9dvD8uCwE2NckeV1V/XYWgvFrVvDz/GNr7YYkqaobk3xoEOrfkOScwTYnJnnbYCZ0S7LpIMe6OMlzkqS19vdVdUpVnTB47arW2uTg8SeTvLqqzkjyV6213SuoEwCAdUhLEAAA+uQ9SZ5aVY9Lckxr7bqqOjfJv0vy1NbaBUn+JsnWZfZtSx4vfX1Dkie01h47+HroAWH1kZhe8rgOutXCa7+5pIaHt9be0lq7OcnjktyQ5D8PZkB/P+85v+T5fL47oeW1ST7cWnt0kn+W5f+8Due+xQettbdnYQb3ZJL3DmZjAwDA9xBYAwDQG4Mg+cNJrsx3F1s8IQvh6T2DWcw/fpDdv1lVj6yqDUl+Zsn4B5L8m8UnVbVce49rkvzC4PXzk5yV5MtH8KMc6P1JfrGqjhu8x0Or6rSqekiS77TW/meS381CeJ0kE0mOP4L3OzHJHYPHL1wyfuBxl/7cT0qyt7X2PbPKq+q8JLe21t6QhX9UuOAIagMAoMcE1gAA9M07kvzTwfe01j6XhVYaX0ry9iQfP8h+r0zy10k+keTOJeO/nGTnYLHAm5K8eJl9/2uSDYO2Gn+W5IWttelltvuBtNY+MKj9k4P3+IssBMePSfLpqro+ya8n+c+DXd6c5G8XF138AfxOkt+sqs/mgW0EP5yF9ijXV9XzkrwmyY9U1eeT/FaSFxzkeD+X5AuDOh+dhV7XAADwPaq1dvitAAAAAABgyMywBgAAAABgTdh4+E0AAIDVUFWPSfInBwxPt9YeP4p6AABgtWkJAgAAAADAmqAlCAAAAAAAa4LAGgAAAACANUFgDQAAAADAmiCwBgAAAABgTfj/ATCg3JeGlio0AAAAAElFTkSuQmCC\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["from sklearn.ensemble import AdaBoostClassifier\n","\n","ada_best_estimator = AdaBoostClassifier(n_estimators=best_estimator,random_state=0)\n","ada_best_estimator.fit(X_train, y_train)\n","y_pred = ada_best_estimator.predict(X_test)\n","\n","from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n","print(confusion_matrix(y_test, y_pred))\n","print(classification_report(y_test,y_pred))\n","print(\"Accurecy: \",accuracy_score(y_test, y_pred))\n","result[(ada_best_estimator,1,'AdaBoostClassifier')]=accuracy_score(y_test, y_pred)"],"metadata":{"id":"ctzoGCmFo0In","colab":{"base_uri":"https://localhost:8080/"},"outputId":"2faec189-860b-4bdf-d672-43b45750ba57","executionInfo":{"status":"ok","timestamp":1671765397238,"user_tz":-360,"elapsed":5960,"user":{"displayName":"","userId":""}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[105  35  20   3]\n"," [ 41  92   6   6]\n"," [ 36  23  72  37]\n"," [  4   6  14 135]]\n","              precision    recall  f1-score   support\n","\n","           0       0.56      0.64      0.60       163\n","           1       0.59      0.63      0.61       145\n","           2       0.64      0.43      0.51       168\n","           3       0.75      0.85      0.79       159\n","\n","    accuracy                           0.64       635\n","   macro avg       0.64      0.64      0.63       635\n","weighted avg       0.64      0.64      0.63       635\n","\n","Accurecy:  0.6362204724409449\n"]}]},{"cell_type":"markdown","source":["\n","\n","---\n","\n","\n","\n","---\n","\n"],"metadata":{"id":"JQhATacCo1AD"}},{"cell_type":"markdown","source":["#Graddient Boosting"],"metadata":{"id":"FJybpt_UvCU0"}},{"cell_type":"code","source":["from sklearn.ensemble import GradientBoostingClassifier\n","from sklearn.model_selection import RepeatedStratifiedKFold\n","\n","gradBoost_default = GradientBoostingClassifier(random_state=0)\n","gradBoost_default.fit(X_train, y_train)\n","y_pred = gradBoost_default.predict(X_test)\n","\n","from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n","print(confusion_matrix(y_test, y_pred))\n","print(classification_report(y_test,y_pred))\n","print(\"Accurecy: \",accuracy_score(y_test, y_pred))\n","result[(gradBoost_default,2,'GradientBoostingClassifier')]=accuracy_score(y_test, y_pred)"],"metadata":{"id":"sgmvc8A_o18j","colab":{"base_uri":"https://localhost:8080/"},"outputId":"fec681b7-8a7a-482d-a908-4c6cd1ecdeac","executionInfo":{"status":"ok","timestamp":1671778218323,"user_tz":-360,"elapsed":5501,"user":{"displayName":"Rafsan Jany","userId":"08721334090885411304"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[125  11  16  11]\n"," [ 24 109   6   6]\n"," [ 24  15  98  31]\n"," [ 10   5  18 126]]\n","              precision    recall  f1-score   support\n","\n","           0       0.68      0.77      0.72       163\n","           1       0.78      0.75      0.76       145\n","           2       0.71      0.58      0.64       168\n","           3       0.72      0.79      0.76       159\n","\n","    accuracy                           0.72       635\n","   macro avg       0.72      0.72      0.72       635\n","weighted avg       0.72      0.72      0.72       635\n","\n","Accurecy:  0.721259842519685\n"]}]},{"cell_type":"code","source":["from sklearn.ensemble import GradientBoostingClassifier\n","from sklearn.metrics import accuracy_score\n","N=200\n","k_range = range (1,N+1)\n","scores={}\n","scores_list = []\n","for k in k_range:\n","  classifier = GradientBoostingClassifier(n_estimators=k,random_state=0)\n","  classifier.fit(X_train, y_train)\n","  y_pred=classifier.predict(X_test)\n","  scores[k] = accuracy_score(y_test,y_pred)\n","  scores_list.append(accuracy_score(y_test,y_pred))\n","  print(str(k)+\"/\"+str(N)+\" round completed......................... Accurecy: \"+str(accuracy_score(y_test,y_pred)))\n","\n","\n","\n","%matplotlib inline\n","import matplotlib.pyplot as plt\n","\n","plt.figure(figsize = (25,10))\n","plt.plot(k_range,scores_list)\n","plt.xlabel('Value of n_estimators')\n","plt.ylabel ('Testing Accuracy')\n","\n","\n","\n","print(\"The best n_estimators:\")\n","best_estimator=list(scores.keys())[scores_list.index(max(scores_list))]\n","print(best_estimator)"],"metadata":{"id":"9brp-qNgo-tX","colab":{"base_uri":"https://localhost:8080/"},"outputId":"2bff1472-7955-422c-ba2e-5adf8147a105"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1/200 round completed......................... Accurecy: 0.5622047244094488\n","2/200 round completed......................... Accurecy: 0.5779527559055118\n","3/200 round completed......................... Accurecy: 0.5858267716535434\n","4/200 round completed......................... Accurecy: 0.5858267716535434\n","5/200 round completed......................... Accurecy: 0.5968503937007874\n","6/200 round completed......................... Accurecy: 0.5952755905511811\n","7/200 round completed......................... Accurecy: 0.5937007874015748\n","8/200 round completed......................... Accurecy: 0.6031496062992125\n","9/200 round completed......................... Accurecy: 0.6047244094488189\n","10/200 round completed......................... Accurecy: 0.6094488188976378\n","11/200 round completed......................... Accurecy: 0.6141732283464567\n","12/200 round completed......................... Accurecy: 0.6110236220472441\n","13/200 round completed......................... Accurecy: 0.6141732283464567\n","14/200 round completed......................... Accurecy: 0.6267716535433071\n","15/200 round completed......................... Accurecy: 0.6157480314960629\n","16/200 round completed......................... Accurecy: 0.6125984251968504\n","17/200 round completed......................... Accurecy: 0.6204724409448819\n","18/200 round completed......................... Accurecy: 0.6173228346456693\n","19/200 round completed......................... Accurecy: 0.6204724409448819\n","20/200 round completed......................... Accurecy: 0.6188976377952756\n","21/200 round completed......................... Accurecy: 0.6188976377952756\n","22/200 round completed......................... Accurecy: 0.6188976377952756\n","23/200 round completed......................... Accurecy: 0.6283464566929133\n","24/200 round completed......................... Accurecy: 0.6330708661417322\n","25/200 round completed......................... Accurecy: 0.6283464566929133\n","26/200 round completed......................... Accurecy: 0.6362204724409449\n","27/200 round completed......................... Accurecy: 0.6393700787401575\n","28/200 round completed......................... Accurecy: 0.6440944881889764\n","29/200 round completed......................... Accurecy: 0.647244094488189\n","30/200 round completed......................... Accurecy: 0.647244094488189\n","31/200 round completed......................... Accurecy: 0.6456692913385826\n","32/200 round completed......................... Accurecy: 0.6488188976377953\n","33/200 round completed......................... Accurecy: 0.6535433070866141\n","34/200 round completed......................... Accurecy: 0.6535433070866141\n","35/200 round completed......................... Accurecy: 0.6535433070866141\n","36/200 round completed......................... Accurecy: 0.6598425196850394\n","37/200 round completed......................... Accurecy: 0.6645669291338583\n","38/200 round completed......................... Accurecy: 0.6661417322834645\n","39/200 round completed......................... Accurecy: 0.662992125984252\n","40/200 round completed......................... Accurecy: 0.658267716535433\n","41/200 round completed......................... Accurecy: 0.6645669291338583\n","42/200 round completed......................... Accurecy: 0.6598425196850394\n","43/200 round completed......................... Accurecy: 0.6724409448818898\n","44/200 round completed......................... Accurecy: 0.6692913385826772\n","45/200 round completed......................... Accurecy: 0.6724409448818898\n","46/200 round completed......................... Accurecy: 0.6755905511811023\n","47/200 round completed......................... Accurecy: 0.6724409448818898\n","48/200 round completed......................... Accurecy: 0.6724409448818898\n","49/200 round completed......................... Accurecy: 0.6724409448818898\n","50/200 round completed......................... Accurecy: 0.6787401574803149\n","51/200 round completed......................... Accurecy: 0.6787401574803149\n","52/200 round completed......................... Accurecy: 0.6803149606299213\n","53/200 round completed......................... Accurecy: 0.6850393700787402\n","54/200 round completed......................... Accurecy: 0.6866141732283465\n","55/200 round completed......................... Accurecy: 0.6866141732283465\n","56/200 round completed......................... Accurecy: 0.6834645669291338\n","57/200 round completed......................... Accurecy: 0.6834645669291338\n","58/200 round completed......................... Accurecy: 0.6850393700787402\n","59/200 round completed......................... Accurecy: 0.6881889763779527\n","60/200 round completed......................... Accurecy: 0.6850393700787402\n","61/200 round completed......................... Accurecy: 0.6850393700787402\n","62/200 round completed......................... Accurecy: 0.6881889763779527\n","63/200 round completed......................... Accurecy: 0.6960629921259842\n","64/200 round completed......................... Accurecy: 0.6976377952755906\n","65/200 round completed......................... Accurecy: 0.6992125984251969\n","66/200 round completed......................... Accurecy: 0.7007874015748031\n","67/200 round completed......................... Accurecy: 0.6976377952755906\n","68/200 round completed......................... Accurecy: 0.6929133858267716\n","69/200 round completed......................... Accurecy: 0.7007874015748031\n","70/200 round completed......................... Accurecy: 0.7007874015748031\n","71/200 round completed......................... Accurecy: 0.705511811023622\n","72/200 round completed......................... Accurecy: 0.7023622047244095\n","73/200 round completed......................... Accurecy: 0.7070866141732284\n","74/200 round completed......................... Accurecy: 0.705511811023622\n","75/200 round completed......................... Accurecy: 0.705511811023622\n","76/200 round completed......................... Accurecy: 0.7023622047244095\n","77/200 round completed......................... Accurecy: 0.7023622047244095\n","78/200 round completed......................... Accurecy: 0.7023622047244095\n","79/200 round completed......................... Accurecy: 0.7039370078740157\n","80/200 round completed......................... Accurecy: 0.705511811023622\n","81/200 round completed......................... Accurecy: 0.7039370078740157\n","82/200 round completed......................... Accurecy: 0.7086614173228346\n","83/200 round completed......................... Accurecy: 0.7070866141732284\n","84/200 round completed......................... Accurecy: 0.7133858267716535\n","85/200 round completed......................... Accurecy: 0.710236220472441\n","86/200 round completed......................... Accurecy: 0.7165354330708661\n","87/200 round completed......................... Accurecy: 0.710236220472441\n","88/200 round completed......................... Accurecy: 0.7133858267716535\n","89/200 round completed......................... Accurecy: 0.7118110236220473\n","90/200 round completed......................... Accurecy: 0.710236220472441\n","91/200 round completed......................... Accurecy: 0.7118110236220473\n","92/200 round completed......................... Accurecy: 0.7133858267716535\n","93/200 round completed......................... Accurecy: 0.7165354330708661\n","94/200 round completed......................... Accurecy: 0.7149606299212599\n","95/200 round completed......................... Accurecy: 0.721259842519685\n","96/200 round completed......................... Accurecy: 0.7275590551181103\n","97/200 round completed......................... Accurecy: 0.7149606299212599\n","98/200 round completed......................... Accurecy: 0.7181102362204724\n","99/200 round completed......................... Accurecy: 0.721259842519685\n","100/200 round completed......................... Accurecy: 0.721259842519685\n","101/200 round completed......................... Accurecy: 0.721259842519685\n","102/200 round completed......................... Accurecy: 0.7228346456692913\n","103/200 round completed......................... Accurecy: 0.7307086614173228\n","104/200 round completed......................... Accurecy: 0.7291338582677165\n","105/200 round completed......................... Accurecy: 0.7307086614173228\n","106/200 round completed......................... Accurecy: 0.7322834645669292\n","107/200 round completed......................... Accurecy: 0.7354330708661417\n"]}]},{"cell_type":"code","source":["from sklearn.ensemble import GradientBoostingClassifier\n","from sklearn.metrics import accuracy_score\n","N=13\n","k_range = range (1,N+1)\n","scores={}\n","scores_list = []\n","for k in k_range:\n","  classifier = GradientBoostingClassifier(max_depth=k,random_state=0)\n","  classifier.fit(X_train, y_train)\n","  y_pred=classifier.predict(X_test)\n","  scores[k] = accuracy_score(y_test,y_pred)\n","  scores_list.append(accuracy_score(y_test,y_pred))\n","  print(str(k)+\"/\"+str(N)+\" round completed......................... Accurecy: \"+str(accuracy_score(y_test,y_pred)))\n","\n","\n","\n","%matplotlib inline\n","import matplotlib.pyplot as plt\n","\n","plt.figure(figsize = (25,10))\n","plt.plot(k_range,scores_list)\n","plt.xlabel('Value of n_estimators')\n","plt.ylabel ('Testing Accuracy')\n","\n","\n","\n","print(\"The best Depth:\")\n","best_depth=list(scores.keys())[scores_list.index(max(scores_list))]\n","print(best_depth)"],"metadata":{"id":"JtO5QAkHpDAy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.ensemble import GradientBoostingClassifier\n","\n","gradBoost_estimator = GradientBoostingClassifier(n_estimators=best_estimator,random_state=0)\n","gradBoost_estimator.fit(X_train, y_train)\n","y_pred = gradBoost_estimator.predict(X_test)\n","\n","from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n","print(confusion_matrix(y_test, y_pred))\n","print(classification_report(y_test,y_pred))\n","print(\"Accurecy: \",accuracy_score(y_test, y_pred))\n","result[(gradBoost_estimator,2,'GradientBoostingClassifier')]=accuracy_score(y_test, y_pred)"],"metadata":{"id":"EFg4mMYepGXx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.ensemble import GradientBoostingClassifier\n","\n","gradBoost_depth = GradientBoostingClassifier(max_depth=best_depth,random_state=0)\n","gradBoost_depth.fit(X_train, y_train)\n","y_pred = gradBoost_depth.predict(X_test)\n","\n","from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n","print(confusion_matrix(y_test, y_pred))\n","print(classification_report(y_test,y_pred))\n","print(\"Accurecy: \",accuracy_score(y_test, y_pred))\n","\n","result[(gradBoost_depth,2,'GradientBoostingClassifier')]=accuracy_score(y_test, y_pred)"],"metadata":{"id":"oS_ycrCQpI09"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.ensemble import GradientBoostingClassifier\n","\n","gradBoost_all = GradientBoostingClassifier(n_estimators=best_estimator,max_depth=best_depth,random_state=0)\n","gradBoost_all.fit(X_train, y_train)\n","y_pred = gradBoost_all.predict(X_test)\n","\n","from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n","print(confusion_matrix(y_test, y_pred))\n","print(classification_report(y_test,y_pred))\n","print(\"Accurecy: \",accuracy_score(y_test, y_pred))\n","\n","result[(gradBoost_all,2,'GradientBoostingClassifier')]=accuracy_score(y_test, y_pred)"],"metadata":{"id":"GU8wNje3pJjR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","\n","---\n","\n","\n","\n","---\n","\n"],"metadata":{"id":"ThoTlhc4pRJT"}},{"cell_type":"markdown","source":["#Random Forest"],"metadata":{"id":"AgMT_U8gvM7F"}},{"cell_type":"code","source":["from sklearn.ensemble import RandomForestClassifier\n","rf_default = RandomForestClassifier(random_state=0)\n","rf_default.fit(X_train, y_train)\n","y_pred=rf_default.predict(X_test)\n","\n","\n","from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n","print(confusion_matrix(y_test, y_pred))\n","print(classification_report(y_test,y_pred))\n","print(\"Accurecy: \",accuracy_score(y_test, y_pred))\n","result[(rf_default,3,'RandomForestClassifier')]=accuracy_score(y_test, y_pred)"],"metadata":{"id":"-4GMunEvtWk2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score\n","N=150\n","k_range = range (1,N+1)\n","scores={}\n","scores_list = []\n","for k in k_range:\n","  classifier = RandomForestClassifier(n_estimators=k,random_state=0)\n","  classifier.fit(X_train, y_train)\n","  y_pred=classifier.predict(X_test)\n","  scores[k] = accuracy_score(y_test,y_pred)\n","  scores_list.append(accuracy_score(y_test,y_pred))\n","  print(str(k)+\"/\"+str(N)+\" round completed......................... Accurecy: \"+str(accuracy_score(y_test,y_pred)))\n","\n","\n","\n","%matplotlib inline\n","import matplotlib.pyplot as plt\n","\n","plt.figure(figsize = (25,10))\n","plt.plot(k_range,scores_list)\n","plt.xlabel('Value of n_estimators')\n","plt.ylabel ('Testing Accuracy')\n","\n","\n","\n","print(\"The best n_estimators:\")\n","best_estimator=list(scores.keys())[scores_list.index(max(scores_list))]\n","print(best_estimator)"],"metadata":{"id":"ve34YgestieE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score\n","N=150\n","k_range = range (1,N+1)\n","scores={}\n","scores_list = []\n","for k in k_range:\n","  classifier = RandomForestClassifier(max_depth=k,random_state=0)\n","  classifier.fit(X_train, y_train)\n","  y_pred=classifier.predict(X_test)\n","  scores[k] = accuracy_score(y_test,y_pred)\n","  scores_list.append(accuracy_score(y_test,y_pred))\n","  print(str(k)+\"/\"+str(N)+\" round completed......................... Accurecy: \"+str(accuracy_score(y_test,y_pred)))\n","\n","\n","\n","%matplotlib inline\n","import matplotlib.pyplot as plt\n","\n","plt.figure(figsize = (25,10))\n","plt.plot(k_range,scores_list)\n","plt.xlabel('Value of n_estimators')\n","plt.ylabel ('Testing Accuracy')\n","\n","\n","\n","print(\"The best Depth:\")\n","best_depth=list(scores.keys())[scores_list.index(max(scores_list))]\n","print(best_depth)"],"metadata":{"id":"eVfKbSTWtnny"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.ensemble import RandomForestClassifier\n","rf_estimator = RandomForestClassifier(n_estimators=best_estimator,random_state=0)\n","rf_estimator.fit(X_train, y_train)\n","y_pred=rf_estimator.predict(X_test)\n","\n","\n","from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n","print(confusion_matrix(y_test, y_pred))\n","print(classification_report(y_test,y_pred))\n","print(\"Accurecy: \",accuracy_score(y_test, y_pred))\n","result[(rf_estimator,3,'RandomForestClassifier')]=accuracy_score(y_test, y_pred)"],"metadata":{"id":"LMUwwEqUt2-T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.ensemble import RandomForestClassifier\n","rf_depth = RandomForestClassifier(max_depth=best_depth,random_state=0)\n","rf_depth.fit(X_train, y_train)\n","y_pred=rf_depth.predict(X_test)\n","\n","\n","from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n","print(confusion_matrix(y_test, y_pred))\n","print(classification_report(y_test,y_pred))\n","print(\"Accurecy: \",accuracy_score(y_test, y_pred))\n","result[(rf_depth,3,'RandomForestClassifier')]=accuracy_score(y_test, y_pred)"],"metadata":{"id":"NRybS4-nt_vO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.ensemble import RandomForestClassifier\n","rf_all = RandomForestClassifier(n_estimators=best_estimator,max_depth=best_depth,random_state=0)\n","rf_all.fit(X_train, y_train)\n","y_pred=rf_all.predict(X_test)\n","\n","\n","from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n","print(confusion_matrix(y_test, y_pred))\n","print(classification_report(y_test,y_pred))\n","print(\"Accurecy: \",accuracy_score(y_test, y_pred))\n","result[(rf_all,3,'RandomForestClassifier')]=accuracy_score(y_test, y_pred)"],"metadata":{"id":"G9p0fJyBtrdZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","\n","---\n","\n","\n","\n","---\n","\n"],"metadata":{"id":"G_DChNuquB92"}},{"cell_type":"markdown","source":["#XGB"],"metadata":{"id":"jRG4cBnKvZU2"}},{"cell_type":"code","source":["\n","\n","import xgboost as xgb\n","xgb_deafult = xgb.XGBClassifier(random_state=0)\n","xgb_deafult.fit(X_train,y_train)\n","y_pred = xgb_deafult.predict(X_test)\n","\n","\n","from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n","print(confusion_matrix(y_test, y_pred))\n","print(classification_report(y_test,y_pred))\n","print(\"Accurecy: \",accuracy_score(y_test, y_pred))\n","result[(xgb_deafult,4,'xgboost')]=accuracy_score(y_test, y_pred)"],"metadata":{"id":"sC1lAZeeuCw8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import xgboost as xgb\n","from sklearn.metrics import accuracy_score\n","N=250\n","k_range = range (1,N+1)\n","scores={}\n","scores_list = []\n","for k in k_range:\n","  xgb_classifier = xgb.XGBClassifier(n_estimators=k,random_state=0)\n","  xgb_classifier.fit(X_train, y_train)\n","  y_pred=xgb_classifier.predict(X_test)\n","  scores[k] = accuracy_score(y_test,y_pred)\n","  scores_list.append(accuracy_score(y_test,y_pred))\n","  print(str(k)+\"/\"+str(N)+\" round completed......................... Accurecy: \"+str(accuracy_score(y_test,y_pred)))\n","\n","\n","%matplotlib inline\n","import matplotlib.pyplot as plt\n","\n","plt.figure(figsize = (25,10))\n","plt.plot(k_range,scores_list)\n","plt.xlabel('Value of n_estimators')\n","plt.ylabel ('Testing Accuracy')\n","\n","\n","\n","print(\"The best n_estimators:\")\n","best_estimator=list(scores.keys())[scores_list.index(max(scores_list))]\n","print(best_estimator)"],"metadata":{"id":"YQYsfVO0uPMA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import xgboost as xgb\n","from sklearn.metrics import accuracy_score\n","N=250\n","k_range = range (1,N+1)\n","scores={}\n","scores_list = []\n","for k in k_range:\n","  xgb_classifier = xgb.XGBClassifier(max_depth=k,random_state=0)\n","  xgb_classifier.fit(X_train, y_train)\n","  y_pred=xgb_classifier.predict(X_test)\n","  scores[k] = accuracy_score(y_test,y_pred)\n","  scores_list.append(accuracy_score(y_test,y_pred))\n","  print(str(k)+\"/\"+str(N)+\" round completed......................... Accurecy: \"+str(accuracy_score(y_test,y_pred)))\n","\n","\n","%matplotlib inline\n","import matplotlib.pyplot as plt\n","\n","plt.figure(figsize = (25,10))\n","plt.plot(k_range,scores_list)\n","plt.xlabel('Value of n_estimators')\n","plt.ylabel ('Testing Accuracy')\n","\n","\n","\n","print(\"The best depth:\")\n","best_depth=list(scores.keys())[scores_list.index(max(scores_list))]\n","print(best_depth)"],"metadata":{"id":"ABex6e-3kxuX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import xgboost as xgb\n","xgb_depth = xgb.XGBClassifier(max_depth=best_depth,random_state=0)\n","xgb_depth.fit(X_train,y_train)\n","y_pred = xgb_depth.predict(X_test)\n","\n","\n","from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n","print(confusion_matrix(y_test, y_pred))\n","print(classification_report(y_test,y_pred))\n","print(\"Accurecy: \",accuracy_score(y_test, y_pred))\n","result[(xgb_depth,4,'xgboost')]=accuracy_score(y_test, y_pred)\n","print(xgb_depth)"],"metadata":{"id":"lfBp-uGXuaKY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import xgboost as xgb\n","xgb_estimator = xgb.XGBClassifier(n_estimators=best_estimator,random_state=0)\n","xgb_estimator.fit(X_train,y_train)\n","y_pred = xgb_estimator.predict(X_test)\n","\n","\n","from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n","print(confusion_matrix(y_test, y_pred))\n","print(classification_report(y_test,y_pred))\n","print(\"Accurecy: \",accuracy_score(y_test, y_pred))\n","result[(xgb_estimator,4,'xgboost')]=accuracy_score(y_test, y_pred)\n","print(xgb_estimator)"],"metadata":{"id":"_qBm-yTqzOsi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import xgboost as xgb\n","xgb_all = xgb.XGBClassifier(n_estimators=best_estimator,max_depth=best_depth,random_state=0)\n","xgb_all.fit(X_train,y_train)\n","y_pred = xgb_all.predict(X_test)\n","\n","\n","from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n","print(confusion_matrix(y_test, y_pred))\n","print(classification_report(y_test,y_pred))\n","print(\"Accurecy: \",accuracy_score(y_test, y_pred))\n","result[(xgb_all,4,'xgboost')]=accuracy_score(y_test, y_pred)"],"metadata":{"id":"zW-0PfT-zX3C"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#KNN"],"metadata":{"id":"K6_icFWdauSI"}},{"cell_type":"code","source":["from sklearn.neighbors import KNeighborsClassifier\n","knn_default = KNeighborsClassifier()\n","knn_default.fit(X_train, y_train)\n","y_pred=knn_default.predict(X_test)\n","\n","\n","from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n","print(confusion_matrix(y_test, y_pred))\n","print(classification_report(y_test,y_pred))\n","print(\"Accurecy: \",accuracy_score(y_test, y_pred))\n","result[(knn_default,5,'KNeighborsClassifier')]=accuracy_score(y_test, y_pred)"],"metadata":{"id":"6GALUBYbaz1z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.metrics import accuracy_score\n","Neighbors=105\n","k_range = range (1,Neighbors+1)\n","scores={}\n","scores_list = []\n","for k in k_range:\n","  knn = KNeighborsClassifier(n_neighbors=k)\n","  knn.fit(X_train, y_train)\n","  y_pred=knn.predict(X_test)\n","  scores[k] = accuracy_score(y_test,y_pred)\n","  scores_list.append(accuracy_score(y_test,y_pred))\n","  print(str(k)+\"/\"+str(Neighbors)+\" round completed......................... Accurecy: \"+str(accuracy_score(y_test,y_pred)))\n","\n","\n","%matplotlib inline\n","import matplotlib.pyplot as plt\n","\n","plt.figure(figsize = (25,10))\n","plt.plot(k_range,scores_list)\n","plt.xlabel('Value of n_estimators')\n","plt.ylabel ('Testing Accuracy')\n","\n","\n","\n","print(\"The best Depth:\")\n","best=list(scores.keys())[scores_list.index(max(scores_list))]\n","print(best)"],"metadata":{"id":"CpSsmYDHa-VF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.neighbors import KNeighborsClassifier\n","knn_neighbors = KNeighborsClassifier(n_neighbors=best)\n","knn_neighbors.fit(X_train, y_train)\n","y_pred=knn_neighbors.predict(X_test)\n","\n","\n","from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n","print(confusion_matrix(y_test, y_pred))\n","print(classification_report(y_test,y_pred))\n","print(\"Accurecy: \",accuracy_score(y_test, y_pred))\n","result[(knn_neighbors,5,'KNeighborsClassifier')]=accuracy_score(y_test, y_pred)"],"metadata":{"id":"MIVJZYV8bCjo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#NB"],"metadata":{"id":"_Btki9jRvc1Y"}},{"cell_type":"code","source":["from sklearn.naive_bayes import GaussianNB\n","\n","nb_deafult = GaussianNB()\n","nb_deafult.fit(X_train, y_train)\n","y_pred = nb_deafult.predict(X_test)\n","\n","\n","from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n","print(confusion_matrix(y_test, y_pred))\n","print(classification_report(y_test,y_pred))\n","print(\"Accurecy: \",accuracy_score(y_test, y_pred))\n","result[(nb_deafult,6,'GaussianNB')]=accuracy_score(y_test, y_pred)"],"metadata":{"id":"iRmd7ve-ubcd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","\n","---\n","\n","\n","\n","---\n","\n"],"metadata":{"id":"qqsWPAB3uv72"}},{"cell_type":"markdown","source":["#Result"],"metadata":{"id":"6FEsxCdvkg2D"}},{"cell_type":"code","source":["\n","models=[]\n","\n","for i in result:\n","  models.append(i[0])\n","  print(i[0],i[1],\" : \",result[i])\n","  print(\"---------------------------------------------------------------\")\n","  print()\n"],"metadata":{"id":"rx7qCLU14Aim"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sorted_list=[]\n","sorted_list = sorted(result, key=result.get,reverse=True)\n","\n","for i in sorted_list:\n","  print(i,\"  : \",result[i])\n","  print(\"-------------------------------------------------------------------------------------------------\")\n","\n","print(sorted_list)\n","\n","\n","flage=[]\n","best_models=[]\n","it=0\n","\n","for i in sorted_list:\n","  if it==4:\n","    break\n","\n","  if i[1] not in flage:\n","    best_models.append((i[0],i[2]))\n","    flage.append(i[1])\n","    it+=1\n"],"metadata":{"id":"slItYG8uLOFi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"best_models:\")\n","for i in best_models:\n","  print(i)\n"],"metadata":{"id":"SR0XBsJDMi_1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(best_models)"],"metadata":{"id":"VQCaVYKA5acD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Testing Accuracy For Best 4 Models"],"metadata":{"id":"znXNx2bgUvtd"}},{"cell_type":"code","source":["\n","for i in best_models:\n","  print(\"--------------------------------------------------\")\n","  print(i[0])\n","  y_pred=i[0].predict(X_train)\n","  print(confusion_matrix(y_train, y_pred))\n","  print(classification_report(y_train,y_pred))\n","  print(\"Accurecy: \",accuracy_score(y_train, y_pred))"],"metadata":{"id":"2j9CXuBkUuiR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"vdNgE1HYwEjc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Cross_val_score function"],"metadata":{"id":"jX_PfaT_xslF"}},{"cell_type":"code","source":["from sklearn.model_selection import cross_val_score\n","\n","k=5\n","for i in result:\n","  print(i[0],\" -> Accuracy: \",result[i])\n","  l=list(cross_val_score(i[0],X_new.iloc[:,1:], y_new,cv=k))\n","  avg=sum(l)/k\n","  print(i[0],\" -> AVG Accurecy After CV: \"+str(avg)+ \" (For \"+str(k)+\" Fold)\")\n","  print(\"--------------------------------------------------------------------------\")"],"metadata":{"id":"8pxPGEPkxt_5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","\n","def CV_ROC(model,folds,graph_feat):\n","  import matplotlib.pyplot as plt\n","\n","  from sklearn import svm\n","  from sklearn.metrics import auc,roc_curve\n","  from sklearn.metrics import RocCurveDisplay\n","  from sklearn.model_selection import StratifiedKFold\n","\n","\n","  cv = StratifiedKFold(n_splits=folds)\n","\n","\n","\n","  tprs = []\n","  aucs = []\n","  mean_fpr = np.linspace(0,1,100)\n","  i = 1\n","  for train,test in cv.split(X_new.iloc[:,1:], y_new.values):\n","      prediction = model.fit(X_new.iloc[:,1:].values[train], y_new.values[train]).predict_proba(X_new.iloc[:,1:].values[test])\n","      fpr, tpr, t = roc_curve(y_new.values[test], prediction[:, 1])\n","      tprs.append(np.interp(mean_fpr, fpr, tpr))\n","      roc_auc = auc(fpr, tpr)\n","      aucs.append(roc_auc)\n","      plt.plot(fpr, tpr, lw=2, alpha=0.3, label='ROC fold %d (AUC = %0.2f)' % (i, roc_auc))\n","      i= i+1\n","\n","  plt.plot([0,1],[0,1],linestyle = '--',lw = 2,color = 'black')\n","  mean_tpr = np.mean(tprs, axis=0)\n","  mean_auc = auc(mean_fpr, mean_tpr)\n","  plt.plot(mean_fpr, mean_tpr, color='blue',\n","          label=r'Mean ROC (AUC = %0.2f )' % (mean_auc),lw=2, alpha=1)\n","\n","  plt.title('CV-ROC-> '+str(model),fontsize= graph_feat[\"Title Size\"], fontweight=graph_feat[\"Title Fontweight\"])\n","  plt.xlabel('False Positive Rate',fontweight=graph_feat[\"X axis Label Fontweight\"],fontsize=graph_feat[\"X axis Label Font Size\"])\n","  plt.ylabel('True Positive Rate',fontweight=graph_feat[\"Y axis Label Fontweight\"],fontsize=graph_feat[\"Y axis Label Font Size\"])\n","  plt.legend( \n","           prop = {'size' : graph_feat[\"legend Font Size\"]}, \n","           loc = graph_feat[\"legend Position\"])\n","  \n","  fig = plt.gcf()\n","  fig.set_size_inches(graph_feat[\"Fig Width (inches)\"], graph_feat[\"Fig Height (inches)\"])\n","  fig.savefig(graph_feat[\"Fig Saving Name\"], dpi=graph_feat[\"dpi\"])\n","  plt.show()"],"metadata":{"id":"zaLJJ_w0xwla"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["new_keys=models_check_box(models)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":172},"id":"cogEJNQOyhd0","executionInfo":{"status":"error","timestamp":1671779033985,"user_tz":-360,"elapsed":453,"user":{"displayName":"Rafsan Jany","userId":"08721334090885411304"}},"outputId":"a297cf9a-377a-4701-fc68-f5b7f7200b36"},"execution_count":3,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-7959e4fafbbe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnew_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodels_check_box\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'models' is not defined"]}]},{"cell_type":"code","source":["# run this cell after selecting\n","\n","graph_feat={\n","    \"Title Size\":18,\n","    \"Title Fontweight\":'bold',\n","\n","    \"legend Font Size\": 14,\n","    \"legend Position\": \"lower right\",\n","\n","    \"X axis Label Font Size\":16,\n","    \"X axis Label Fontweight\":'bold',\n","\n","    \"Y axis Label Font Size\":16,\n","    \"Y axis Label Fontweight\":'bold',\n","\n","    \"Fig Height (inches)\":10.8,\n","    \"Fig Width (inches)\":18.8,\n","\n","    \"Fig Saving Name\": \"ROC_testing.png\",\n","    \"dpi\":100\n","\n","}\n","\n","\n","\n","\n","\n","k_fold=5\n","\n","for i in range(len(new_keys)):\n","  if new_keys[i].value ==True:\n","    CV_ROC(models[i],5,graph_feat)\n","    print(\"-----------------------------------------------------------------\")\n","    print(\"-----------------------------------------------------------------\")"],"metadata":{"id":"1GBQnrJvynrV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#ROC"],"metadata":{"id":"bqG9Vdd0Km6A"}},{"cell_type":"code","source":["!pip install plotly==5.11.0\n","!pip install -U kaleido\n","\n","\n","import plotly.graph_objects as go\n","import plotly.express as px\n","import numpy as np\n","import pandas as pd\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import roc_curve, roc_auc_score\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","def ploty_ROC(model,X,y,fig_name):\n","    \n","    lebel_dict={\n","    0: 'Reading',\n","    1: 'Resting',\n","    2: 'Walking',\n","    3: 'Working'\n","    }\n","\n","    y_scores = model.predict_proba(X)\n","\n","    y_onehot = pd.get_dummies(y, columns=model.classes_)\n","\n","    fig = go.Figure()\n","    fig.add_shape(\n","        type='line', line=dict(dash='dash'),\n","        x0=0, x1=1, y0=0, y1=1\n","    )\n","\n","    for i in range(y_scores.shape[1]):\n","        y_true = y_onehot.iloc[:, i]\n","        y_score = y_scores[:, i]\n","\n","        fpr, tpr, _ = roc_curve(y_true, y_score)\n","        auc_score = roc_auc_score(y_true, y_score)\n","        name = f\"{lebel_dict[y_onehot.columns[i]]} (AUC={auc_score:.2f})\"\n","        fig.add_trace(go.Scatter(x=fpr, y=tpr, name=name, mode='lines'))\n","\n","    fig.update_layout(\n","        xaxis_title='False Positive Rate',\n","        yaxis_title='True Positive Rate',\n","        yaxis=dict(scaleanchor=\"x\", scaleratio=1),\n","        xaxis=dict(constrain='domain'),\n","        width=1000, height=1000,\n","        font=dict(\n","            family=\"Courier New, monospace\",\n","            size=20,\n","            color=\"BLack\"\n","        ),\n","        legend=dict(\n","            x=0.67,\n","            y=0.05,\n","            traceorder=\"reversed\",\n","            title_font_family=\"Times New Roman\",\n","            font=dict(\n","                family=\"Courier New, monospace\",\n","                size=20,\n","                color=\"black\"\n","            ),\n","            bgcolor=\"LightSteelBlue\",\n","            bordercolor=\"White\",\n","            borderwidth=2\n","        )\n","    )\n","    fig.show()\n","    fig.write_image(fig_name+\".png\")"],"metadata":{"id":"uGMhOiOmKqA7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#SHAP"],"metadata":{"id":"zxxWSX26jsGT"}},{"cell_type":"code","source":["!pip install shap\n","import shap"],"metadata":{"id":"YUhJ7dWajur-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","def SHAP_EXP(model,graph_feat):\n","  print(\"Models: \",model)\n","\n","  explainer = shap.Explainer(model.predict, X_test)\n","\n","  shap_values1 = explainer(X_test)\n","  features_names=list_of_feat\n","\n","  if 'Subjects' in features_names:\n","    features_names.pop(0)\n","\n","\n","  shap.plots.bar(shap_values1,max_display=graph_feat[\"max_display\"])\n","\n","  print(\"---------------------\")\n","\n","  shap.summary_plot(shap_values1,max_display=graph_feat[\"max_display\"],feature_names=features_names)\n","\n","  print(\"---------------------\")\n","\n","  print(\"Local Explaination\")\n","  shap.plots.waterfall(shap_values1[graph_feat[\"shap_values Index\"]],max_display=graph_feat[\"max_display\"])\n","\n","\n","  print(\"---------------------\")\n","\n","  shap.plots.bar(shap_values1[graph_feat[\"shap_values Index\"]],max_display=graph_feat[\"max_display\"])"],"metadata":{"id":"POk0kUrdB-Y4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["new_keys_7=models_check_box(models)"],"metadata":{"id":"V-G5szfQDiz1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["graph_feat={\n","    \"max_display\":20,\n","    \"shap_values Index\":2\n","}\n","\n","for i in range(len(new_keys_7)):\n","  if new_keys_7[i].value ==True:\n","    SHAP_EXP(models[i],graph_feat)\n","    print(\"---------------------------------------------------------\")\n","    print(\"---------------------------------------------------------\")\n","    print(\"---------------------------------------------------------\")\n","    print(\"---------------------------------------------------------\")"],"metadata":{"id":"JeD8HT_iDodb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **LIME**"],"metadata":{"id":"iDu8Ipdm8qaV"}},{"cell_type":"code","source":["!pip install lime"],"metadata":{"id":"kw4wkx98AuLW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","import lime\n","from lime import lime_tabular\n","explainer = lime_tabular.LimeTabularExplainer(\n","    training_data=np.array(X_train),\n","    feature_names=list(X.columns),\n","    class_names=['Reading', 'Resting', 'Walking', 'Working'],\n","    mode='classification'\n",")\n","     "],"metadata":{"id":"KM6UBpC3DBAj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["row = int(input(\"Enter the index of row to explain: \"))      # the index of row to be explained in LIME\n","\n","\n","exp = explainer.explain_instance(X_test.iloc[row],\n","                                 gradBoost_estimator.predict_proba,               #here write the model name\n","                                 num_features=6,\n","                                 top_labels=4)\n","\n","exp.show_in_notebook(show_table=True, show_all=True)\n","\n","\n","\n","from IPython.display import HTML\n","\n","html_data = exp.as_html()\n","HTML(data=html_data)\n","\n","\n","exp.save_to_file(\"classif_explanation.html\")"],"metadata":{"id":"NU96KbYHDIWA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","with plt.style.context(\"ggplot\"):\n","    exp.as_pyplot_figure()"],"metadata":{"id":"u-BkKmWjKGXn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"ydEeo7l_C1Zs"}}]}