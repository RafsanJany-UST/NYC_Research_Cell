{"cells":[{"cell_type":"code","source":[],"metadata":{"id":"z8LV1VV5WgHJ"},"id":"z8LV1VV5WgHJ","execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wvqgcYmUWhlG","executionInfo":{"status":"ok","timestamp":1718157472355,"user_tz":-360,"elapsed":30991,"user":{"displayName":"Rafsan Jany","userId":"08721334090885411304"}},"outputId":"eff6956d-2990-4a06-b1d8-342ca650553e"},"id":"wvqgcYmUWhlG","execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["\"\"\"!wget -r -N -c -np --user iqram20 --ask-password -P \"/content/drive/MyDrive/Iqram Sir/MIMIC/main\" https://physionet.org/files/mimic-iv-note/2.2/\"\"\""],"metadata":{"id":"9OSXhfRKV3Mx"},"id":"9OSXhfRKV3Mx","execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","\n","# Load the .csv.gz file directly into a DataFrame\n","df1 = pd.read_csv('/content/drive/MyDrive/Iqram Sir/MIMIC/main/physionet.org/files/mimic-iv-note/2.2/note/discharge.csv.gz')\n","df2 = pd.read_csv('/content/drive/MyDrive/Iqram Sir/MIMIC/main/physionet.org/files/mimic-iv-note/2.2/note/discharge_detail.csv.gz')\n","df3 = pd.read_csv('/content/drive/MyDrive/Iqram Sir/MIMIC/main/physionet.org/files/mimic-iv-note/2.2/note/radiology.csv.gz')\n","df4 = pd.read_csv('/content/drive/MyDrive/Iqram Sir/MIMIC/main/physionet.org/files/mimic-iv-note/2.2/note/radiology_detail.csv.gz')\n","\n","\n"],"metadata":{"id":"E03ULgl7STQV","executionInfo":{"status":"ok","timestamp":1718157923879,"user_tz":-360,"elapsed":146968,"user":{"displayName":"Rafsan Jany","userId":"08721334090885411304"}}},"id":"E03ULgl7STQV","execution_count":2,"outputs":[]},{"cell_type":"code","source":["df1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"56Fvg4ykSTOo","executionInfo":{"status":"ok","timestamp":1718157923880,"user_tz":-360,"elapsed":71,"user":{"displayName":"Rafsan Jany","userId":"08721334090885411304"}},"outputId":"a58cea51-91a7-4d3d-dbb9-0c94d5c03a97"},"id":"56Fvg4ykSTOo","execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["               note_id  subject_id   hadm_id note_type  note_seq  \\\n","0       10000032-DS-21    10000032  22595853        DS        21   \n","1       10000032-DS-22    10000032  22841357        DS        22   \n","2       10000032-DS-23    10000032  29079034        DS        23   \n","3       10000032-DS-24    10000032  25742920        DS        24   \n","4       10000084-DS-17    10000084  23052089        DS        17   \n","...                ...         ...       ...       ...       ...   \n","331788   19999828-DS-6    19999828  29734428        DS         6   \n","331789   19999828-DS-7    19999828  25744818        DS         7   \n","331790  19999840-DS-20    19999840  26071774        DS        20   \n","331791  19999840-DS-21    19999840  21033226        DS        21   \n","331792   19999987-DS-2    19999987  23865745        DS         2   \n","\n","                  charttime            storetime  \\\n","0       2180-05-07 00:00:00  2180-05-09 15:26:00   \n","1       2180-06-27 00:00:00  2180-07-01 10:15:00   \n","2       2180-07-25 00:00:00  2180-07-25 21:42:00   \n","3       2180-08-07 00:00:00  2180-08-10 05:43:00   \n","4       2160-11-25 00:00:00  2160-11-25 15:09:00   \n","...                     ...                  ...   \n","331788  2147-08-04 00:00:00  2147-08-12 15:36:00   \n","331789  2149-01-18 00:00:00  2149-01-19 07:03:00   \n","331790  2164-07-28 00:00:00  2164-07-29 14:52:00   \n","331791  2164-09-17 00:00:00  2164-09-18 01:36:00   \n","331792  2145-11-11 00:00:00  2145-11-11 13:13:00   \n","\n","                                                     text  \n","0        \\nName:  ___                     Unit No:   _...  \n","1        \\nName:  ___                     Unit No:   _...  \n","2        \\nName:  ___                     Unit No:   _...  \n","3        \\nName:  ___                     Unit No:   _...  \n","4        \\nName:  ___                    Unit No:   __...  \n","...                                                   ...  \n","331788   \\nName:  ___                   Unit No:   ___...  \n","331789   \\nName:  ___                   Unit No:   ___...  \n","331790   \\nName:  ___                  Unit No:   ___\\...  \n","331791   \\nName:  ___                  Unit No:   ___\\...  \n","331792   \\nName:  ___                    Unit No:   __...  \n","\n","[331793 rows x 8 columns]"],"text/html":["\n","  <div id=\"df-6d327255-b2ef-4e45-9aca-6b6d43920c83\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>note_id</th>\n","      <th>subject_id</th>\n","      <th>hadm_id</th>\n","      <th>note_type</th>\n","      <th>note_seq</th>\n","      <th>charttime</th>\n","      <th>storetime</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>10000032-DS-21</td>\n","      <td>10000032</td>\n","      <td>22595853</td>\n","      <td>DS</td>\n","      <td>21</td>\n","      <td>2180-05-07 00:00:00</td>\n","      <td>2180-05-09 15:26:00</td>\n","      <td>\\nName:  ___                     Unit No:   _...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>10000032-DS-22</td>\n","      <td>10000032</td>\n","      <td>22841357</td>\n","      <td>DS</td>\n","      <td>22</td>\n","      <td>2180-06-27 00:00:00</td>\n","      <td>2180-07-01 10:15:00</td>\n","      <td>\\nName:  ___                     Unit No:   _...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>10000032-DS-23</td>\n","      <td>10000032</td>\n","      <td>29079034</td>\n","      <td>DS</td>\n","      <td>23</td>\n","      <td>2180-07-25 00:00:00</td>\n","      <td>2180-07-25 21:42:00</td>\n","      <td>\\nName:  ___                     Unit No:   _...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>10000032-DS-24</td>\n","      <td>10000032</td>\n","      <td>25742920</td>\n","      <td>DS</td>\n","      <td>24</td>\n","      <td>2180-08-07 00:00:00</td>\n","      <td>2180-08-10 05:43:00</td>\n","      <td>\\nName:  ___                     Unit No:   _...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>10000084-DS-17</td>\n","      <td>10000084</td>\n","      <td>23052089</td>\n","      <td>DS</td>\n","      <td>17</td>\n","      <td>2160-11-25 00:00:00</td>\n","      <td>2160-11-25 15:09:00</td>\n","      <td>\\nName:  ___                    Unit No:   __...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>331788</th>\n","      <td>19999828-DS-6</td>\n","      <td>19999828</td>\n","      <td>29734428</td>\n","      <td>DS</td>\n","      <td>6</td>\n","      <td>2147-08-04 00:00:00</td>\n","      <td>2147-08-12 15:36:00</td>\n","      <td>\\nName:  ___                   Unit No:   ___...</td>\n","    </tr>\n","    <tr>\n","      <th>331789</th>\n","      <td>19999828-DS-7</td>\n","      <td>19999828</td>\n","      <td>25744818</td>\n","      <td>DS</td>\n","      <td>7</td>\n","      <td>2149-01-18 00:00:00</td>\n","      <td>2149-01-19 07:03:00</td>\n","      <td>\\nName:  ___                   Unit No:   ___...</td>\n","    </tr>\n","    <tr>\n","      <th>331790</th>\n","      <td>19999840-DS-20</td>\n","      <td>19999840</td>\n","      <td>26071774</td>\n","      <td>DS</td>\n","      <td>20</td>\n","      <td>2164-07-28 00:00:00</td>\n","      <td>2164-07-29 14:52:00</td>\n","      <td>\\nName:  ___                  Unit No:   ___\\...</td>\n","    </tr>\n","    <tr>\n","      <th>331791</th>\n","      <td>19999840-DS-21</td>\n","      <td>19999840</td>\n","      <td>21033226</td>\n","      <td>DS</td>\n","      <td>21</td>\n","      <td>2164-09-17 00:00:00</td>\n","      <td>2164-09-18 01:36:00</td>\n","      <td>\\nName:  ___                  Unit No:   ___\\...</td>\n","    </tr>\n","    <tr>\n","      <th>331792</th>\n","      <td>19999987-DS-2</td>\n","      <td>19999987</td>\n","      <td>23865745</td>\n","      <td>DS</td>\n","      <td>2</td>\n","      <td>2145-11-11 00:00:00</td>\n","      <td>2145-11-11 13:13:00</td>\n","      <td>\\nName:  ___                    Unit No:   __...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>331793 rows Ã— 8 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6d327255-b2ef-4e45-9aca-6b6d43920c83')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-6d327255-b2ef-4e45-9aca-6b6d43920c83 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-6d327255-b2ef-4e45-9aca-6b6d43920c83');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-236388d1-6d94-4c92-bd35-bb208bbf7dbe\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-236388d1-6d94-4c92-bd35-bb208bbf7dbe')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-236388d1-6d94-4c92-bd35-bb208bbf7dbe button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_4ff5d52c-7f89-4aee-b558-1e4b08af6542\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df1')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_4ff5d52c-7f89-4aee-b558-1e4b08af6542 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('df1');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df1"}},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["df2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"QRLrltd1STLf","executionInfo":{"status":"ok","timestamp":1718157923880,"user_tz":-360,"elapsed":65,"user":{"displayName":"Rafsan Jany","userId":"08721334090885411304"}},"outputId":"4d6db2d3-d1ee-48c5-e8f2-83b3d4af9ab5"},"id":"QRLrltd1STLf","execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["               note_id  subject_id field_name field_value  field_ordinal\n","0       10000032-DS-21    10000032     author         ___              1\n","1       10000032-DS-22    10000032     author         ___              1\n","2       10000032-DS-23    10000032     author         ___              1\n","3       10000032-DS-24    10000032     author         ___              1\n","4       10000084-DS-17    10000084     author         ___              1\n","...                ...         ...        ...         ...            ...\n","186133  15614172-DS-13    15614172     author         ___              1\n","186134  15614172-DS-14    15614172     author         ___              1\n","186135  15614172-DS-15    15614172     author         ___              1\n","186136  15614172-DS-16    15614172     author         ___              1\n","186137  15614172-DS-17    15614172     author         ___              1\n","\n","[186138 rows x 5 columns]"],"text/html":["\n","  <div id=\"df-1b8a4e07-21e2-4f98-b343-355ea3c74d92\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>note_id</th>\n","      <th>subject_id</th>\n","      <th>field_name</th>\n","      <th>field_value</th>\n","      <th>field_ordinal</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>10000032-DS-21</td>\n","      <td>10000032</td>\n","      <td>author</td>\n","      <td>___</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>10000032-DS-22</td>\n","      <td>10000032</td>\n","      <td>author</td>\n","      <td>___</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>10000032-DS-23</td>\n","      <td>10000032</td>\n","      <td>author</td>\n","      <td>___</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>10000032-DS-24</td>\n","      <td>10000032</td>\n","      <td>author</td>\n","      <td>___</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>10000084-DS-17</td>\n","      <td>10000084</td>\n","      <td>author</td>\n","      <td>___</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>186133</th>\n","      <td>15614172-DS-13</td>\n","      <td>15614172</td>\n","      <td>author</td>\n","      <td>___</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>186134</th>\n","      <td>15614172-DS-14</td>\n","      <td>15614172</td>\n","      <td>author</td>\n","      <td>___</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>186135</th>\n","      <td>15614172-DS-15</td>\n","      <td>15614172</td>\n","      <td>author</td>\n","      <td>___</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>186136</th>\n","      <td>15614172-DS-16</td>\n","      <td>15614172</td>\n","      <td>author</td>\n","      <td>___</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>186137</th>\n","      <td>15614172-DS-17</td>\n","      <td>15614172</td>\n","      <td>author</td>\n","      <td>___</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>186138 rows Ã— 5 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1b8a4e07-21e2-4f98-b343-355ea3c74d92')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-1b8a4e07-21e2-4f98-b343-355ea3c74d92 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-1b8a4e07-21e2-4f98-b343-355ea3c74d92');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-15e244cf-8925-4e75-9752-d639352f2800\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-15e244cf-8925-4e75-9752-d639352f2800')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-15e244cf-8925-4e75-9752-d639352f2800 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_aa7d854e-7077-427d-94a8-b4002728a97e\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df2')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_aa7d854e-7077-427d-94a8-b4002728a97e button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('df2');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df2"}},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["df3"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":597},"id":"rrLDc-bBSTHU","executionInfo":{"status":"ok","timestamp":1718157923880,"user_tz":-360,"elapsed":63,"user":{"displayName":"Rafsan Jany","userId":"08721334090885411304"}},"outputId":"07062ef1-c382-4d37-aba5-4a7c9997c66c"},"id":"rrLDc-bBSTHU","execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                note_id  subject_id     hadm_id note_type  note_seq  \\\n","0        10000032-RR-14    10000032  22595853.0        RR        14   \n","1        10000032-RR-15    10000032  22595853.0        RR        15   \n","2        10000032-RR-16    10000032  22595853.0        RR        16   \n","3        10000032-RR-18    10000032         NaN        RR        18   \n","4        10000032-RR-20    10000032         NaN        RR        20   \n","...                 ...         ...         ...       ...       ...   \n","2321350  19999987-RR-17    19999987  23865745.0        RR        17   \n","2321351  19999987-RR-18    19999987  23865745.0        RR        18   \n","2321352  19999987-RR-19    19999987  23865745.0        RR        19   \n","2321353  19999987-RR-20    19999987  23865745.0        RR        20   \n","2321354  19999987-RR-21    19999987  23865745.0        RR        21   \n","\n","                   charttime            storetime  \\\n","0        2180-05-06 21:19:00  2180-05-06 23:32:00   \n","1        2180-05-06 23:00:00  2180-05-06 23:26:00   \n","2        2180-05-07 09:55:00  2180-05-07 11:15:00   \n","3        2180-06-03 12:46:00  2180-06-03 14:01:00   \n","4        2180-07-08 13:18:00  2180-07-08 14:15:00   \n","...                      ...                  ...   \n","2321350  2145-11-02 22:37:00  2145-11-03 18:55:00   \n","2321351  2145-11-03 04:35:00  2145-11-03 10:46:00   \n","2321352  2145-11-03 16:40:00  2145-11-04 08:36:00   \n","2321353  2145-11-04 05:10:00  2145-11-04 08:58:00   \n","2321354  2145-11-07 15:18:00  2145-11-08 16:44:00   \n","\n","                                                      text  \n","0        EXAMINATION:  CHEST (PA AND LAT)\\n\\nINDICATION...  \n","1        EXAMINATION:  LIVER OR GALLBLADDER US (SINGLE ...  \n","2        INDICATION:  ___ HCV cirrhosis c/b ascites, hi...  \n","3        EXAMINATION:  Ultrasound-guided paracentesis.\\...  \n","4        EXAMINATION:  Paracentesis\\n\\nINDICATION:  ___...  \n","...                                                    ...  \n","2321350  HISTORY:  ___, with left occipital bleeding.  ...  \n","2321351  INDICATION:  ___ female intubated for head ble...  \n","2321352  HISTORY:  ___ woman with left occipital hemorr...  \n","2321353  PORTABLE CHEST OF ___\\n\\nCOMPARISON:  ___ radi...  \n","2321354  DATE OF SERVICE:  ___.\\n\\nPRE-OPERATIVE DIAGNO...  \n","\n","[2321355 rows x 8 columns]"],"text/html":["\n","  <div id=\"df-511b51bf-93cb-4bd7-9f47-161845644e93\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>note_id</th>\n","      <th>subject_id</th>\n","      <th>hadm_id</th>\n","      <th>note_type</th>\n","      <th>note_seq</th>\n","      <th>charttime</th>\n","      <th>storetime</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>10000032-RR-14</td>\n","      <td>10000032</td>\n","      <td>22595853.0</td>\n","      <td>RR</td>\n","      <td>14</td>\n","      <td>2180-05-06 21:19:00</td>\n","      <td>2180-05-06 23:32:00</td>\n","      <td>EXAMINATION:  CHEST (PA AND LAT)\\n\\nINDICATION...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>10000032-RR-15</td>\n","      <td>10000032</td>\n","      <td>22595853.0</td>\n","      <td>RR</td>\n","      <td>15</td>\n","      <td>2180-05-06 23:00:00</td>\n","      <td>2180-05-06 23:26:00</td>\n","      <td>EXAMINATION:  LIVER OR GALLBLADDER US (SINGLE ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>10000032-RR-16</td>\n","      <td>10000032</td>\n","      <td>22595853.0</td>\n","      <td>RR</td>\n","      <td>16</td>\n","      <td>2180-05-07 09:55:00</td>\n","      <td>2180-05-07 11:15:00</td>\n","      <td>INDICATION:  ___ HCV cirrhosis c/b ascites, hi...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>10000032-RR-18</td>\n","      <td>10000032</td>\n","      <td>NaN</td>\n","      <td>RR</td>\n","      <td>18</td>\n","      <td>2180-06-03 12:46:00</td>\n","      <td>2180-06-03 14:01:00</td>\n","      <td>EXAMINATION:  Ultrasound-guided paracentesis.\\...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>10000032-RR-20</td>\n","      <td>10000032</td>\n","      <td>NaN</td>\n","      <td>RR</td>\n","      <td>20</td>\n","      <td>2180-07-08 13:18:00</td>\n","      <td>2180-07-08 14:15:00</td>\n","      <td>EXAMINATION:  Paracentesis\\n\\nINDICATION:  ___...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2321350</th>\n","      <td>19999987-RR-17</td>\n","      <td>19999987</td>\n","      <td>23865745.0</td>\n","      <td>RR</td>\n","      <td>17</td>\n","      <td>2145-11-02 22:37:00</td>\n","      <td>2145-11-03 18:55:00</td>\n","      <td>HISTORY:  ___, with left occipital bleeding.  ...</td>\n","    </tr>\n","    <tr>\n","      <th>2321351</th>\n","      <td>19999987-RR-18</td>\n","      <td>19999987</td>\n","      <td>23865745.0</td>\n","      <td>RR</td>\n","      <td>18</td>\n","      <td>2145-11-03 04:35:00</td>\n","      <td>2145-11-03 10:46:00</td>\n","      <td>INDICATION:  ___ female intubated for head ble...</td>\n","    </tr>\n","    <tr>\n","      <th>2321352</th>\n","      <td>19999987-RR-19</td>\n","      <td>19999987</td>\n","      <td>23865745.0</td>\n","      <td>RR</td>\n","      <td>19</td>\n","      <td>2145-11-03 16:40:00</td>\n","      <td>2145-11-04 08:36:00</td>\n","      <td>HISTORY:  ___ woman with left occipital hemorr...</td>\n","    </tr>\n","    <tr>\n","      <th>2321353</th>\n","      <td>19999987-RR-20</td>\n","      <td>19999987</td>\n","      <td>23865745.0</td>\n","      <td>RR</td>\n","      <td>20</td>\n","      <td>2145-11-04 05:10:00</td>\n","      <td>2145-11-04 08:58:00</td>\n","      <td>PORTABLE CHEST OF ___\\n\\nCOMPARISON:  ___ radi...</td>\n","    </tr>\n","    <tr>\n","      <th>2321354</th>\n","      <td>19999987-RR-21</td>\n","      <td>19999987</td>\n","      <td>23865745.0</td>\n","      <td>RR</td>\n","      <td>21</td>\n","      <td>2145-11-07 15:18:00</td>\n","      <td>2145-11-08 16:44:00</td>\n","      <td>DATE OF SERVICE:  ___.\\n\\nPRE-OPERATIVE DIAGNO...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2321355 rows Ã— 8 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-511b51bf-93cb-4bd7-9f47-161845644e93')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-511b51bf-93cb-4bd7-9f47-161845644e93 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-511b51bf-93cb-4bd7-9f47-161845644e93');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-d64dd39b-8205-4578-8ed0-018979f63bd0\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d64dd39b-8205-4578-8ed0-018979f63bd0')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-d64dd39b-8205-4578-8ed0-018979f63bd0 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_40d7cf7a-88b5-4c44-8c90-a0d6bb67015e\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df3')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_40d7cf7a-88b5-4c44-8c90-a0d6bb67015e button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('df3');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df3"}},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["df3"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":597},"id":"tI-bNU3OSS9l","executionInfo":{"status":"ok","timestamp":1718157923881,"user_tz":-360,"elapsed":62,"user":{"displayName":"Rafsan Jany","userId":"08721334090885411304"}},"outputId":"026660a3-edae-44d0-ce82-eda09a38e325"},"id":"tI-bNU3OSS9l","execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                note_id  subject_id     hadm_id note_type  note_seq  \\\n","0        10000032-RR-14    10000032  22595853.0        RR        14   \n","1        10000032-RR-15    10000032  22595853.0        RR        15   \n","2        10000032-RR-16    10000032  22595853.0        RR        16   \n","3        10000032-RR-18    10000032         NaN        RR        18   \n","4        10000032-RR-20    10000032         NaN        RR        20   \n","...                 ...         ...         ...       ...       ...   \n","2321350  19999987-RR-17    19999987  23865745.0        RR        17   \n","2321351  19999987-RR-18    19999987  23865745.0        RR        18   \n","2321352  19999987-RR-19    19999987  23865745.0        RR        19   \n","2321353  19999987-RR-20    19999987  23865745.0        RR        20   \n","2321354  19999987-RR-21    19999987  23865745.0        RR        21   \n","\n","                   charttime            storetime  \\\n","0        2180-05-06 21:19:00  2180-05-06 23:32:00   \n","1        2180-05-06 23:00:00  2180-05-06 23:26:00   \n","2        2180-05-07 09:55:00  2180-05-07 11:15:00   \n","3        2180-06-03 12:46:00  2180-06-03 14:01:00   \n","4        2180-07-08 13:18:00  2180-07-08 14:15:00   \n","...                      ...                  ...   \n","2321350  2145-11-02 22:37:00  2145-11-03 18:55:00   \n","2321351  2145-11-03 04:35:00  2145-11-03 10:46:00   \n","2321352  2145-11-03 16:40:00  2145-11-04 08:36:00   \n","2321353  2145-11-04 05:10:00  2145-11-04 08:58:00   \n","2321354  2145-11-07 15:18:00  2145-11-08 16:44:00   \n","\n","                                                      text  \n","0        EXAMINATION:  CHEST (PA AND LAT)\\n\\nINDICATION...  \n","1        EXAMINATION:  LIVER OR GALLBLADDER US (SINGLE ...  \n","2        INDICATION:  ___ HCV cirrhosis c/b ascites, hi...  \n","3        EXAMINATION:  Ultrasound-guided paracentesis.\\...  \n","4        EXAMINATION:  Paracentesis\\n\\nINDICATION:  ___...  \n","...                                                    ...  \n","2321350  HISTORY:  ___, with left occipital bleeding.  ...  \n","2321351  INDICATION:  ___ female intubated for head ble...  \n","2321352  HISTORY:  ___ woman with left occipital hemorr...  \n","2321353  PORTABLE CHEST OF ___\\n\\nCOMPARISON:  ___ radi...  \n","2321354  DATE OF SERVICE:  ___.\\n\\nPRE-OPERATIVE DIAGNO...  \n","\n","[2321355 rows x 8 columns]"],"text/html":["\n","  <div id=\"df-e82ba4ec-36f8-4aea-8315-2c0cf491080d\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>note_id</th>\n","      <th>subject_id</th>\n","      <th>hadm_id</th>\n","      <th>note_type</th>\n","      <th>note_seq</th>\n","      <th>charttime</th>\n","      <th>storetime</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>10000032-RR-14</td>\n","      <td>10000032</td>\n","      <td>22595853.0</td>\n","      <td>RR</td>\n","      <td>14</td>\n","      <td>2180-05-06 21:19:00</td>\n","      <td>2180-05-06 23:32:00</td>\n","      <td>EXAMINATION:  CHEST (PA AND LAT)\\n\\nINDICATION...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>10000032-RR-15</td>\n","      <td>10000032</td>\n","      <td>22595853.0</td>\n","      <td>RR</td>\n","      <td>15</td>\n","      <td>2180-05-06 23:00:00</td>\n","      <td>2180-05-06 23:26:00</td>\n","      <td>EXAMINATION:  LIVER OR GALLBLADDER US (SINGLE ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>10000032-RR-16</td>\n","      <td>10000032</td>\n","      <td>22595853.0</td>\n","      <td>RR</td>\n","      <td>16</td>\n","      <td>2180-05-07 09:55:00</td>\n","      <td>2180-05-07 11:15:00</td>\n","      <td>INDICATION:  ___ HCV cirrhosis c/b ascites, hi...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>10000032-RR-18</td>\n","      <td>10000032</td>\n","      <td>NaN</td>\n","      <td>RR</td>\n","      <td>18</td>\n","      <td>2180-06-03 12:46:00</td>\n","      <td>2180-06-03 14:01:00</td>\n","      <td>EXAMINATION:  Ultrasound-guided paracentesis.\\...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>10000032-RR-20</td>\n","      <td>10000032</td>\n","      <td>NaN</td>\n","      <td>RR</td>\n","      <td>20</td>\n","      <td>2180-07-08 13:18:00</td>\n","      <td>2180-07-08 14:15:00</td>\n","      <td>EXAMINATION:  Paracentesis\\n\\nINDICATION:  ___...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2321350</th>\n","      <td>19999987-RR-17</td>\n","      <td>19999987</td>\n","      <td>23865745.0</td>\n","      <td>RR</td>\n","      <td>17</td>\n","      <td>2145-11-02 22:37:00</td>\n","      <td>2145-11-03 18:55:00</td>\n","      <td>HISTORY:  ___, with left occipital bleeding.  ...</td>\n","    </tr>\n","    <tr>\n","      <th>2321351</th>\n","      <td>19999987-RR-18</td>\n","      <td>19999987</td>\n","      <td>23865745.0</td>\n","      <td>RR</td>\n","      <td>18</td>\n","      <td>2145-11-03 04:35:00</td>\n","      <td>2145-11-03 10:46:00</td>\n","      <td>INDICATION:  ___ female intubated for head ble...</td>\n","    </tr>\n","    <tr>\n","      <th>2321352</th>\n","      <td>19999987-RR-19</td>\n","      <td>19999987</td>\n","      <td>23865745.0</td>\n","      <td>RR</td>\n","      <td>19</td>\n","      <td>2145-11-03 16:40:00</td>\n","      <td>2145-11-04 08:36:00</td>\n","      <td>HISTORY:  ___ woman with left occipital hemorr...</td>\n","    </tr>\n","    <tr>\n","      <th>2321353</th>\n","      <td>19999987-RR-20</td>\n","      <td>19999987</td>\n","      <td>23865745.0</td>\n","      <td>RR</td>\n","      <td>20</td>\n","      <td>2145-11-04 05:10:00</td>\n","      <td>2145-11-04 08:58:00</td>\n","      <td>PORTABLE CHEST OF ___\\n\\nCOMPARISON:  ___ radi...</td>\n","    </tr>\n","    <tr>\n","      <th>2321354</th>\n","      <td>19999987-RR-21</td>\n","      <td>19999987</td>\n","      <td>23865745.0</td>\n","      <td>RR</td>\n","      <td>21</td>\n","      <td>2145-11-07 15:18:00</td>\n","      <td>2145-11-08 16:44:00</td>\n","      <td>DATE OF SERVICE:  ___.\\n\\nPRE-OPERATIVE DIAGNO...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2321355 rows Ã— 8 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e82ba4ec-36f8-4aea-8315-2c0cf491080d')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-e82ba4ec-36f8-4aea-8315-2c0cf491080d button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-e82ba4ec-36f8-4aea-8315-2c0cf491080d');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-aec713ea-3765-4be0-9229-7b652437a8c3\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-aec713ea-3765-4be0-9229-7b652437a8c3')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-aec713ea-3765-4be0-9229-7b652437a8c3 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_70defb87-cadd-4a4e-a077-521c35faa8dd\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df3')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_70defb87-cadd-4a4e-a077-521c35faa8dd button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('df3');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df3"}},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["df4"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"egWoFuivSS6g","executionInfo":{"status":"ok","timestamp":1718157925843,"user_tz":-360,"elapsed":12,"user":{"displayName":"Rafsan Jany","userId":"08721334090885411304"}},"outputId":"d159bf91-e263-4719-9698-318501c19ba0"},"id":"egWoFuivSS6g","execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                note_id  subject_id field_name                field_value  \\\n","0        10000032-RR-14    10000032  exam_code                        C11   \n","1        10000032-RR-14    10000032  exam_name           CHEST (PA & LAT)   \n","2        10000032-RR-15    10000032  exam_code                       U314   \n","3        10000032-RR-15    10000032  exam_code                       U644   \n","4        10000032-RR-15    10000032  exam_code                        W82   \n","...                 ...         ...        ...                        ...   \n","6046116  19999987-RR-21    19999987  exam_name     PLACE CATH CAROTID ART   \n","6046117  19999987-RR-21    19999987  exam_name     PLACE CATH CAROTID ART   \n","6046118  19999987-RR-21    19999987  exam_name   PLACE CATH VERTEBRAL ART   \n","6046119  19999987-RR-21    19999987  exam_name  PLACE CATH XTRNL CAROTID    \n","6046120  19999987-RR-21    19999987  exam_name  PLACE CATH XTRNL CAROTID    \n","\n","         field_ordinal  \n","0                    1  \n","1                    1  \n","2                    1  \n","3                    3  \n","4                    2  \n","...                ...  \n","6046116              1  \n","6046117              2  \n","6046118              7  \n","6046119              4  \n","6046120              5  \n","\n","[6046121 rows x 5 columns]"],"text/html":["\n","  <div id=\"df-283cc449-7ee9-45b0-8654-01ed3f70f3ee\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>note_id</th>\n","      <th>subject_id</th>\n","      <th>field_name</th>\n","      <th>field_value</th>\n","      <th>field_ordinal</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>10000032-RR-14</td>\n","      <td>10000032</td>\n","      <td>exam_code</td>\n","      <td>C11</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>10000032-RR-14</td>\n","      <td>10000032</td>\n","      <td>exam_name</td>\n","      <td>CHEST (PA &amp; LAT)</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>10000032-RR-15</td>\n","      <td>10000032</td>\n","      <td>exam_code</td>\n","      <td>U314</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>10000032-RR-15</td>\n","      <td>10000032</td>\n","      <td>exam_code</td>\n","      <td>U644</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>10000032-RR-15</td>\n","      <td>10000032</td>\n","      <td>exam_code</td>\n","      <td>W82</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>6046116</th>\n","      <td>19999987-RR-21</td>\n","      <td>19999987</td>\n","      <td>exam_name</td>\n","      <td>PLACE CATH CAROTID ART</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>6046117</th>\n","      <td>19999987-RR-21</td>\n","      <td>19999987</td>\n","      <td>exam_name</td>\n","      <td>PLACE CATH CAROTID ART</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>6046118</th>\n","      <td>19999987-RR-21</td>\n","      <td>19999987</td>\n","      <td>exam_name</td>\n","      <td>PLACE CATH VERTEBRAL ART</td>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>6046119</th>\n","      <td>19999987-RR-21</td>\n","      <td>19999987</td>\n","      <td>exam_name</td>\n","      <td>PLACE CATH XTRNL CAROTID</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>6046120</th>\n","      <td>19999987-RR-21</td>\n","      <td>19999987</td>\n","      <td>exam_name</td>\n","      <td>PLACE CATH XTRNL CAROTID</td>\n","      <td>5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>6046121 rows Ã— 5 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-283cc449-7ee9-45b0-8654-01ed3f70f3ee')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-283cc449-7ee9-45b0-8654-01ed3f70f3ee button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-283cc449-7ee9-45b0-8654-01ed3f70f3ee');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-5da215bf-4ef3-48df-abcb-299037fb6aeb\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5da215bf-4ef3-48df-abcb-299037fb6aeb')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-5da215bf-4ef3-48df-abcb-299037fb6aeb button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_caa39807-5bb1-4bc1-86a2-449503a264b2\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df4')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_caa39807-5bb1-4bc1-86a2-449503a264b2 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('df4');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df4"}},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":[],"metadata":{"id":"Q68ZYC6QL1I-"},"id":"Q68ZYC6QL1I-","execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"IiJszGs1L1GB"},"id":"IiJszGs1L1GB","execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"OjSyteTzL1BT"},"id":"OjSyteTzL1BT","execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"fLEYyUD0SSz2"},"id":"fLEYyUD0SSz2","execution_count":null,"outputs":[]},{"cell_type":"code","source":["import json\n","import pandas as pd\n","import re\n","from sklearn.model_selection import train_test_split\n","\n","##############Step 1: Extract \"brief hospital course\" from discharge summary#####################\n","\n","def extract_HC(dc_summary_path):\n","\n","  # Load the data\n","  dc_summary_raw = pd.read_csv(dc_summary_path)\n","\n","  # Set up the regular expression to extract hospital course from discharge summary\n","  # Of note these patterns would not caputre all hospital courses, and is indeed a convservative approach to ensure quality of data\n","  pattern1  = re.compile(\"Brief Hospital Course.*\\n*((?:\\n.*)+?)(Medications on Admission|___  on Admission|___ on Admission)\")\n","  pattern2  = re.compile(\"Brief Hospital Course.*\\n*((?:\\n.*)+?)Discharge Medications\")\n","  pattern3  = re.compile(\"(Brief Hospital Course|rief Hospital Course|HOSPITAL COURSE)\\\n","                        .*\\n*((?:\\n.*)+?)\\\n","                        (Medications on Admission|Discharge Medications|DISCHARGE MEDICATIONS|DISCHARGE DIAGNOSIS|Discharge Disposition|___ Disposition|CONDITION ON DISCHARGE|DISCHARGE INSTRUCTIONS)\")\n","  pattern4  = re.compile(\"(Mg-[12].|LACTATE-[12].|Epi-|Gap-|COUNT-|TRF-)___(.*\\n*((?:\\n.*)+?))(Medications on Admission)\")\n","\n","\n","  # Idea here is to try more convservaite pattern first, if not work, try less conservative pattern\n","  def split_note(note):\n","    if re.search(pattern1, note):\n","      return re.search(pattern1, note).group(1)\n","    else:\n","      if re.search(pattern2, note):\n","        return re.search(pattern2, note).group(1)\n","      else:\n","        if re.search(pattern3, note):\n","          return re.search(pattern3, note).group(2)\n","        else:\n","          if re.search(pattern4, note):\n","            return re.search(pattern4, note).group(2)\n","          else:\n","            return None\n","\n","  # Apply the function to dc_summary_raw to extract hospital course\n","  dc_summary_raw[\"hospital_course\"] = dc_summary_raw[\"text\"].apply(split_note)\n","\n","  # Drop those records that do not have hospital course captured with above regular expression patterns\n","  dc_summary = dc_summary_raw[[\"hadm_id\", \"hospital_course\"]].dropna()\n","\n","  # Get the number of words for each hospital course. Note that the current method is not accurate due to presense of special characters, but it's good enough for our purpose\n","  dc_summary[\"num_words\"] = dc_summary[\"hospital_course\"].apply(lambda x: len(x.split()))\n","\n","  # Remove the notes with less than 40 words\n","  dc_summary = dc_summary[dc_summary[\"num_words\"] > 40]\n","\n","  # Remove duplicate hospital courses (but keep the first one), as most of these notes represent low quality data\n","  dc_summary = dc_summary.drop_duplicates(subset=[\"hospital_course\"], keep=\"first\")\n","\n","  # Mean number of words in the hospital course is 378\n","  dc_summary[\"num_words\"].mean()\n","\n","  # only keep hadm_id and hospital_course\n","  dc_summary = dc_summary[[\"hadm_id\", \"hospital_course\"]]\n","\n","  return dc_summary\n","\n","##############Step 2: Map all DRG codes to MS-DRG v34.0#####################\n","# HCFA DRG is the MS-DRG code (https://github.com/MIT-LCP/mimic-code/issues/1561)\n","def map_drg(mimic_drg_path, drg_34_path, my_mapping_path):\n","\n","  drg = pd.read_csv(mimic_drg_path)\n","\n","  drg = drg[[\"hadm_id\", \"drg_code\", \"drg_type\", \"description\"]][drg[\"drg_type\"] == \"HCFA\"]\n","\n","  # We mapped all MS-DRG codes to v.34, which was released in 2016\n","  # Read the DRG v.34.0 codes from the csv file\n","  drg_34 = pd.read_csv(drg_34_path, sep=\"\\t\", header=0)\n","\n","  # Extra the set of all DRG description mentioned in the dataset\n","  drg_mapping = pd.DataFrame(drg[\"description\"].drop_duplicates())\n","\n","  # Create a second column called tranformation, which is to make basic normalizaiton of the DRG descriptions (e.g., W to WITH, W/O to WITHOUT, & to AND)\n","  drg_mapping[\"transformation\"] = drg_mapping[\"description\"].str.replace(\"W/O\", \"WITHOUT\").str.replace(\" W \", \" WITH \").str.replace(\"&\", \"AND\")\n","  drg_mapping[\"transformation\"] = drg_mapping[\"transformation\"].str.replace(\",\", \"\").str.replace(\" CATH \", \" CATHETERIZATION \").str.replace(\" PROC \", \" PROCEDURES \")\n","\n","  # Read the mapping rule to MS-DRG v.34\n","  my_mapping = pd.read_csv(my_mapping_path, header=0)\n","\n","  # create a dictionay from my_mapping, where raw_description is the key and DRG_34_description is the value\n","  my_mapping_dict = dict(zip(my_mapping.raw_description, my_mapping.DRG_34_description))\n","\n","  # Create a thrid column called drg_34_description, which copy the transformation column if the description is in drg_34\n","  # otherwide copy the value from my_mapping_dict where the key is the transformation\n","  drg_mapping[\"drg_34_description\"] = drg_mapping[\"transformation\"].where(drg_mapping[\"transformation\"].isin(drg_34.Description), other=drg_mapping[\"transformation\"].map(my_mapping_dict))\n","\n","  # check number of na in drg_34_description: 20\n","  drg_mapping.drg_34_description.isna().sum()\n","\n","  #rename the column name of description to raw_description\n","  drg_mapping = drg_mapping.rename(columns={\"description\": \"raw_description\"})\n","\n","  # Crate a table called drg_code_mapping by joining drg_mapping and drg_34 by drg_34_description\n","  drg_code_mapping = pd.merge(drg_mapping, drg_34, how=\"left\", left_on=\"drg_34_description\", right_on=\"Description\")\n","\n","  # make a dictinoary from drg_code_mapping, where raw_description is the key and DRG is the value\n","  drg_mapping_dict = dict(zip(drg_code_mapping.raw_description, drg_code_mapping.DRG))\n","\n","  # In the table drg, create a new column called drg_34_description, which is the mapped value from drg_mapping_dict where the key is description\n","  drg[\"drg_34_code\"] = drg[\"description\"].map(drg_mapping_dict)\n","\n","  # drop the rows with na in drg_34_code\n","  drg = drg.dropna(subset=[\"drg_34_code\"])\n","\n","  # only keep hadm_id and drg_34_code, and change drg_34_code to int\n","  drg = drg[[\"hadm_id\", \"drg_34_code\"]].astype({\"drg_34_code\": int})\n","\n","  return drg\n","\n","################Step 3. Merge discharge summary and drg, and split into training/testing sets#####################\n","#merge drg and dc_summary by hadm_id\n","def merge_HC_drg(dc_summary, drg):\n","\n","  dc_drg = pd.merge(dc_summary, drg, how=\"inner\", on=\"hadm_id\")\n","\n","  # remove drg_34_code with less than 2 observations\n","  # in this step removed code 998, 985 and 793\n","  dc_drg = dc_drg.groupby(\"drg_34_code\").filter(lambda x: len(x) >= 2)\n","\n","\n","  # number of unique drg_34_code in dc_drg: 738\n","  drg_count = dc_drg.drg_34_code.nunique()\n","\n","\n","  # rank dc_drg by drg_34_code\n","  dc_drg = dc_drg.sort_values(by=[\"drg_34_code\"])\n","\n","  # make a new dataframe called id2label, where the first column is drg_34_code and the second column is the rank of drg_34_code starting form 0 to 737\n","  id2label = pd.DataFrame(dc_drg.drg_34_code.drop_duplicates())\n","  id2label[\"label\"] = range(0, drg_count)\n","\n","  # in dc_drg, create a new column called label, which is the mapped value from id2label where the key is drg_34_code\n","  dc_drg[\"label\"] = dc_drg[\"drg_34_code\"].map(dict(zip(id2label.drg_34_code, id2label.label)))\n","\n","  # split dc_drc into train and test, test takes 10% of the data, set radoom state to 42, stratify by label\n","  train, test = train_test_split(dc_drg, test_size=0.1, random_state=42, stratify=dc_drg.label)\n","\n","  # rename hospital_course to text, remove column of hadm_id and drg_34_code, and save train and test to csv\n","  train = train.rename(columns={\"hospital_course\": \"text\"})\n","  test = test.rename(columns={\"hospital_course\": \"text\"})\n","  train = train[[\"text\", \"label\"]]\n","  test = test[[\"text\", \"label\"]]\n","\n","  return train, test, id2label\n","\n","if __name__ == \"__main__\":\n","    # Read path from the json file\n","  with open('paths.json', 'r') as f:\n","      path = json.load(f)\n","      dc_summary_path = path[\"dc_summary_path\"]\n","      mimic_drg_path = path[\"mimic_drg_path\"]\n","      drg_34_path = path[\"drg_34_path\"]\n","      my_mapping_path = path[\"my_mapping_path\"]\n","      train_set_path = path[\"train_set_path\"]\n","      test_set_path = path[\"test_set_path\"]\n","      id2label_path = path[\"id2label_path\"]\n","\n","\n","  drg = map_drg(mimic_drg_path, drg_34_path, my_mapping_path)\n","  dc_summary = extract_HC(dc_summary_path)\n","\n","  train, test, id2label = merge_HC_drg(dc_summary, drg)\n","\n","  id2label.to_csv(id2label_path, index=False)\n","  train.to_csv(train_set_path, index=False)\n","  test.to_csv(test_set_path, index=False)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":365},"id":"-gd3ng-DKTGS","executionInfo":{"status":"error","timestamp":1718091659161,"user_tz":-360,"elapsed":399,"user":{"displayName":"Rafsan Jany","userId":"08721334090885411304"}},"outputId":"d521529b-4e46-475a-9a94-a6dce46a5ab5"},"id":"-gd3ng-DKTGS","execution_count":null,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'drgcodes.csv'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-9653653e04af>\u001b[0m in \u001b[0;36m<cell line: 150>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m   \u001b[0mdrg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap_drg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmimic_drg_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrg_34_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmy_mapping_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m   \u001b[0mdc_summary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_HC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdc_summary_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-5-9653653e04af>\u001b[0m in \u001b[0;36mmap_drg\u001b[0;34m(mimic_drg_path, drg_34_path, my_mapping_path)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmap_drg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmimic_drg_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrg_34_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmy_mapping_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m   \u001b[0mdrg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmimic_drg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m   \u001b[0mdrg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdrg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"hadm_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"drg_code\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"drg_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"description\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdrg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"drg_type\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"HCFA\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    910\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1661\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1662\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1663\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'drgcodes.csv'"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import re\n","import json\n","\n","\n","\n","def drg_dissection(drg_34_path, train_set_path, test_set_path, id2label_path):\n","\n","  drg_34_dissection = pd.read_csv(drg_34_path, sep=\"\\t\", header=0)\n","\n","  # only keep the column on DRG and Description\n","  drg_34_dissection = drg_34_dissection[[\"DRG\", \"Description\"]]\n","\n","  # Make a new column called CC/MCC, where the value is 1 if the value in column Description contains \"WITH CC\" or \"W CC\"\n","  #  2 if the value in column Description contains \"WITH MCC\" or \"W MCC\", 0 if the value in column Description contains \"WITHOUT CC/MCC\" or \"W/O CC/MCC\"\n","  # 3 if the value in column Description contains \"WITHOUT MCC\"or \"W/O MCC\", else 4 (which essentially represents not applicable)\n","    # Note, in the approach here, with cc/mcc will be classified with cc\n","\n","  drg_34_dissection[\"CC/MCC\"] = drg_34_dissection[\"Description\"].apply(lambda x: 1 if (\"WITH CC\" in x) or (\"W CC\" in x) else\n","                                                                        (2 if (\"WITH MCC\" in x) or (\"W MCC\" in x) else\n","                                                                          (0 if (\"WITHOUT CC/MCC\" in x) or (\"W/O CC/MCC\" in x) else\n","                                                                            (3 if (\"WITHOUT MCC\" in x) or (\"W/O MCC\" in x) else 4))))\n","\n","\n","\n","  # Make a new collumn called principal_diagnosis, which uses regex to extraxt text before one of the following words:\n","  # \"WITH CC\", \"W CC\", \"WITH MCC\", \"W MCC\", \"WITHOUT CC/MCC\", \"W/O CC/MCC\", \"WITHOUT MCC\", \"W/O MCC\"\n","\n","  pc_patterh = r\"^(.*?)(?:WITH CC|W CC|WITH MCC|W MCC|WITHOUT CC/MCC|W/O CC/MCC|WITHOUT MCC|W/O MCC)\"\n","  def find_pc(note):\n","    if re.search(pc_patterh, note):\n","      return re.search(pc_patterh, note).group(1)\n","    else:\n","      return note\n","\n","  drg_34_dissection[\"principal_diagnosis\"] = drg_34_dissection[\"Description\"].apply(find_pc)\n","\n","  #In the column of principal_diagnosis, clean up some typo and inconsistence in the offical DRG 34 table\n","\n","  pattern_proc = '|'.join([\"PROEDURESC \", \"PROEDURESC \", \"PROCEDURSE \", \"PROC \", \"PROCEDURE \"])\n","\n","  drg_34_dissection[\"principal_diagnosis\"] = drg_34_dissection[\"principal_diagnosis\"].str.replace(pattern_proc,\"PROCEDURES \", regex=True)\n","  drg_34_dissection[\"principal_diagnosis\"] = drg_34_dissection[\"principal_diagnosis\"].str.replace(\"BILIARY TRACT PROCEDURES EXCEPT ONLY CHOLECYST \", \"BILIARY TRACT PROCEDURES EXCEPT ONLY CHOLECYSTECTOMY \", regex=True)\n","  drg_34_dissection[\"principal_diagnosis\"] = drg_34_dissection[\"principal_diagnosis\"].str.replace(\"CATHETERATION\",\"CATHETERIZATION\", regex=True)\n","  drg_34_dissection[\"principal_diagnosis\"] = drg_34_dissection[\"principal_diagnosis\"].str.replace(\"GASTROENTERISTIS\",\"GASTROENTERITIS\", regex=True)\n","  drg_34_dissection[\"principal_diagnosis\"] = drg_34_dissection[\"principal_diagnosis\"].str.replace(\"FIXATIOM\",\"FIXATION\", regex=True)\n","  drg_34_dissection[\"principal_diagnosis\"] = drg_34_dissection[\"principal_diagnosis\"].str.replace(\"CHEMOTHERPY\",\"CHEMOTHERAPY\", regex=True)\n","  drg_34_dissection[\"principal_diagnosis\"] = drg_34_dissection[\"principal_diagnosis\"].str.replace(\"REMOVAL INTERNAL\",\"REMOVAL OF INTERNAL\", regex=True)\n","  drg_34_dissection[\"principal_diagnosis\"] = drg_34_dissection[\"principal_diagnosis\"].str.replace(\"CHEMOTHERAPY WITH ACUTE LEUKEMIA AS SDX OR WITH HIGH DOSE CHEMOTHERAPY AGENT\",\"CHEMOTHERAPY WITH ACUTE LEUKEMIA AS SDX\", regex=True)\n","\n","\n","\n","  # Number of unique principal_diagnosis: 340\n","  PC_count = drg_34_dissection.principal_diagnosis.nunique()\n","  CC_count = 5\n","\n","  # Make a new collum called principal_diagnosis_lable, which is an interger from 0 to 340\n","  drg_34_dissection[\"principal_diagnosis_lable\"] = drg_34_dissection[\"principal_diagnosis\"].map(dict(zip(drg_34_dissection.principal_diagnosis.drop_duplicates(), range(0, PC_count))))\n","\n","  def to_categorical(y, num_classes):\n","      \"\"\" 1-hot encodes a tensor \"\"\"\n","      return np.eye(num_classes, dtype='uint8')[y]\n","\n","  # Make a new collum called multi_label, which is a one hot vector with 345 elements\n","  # The first 340 (0-339) elements are the one hot vector for principal_diagnosis_lable\n","  # The 340th to 344th (340-344) elements are the one hot vector for CC/MCC\n","  drg_34_dissection[\"multi_label\"] = drg_34_dissection.apply(lambda x: np.concatenate((to_categorical(x[\"principal_diagnosis_lable\"], num_classes=PC_count), to_categorical(x[\"CC/MCC\"], num_classes=CC_count))), axis=1)\n","\n","  # make a new collum called two_label, which is a list of two elements: principal_diagnosis_lable and CC/MCC\n","  drg_34_dissection[\"two_label\"] = drg_34_dissection.apply(lambda x: [x[\"principal_diagnosis_lable\"], x[\"CC/MCC\"]], axis=1)\n","\n","  ##make database\n","  train = pd.read_csv(train_set_path)\n","  test = pd.read_csv(test_set_path)\n","\n","  # read id to label mapping\n","  id2label = pd.read_csv(id2label_path)\n","\n","  # in train and test, add corresponding drg_34_code where label match the label in id2label\n","  train = train.merge(id2label, on=\"label\", how=\"left\")\n","  test = test.merge(id2label, on=\"label\", how=\"left\")\n","\n","  # in train and test, add column of multi_label where drg_34_code match the drg_34_code in drg_34_dissection\n","  train = train.merge(drg_34_dissection[[\"DRG\", \"multi_label\"]], left_on=\"drg_34_code\", right_on=\"DRG\", how=\"left\")\n","  test = test.merge(drg_34_dissection[[\"DRG\", \"multi_label\"]], left_on=\"drg_34_code\", right_on=\"DRG\", how=\"left\")\n","\n","\n","  # for train and test, only keep text and multi_label and rename multi_label to label\n","  train = train[[\"text\", \"multi_label\"]]\n","  train = train.rename(columns={\"multi_label\": \"label\"})\n","  test = test[[\"text\", \"multi_label\"]]\n","  test = test.rename(columns={\"multi_label\": \"label\"})\n","\n","  return train, test, drg_34_dissection\n","\n","if __name__ == \"__main__\":\n","    # Read path from the json file\n","  with open('paths.json', 'r') as f:\n","      path = json.load(f)\n","      drg_34_path = path[\"drg_34_path\"]\n","      drg_34_dissection_path = path[\"drg_34_dissection_path\"]\n","      train_set_path = path[\"train_set_path\"]\n","      test_set_path = path[\"test_set_path\"]\n","      id2label_path = path[\"id2label_path\"]\n","      multi_train_set_path = path[\"multi_train_set_path\"]\n","      multi_test_set_path = path[\"multi_test_set_path\"]\n","\n","  train, test, drg_34_dissection = drg_dissection(drg_34_path, train_set_path, test_set_path, id2label_path)\n","\n","  train.to_csv(multi_train_set_path, index=False)\n","  test.to_csv(multi_test_set_path, index=False)\n","  drg_34_dissection.to_csv(drg_34_dissection_path, index=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":365},"id":"sEbKCkn4KS82","executionInfo":{"status":"error","timestamp":1718091650662,"user_tz":-360,"elapsed":413,"user":{"displayName":"Rafsan Jany","userId":"08721334090885411304"}},"outputId":"5e77f303-1824-499f-f90d-36afb26cb851"},"id":"sEbKCkn4KS82","execution_count":null,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'new_train.csv'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-0816a3739911>\u001b[0m in \u001b[0;36m<cell line: 97>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    107\u001b[0m       \u001b[0mmulti_test_set_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"multi_test_set_path\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m   \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrg_34_dissection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdrg_dissection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrg_34_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_set_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_set_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid2label_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m   \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmulti_train_set_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-4-0816a3739911>\u001b[0m in \u001b[0;36mdrg_dissection\u001b[0;34m(drg_34_path, train_set_path, test_set_path, id2label_path)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m   \u001b[0;31m##make database\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m   \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m   \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_set_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    910\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1661\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1662\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1663\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'new_train.csv'"]}]},{"cell_type":"markdown","id":"d9794339","metadata":{"id":"d9794339"},"source":["# Combined Training Scripts"]},{"cell_type":"code","execution_count":null,"id":"d41faf97","metadata":{"id":"d41faf97"},"outputs":[],"source":["import os\n","from typing import List\n","import pandas as pd\n","from datetime import datetime\n","\n","\n","import fire\n","import torch\n","from datasets import load_dataset\n","\n","from transformers import DataCollatorWithPadding, TrainingArguments, Trainer\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification\n","import torch\n","import json\n","\n","from huggingface_hub import notebook_login\n","import numpy as np\n","\n","from utils.eval_utils import cls_metrics\n","from utils.gen_utils import create_folder\n","\n","\n","with open('paths.json', 'r') as f:\n","        path = json.load(f)\n","        train_set_path = path[\"train_set_path\"]\n","        test_set_path = path[\"test_set_path\"]\n","        catche_path = path[\"catche_path\"]\n","        output_path = path[\"output_path\"]\n","\n","def train(\n","    base_model: str = \"emilyalsentzer/Bio_ClinicalBERT\",  # the only required argument\n","    train_data_path: str = train_set_path,\n","    val_data_path: str = test_set_path,\n","    cache_dir: str = catche_path,\n","    split: int = 100,\n","    micro_batch_size: int = 16, # based on the previous recommended practice for classification-oriented fine-tuning of BERT (Devlin et al. 2018; Adhikari et al. 2019)\n","    num_epochs: int = 3,\n","    learning_rate: float = 2e-5,# 3e-4 is the learning rate used in the LLaMA paper\n","    cutoff_len: int = 512, # consider changing to 1024\n","    model_name: str = \"bert\",\n","    wandb_project: str = \"classification\", #other options: \"generative\", \"multilabel-classification\",\n","    wandb_watch: str = \"gradients\",  # options: false | gradients | all ; issues when using all: I have since bypassed this issue by only logging gradient and instead of all.\n","    wandb_log_model: str = \"\",  # options: false | true\n","    resume_from_checkpoint: str = None,  # either training checkpoint or final adapter\n","):\n","\n","    now = datetime.now()\n","    date_string = now.strftime(\"%B-%d-%H-%M\")\n","    wandb_run_name = f\"{model_name}-{cutoff_len}-{micro_batch_size}-{learning_rate}-{date_string}\"\n","    output_dir = create_folder(f'{output_path}/{wandb_project}', wandb_run_name)\n","\n","    # load file from train_data_path and find out the unique number of labels\n","    num_labels = pd.read_csv(train_data_path).label.nunique()\n","\n","    if int(os.environ.get(\"LOCAL_RANK\", 0)) == 0:\n","        print(\n","            f\"Training LLaMA-LoRA model with params:\\n\"\n","            f\"base_model: {base_model}\\n\"\n","            f\"train_data_path: {train_data_path}\\n\"\n","            f\"val_data_path: {val_data_path}\\n\"\n","            f\"output_dir: {output_dir}\\n\"\n","            f\"cache_dir: {cache_dir}\\n\"\n","            f\"micro_batch_size: {micro_batch_size}\\n\"\n","            f\"split: {split}\\n\"\n","            f\"num_labels: {num_labels}\\n\"\n","            f\"num_epochs: {num_epochs}\\n\"\n","            f\"learning_rate: {learning_rate}\\n\"\n","            f\"cutoff_len: {cutoff_len}\\n\"\n","            f\"wandb_project: {wandb_project}\\n\"\n","            f\"wandb_run_name: {wandb_run_name}\\n\"\n","            f\"wandb_watch: {wandb_watch}\\n\"\n","            f\"wandb_log_model: {wandb_log_model}\\n\"\n","            f\"resume_from_checkpoint: {resume_from_checkpoint or False}\\n\"\n","        )\n","    assert (\n","        base_model\n","    ), \"Please specify a --base_model, e.g. --base_model='huggyllama/llama-7b'\"\n","\n","\n","    device_map = \"auto\"\n","    world_size = int(os.environ.get(\"WORLD_SIZE\", 1))\n","    ddp = world_size != 1\n","    if ddp:\n","        device_map = {\"\": int(os.environ.get(\"LOCAL_RANK\") or 0)}\n","\n","    # Check if parameter passed or if set within environ\n","    use_wandb = len(wandb_project) > 0 or (\n","        \"WANDB_PROJECT\" in os.environ and len(os.environ[\"WANDB_PROJECT\"]) > 0\n","    )\n","    # Only overwrite environ if wandb param passed\n","    if len(wandb_project) > 0:\n","        os.environ[\"WANDB_PROJECT\"] = wandb_project\n","    if len(wandb_watch) > 0:\n","        os.environ[\"WANDB_WATCH\"] = wandb_watch\n","    if len(wandb_log_model) > 0:\n","        os.environ[\"WANDB_LOG_MODEL\"] = wandb_log_model\n","\n","\n","    model = AutoModelForSequenceClassification.from_pretrained(\n","        base_model,\n","        num_labels=num_labels,\n","        cache_dir=cache_dir)\n","\n","\n","    tokenizer = AutoTokenizer.from_pretrained(\n","        base_model,\n","        model_max_length=cutoff_len,\n","        cache_dir=cache_dir)\n","\n","\n","    def print_trainable_parameters(model):\n","        \"\"\"\n","        Prints the number of trainable parameters in the model.\n","        \"\"\"\n","        trainable_params = 0\n","        all_param = 0\n","        for _, param in model.named_parameters():\n","            all_param += param.numel()\n","            if param.requires_grad:\n","                trainable_params += param.numel()\n","        print(\n","            f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param:.2f}\"\n","        )\n","\n","    print_trainable_parameters(model)\n","\n","    for name, param in model.named_parameters():\n","        if param.requires_grad:\n","            print(name, param.shape)\n","\n","    def preprocess_function(examples):\n","        return tokenizer(examples[\"text\"], truncation=True)\n","\n","    train_data = load_dataset(\"csv\", data_files=train_data_path, split=f'train[:{split}%]')\n","    test_data = load_dataset(\"csv\", data_files=val_data_path, split=f'train[:{split}%]')\n","\n","    train_data= train_data.shard(num_shards=5000, index=0)\n","    test_data= test_data.shard(num_shards=2000, index=0)\n","\n","    tokenized_train = train_data.map(preprocess_function, batched=True)\n","    tokenized_test = test_data.map(preprocess_function, batched=True)\n","\n","\n","    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n","\n","    def compute_metrics(eval_pred):\n","        predictions, labels = eval_pred\n","        return cls_metrics(predictions, labels, class_num=num_labels)\n","\n","    training_args = TrainingArguments(\n","        output_dir=output_dir,\n","        learning_rate=learning_rate,\n","        per_device_train_batch_size=micro_batch_size,\n","        per_device_eval_batch_size=micro_batch_size,\n","        num_train_epochs=num_epochs,\n","        weight_decay=0.01,\n","        evaluation_strategy=\"epoch\",\n","        save_strategy=\"epoch\",\n","        save_total_limit=3,\n","        load_best_model_at_end=True,\n","        push_to_hub=False,\n","        ddp_find_unused_parameters=False if ddp else None,\n","        report_to=\"wandb\" if use_wandb else None,\n","        run_name=wandb_run_name if use_wandb else None,\n","        )\n","\n","    if not ddp and torch.cuda.device_count() > 1:\n","        # keeps Trainer from trying its own DataParallelism when more than 1 gpu is available\n","        model.is_parallelizable = True\n","        model.model_parallel = True\n","\n","\n","    trainer = Trainer(\n","        model=model,\n","        args=training_args,\n","        train_dataset=tokenized_train,\n","        eval_dataset=tokenized_test,\n","        tokenizer=tokenizer,\n","        data_collator=data_collator,\n","        compute_metrics=compute_metrics,\n","        )\n","\n","    model.config.use_cache = False\n","\n","    trainer.train(resume_from_checkpoint=resume_from_checkpoint)\n","\n","    model.save_pretrained(output_dir)\n","\n","\n","\n","if __name__ == \"__main__\":\n","    fire.Fire(train)"]},{"cell_type":"code","execution_count":null,"id":"bbf01751","metadata":{"id":"bbf01751"},"outputs":[],"source":["# Adopted framework from: https://github.com/tloen/alpaca-lora\n","\n","\n","import os\n","import pandas as pd\n","from datetime import datetime\n","import json\n","from typing import List\n","\n","import fire\n","import torch\n","from datasets import load_dataset\n","\n","from transformers import DataCollatorWithPadding, TrainingArguments, Trainer\n","from transformers import LlamaTokenizer, LlamaForSequenceClassification\n","from peft import (\n","    LoraConfig,\n","    get_peft_model,\n","    prepare_model_for_int8_training,\n","    set_peft_model_state_dict,\n","    TaskType\n",")\n","import torch\n","\n","from utils.eval_utils import cls_metrics\n","from utils.gen_utils import create_folder\n","\n","\n","with open('paths.json', 'r') as f:\n","        path = json.load(f)\n","        train_set_path = path[\"train_set_path\"]\n","        test_set_path = path[\"test_set_path\"]\n","        catche_path = path[\"catche_path\"]\n","        output_path = path[\"output_path\"]\n","\n","def train(\n","    # model/data params\n","    base_model: str = \"decapoda-research/llama-7b-hf\",  # the only required argument\n","    model_size: str = \"7b\",\n","    train_data_path: str = train_set_path,\n","    val_data_path: str = test_set_path,\n","    split: int = 100,\n","    cache_dir: str = catche_path,\n","    micro_batch_size: int = 4,\n","    num_epochs: int = 3,\n","    learning_rate: float = 2e-5,# 3e-4 is the learning rate used in the LLaMA paper\n","    cutoff_len: int = 512,\n","    lora_r: int = 8,\n","    lora_alpha: int = 16,\n","    lora_dropout: float = 0.05,\n","    lora_target_modules: List[str] = [\n","        \"q_proj\",\n","        \"k_proj\",\n","        \"v_proj\",\n","        \"o_proj\",\n","        \"score\"\n","    ],\n","    padding_side: str = \"right\",\n","    wandb_project: str = \"classification\",\n","    wandb_watch: str = \"gradients\",\n","    wandb_log_model: str = \"\",\n","    resume_from_checkpoint: str = None,  # either training checkpoint or final adapter\n","):\n","\n","    now = datetime.now()\n","    date_string = now.strftime(\"%B-%d-%H-%M\")\n","    wandb_run_name = f\"{model_size}-{cutoff_len}-{micro_batch_size}-{learning_rate}-{padding_side}-{date_string}\"\n","    output_dir = create_folder(f'{output_path}/{wandb_project}', wandb_run_name)\n","\n","    # load file from train_data_path and find out the unique number of labels\n","    num_labels = pd.read_csv(train_data_path).label.nunique()\n","\n","    if int(os.environ.get(\"LOCAL_RANK\", 0)) == 0:\n","        print(\n","            f\"Training LLaMA-LoRA model with params:\\n\"\n","            f\"base_model: {base_model}\\n\"\n","            f\"model_size: {model_size}\\n\"\n","            f\"train_data_path: {train_data_path}\\n\"\n","            f\"val_data_path: {val_data_path}\\n\"\n","            f\"output_dir: {output_dir}\\n\"\n","            f\"cache_dir: {cache_dir}\\n\"\n","            f\"micro_batch_size: {micro_batch_size}\\n\"\n","            f\"split: {split}\\n\"\n","            f\"num_labels: {num_labels}\\n\"\n","            f\"num_epochs: {num_epochs}\\n\"\n","            f\"learning_rate: {learning_rate}\\n\"\n","            f\"cutoff_len: {cutoff_len}\\n\"\n","            f\"lora_r: {lora_r}\\n\"\n","            f\"lora_alpha: {lora_alpha}\\n\"\n","            f\"lora_dropout: {lora_dropout}\\n\"\n","            f\"lora_target_modules: {lora_target_modules}\\n\"\n","            f\"padding_side: {padding_side}\\n\"\n","            f\"wandb_project: {wandb_project}\\n\"\n","            f\"wandb_run_name: {wandb_run_name}\\n\"\n","            f\"wandb_watch: {wandb_watch}\\n\"\n","            f\"wandb_log_model: {wandb_log_model}\\n\"\n","            f\"resume_from_checkpoint: {resume_from_checkpoint or False}\\n\"\n","        )\n","    assert (\n","        base_model\n","    ), \"Please specify a --base_model, e.g. --base_model='huggyllama/llama-7b'\"\n","\n","    device_map = \"auto\"\n","    world_size = int(os.environ.get(\"WORLD_SIZE\", 1))\n","    ddp = world_size != 1\n","    if ddp:\n","        device_map = {\"\": int(os.environ.get(\"LOCAL_RANK\") or 0)}\n","\n","    # Check if parameter passed or if set within environ\n","    use_wandb = len(wandb_project) > 0 or (\n","        \"WANDB_PROJECT\" in os.environ and len(os.environ[\"WANDB_PROJECT\"]) > 0\n","    )\n","    # Only overwrite environ if wandb param passed\n","    if len(wandb_project) > 0:\n","        os.environ[\"WANDB_PROJECT\"] = wandb_project\n","    if len(wandb_watch) > 0:\n","        os.environ[\"WANDB_WATCH\"] = wandb_watch\n","    if len(wandb_log_model) > 0:\n","        os.environ[\"WANDB_LOG_MODEL\"] = wandb_log_model\n","\n","\n","    model = LlamaForSequenceClassification.from_pretrained(\n","        base_model,\n","        num_labels=num_labels,\n","        load_in_8bit=True,\n","        torch_dtype=torch.float16,\n","        device_map=device_map,\n","        cache_dir=cache_dir)\n","\n","    tokenizer = LlamaTokenizer.from_pretrained(\n","        base_model,\n","        model_max_length=cutoff_len,\n","        cache_dir=cache_dir)\n","\n","    # This is to fix the bad token in \"decapoda-research/llama-7b-hf\"\n","\n","    model.config.pad_token_id = tokenizer.pad_token_id = 0  # unk\n","    model.config.bos_token_id = 1\n","    model.config.eos_token_id = 2\n","\n","    model = prepare_model_for_int8_training(model)\n","\n","    # note when passing task type as string argument, it will lead to error. May consider adding module_to_save manually\n","    config = LoraConfig(\n","        r=lora_r,\n","        lora_alpha=lora_alpha,\n","        target_modules=lora_target_modules,\n","        lora_dropout=lora_dropout,\n","        bias=\"none\",\n","        task_type=TaskType.SEQ_CLS,\n","        modules_to_save=None,\n","    )\n","    model = get_peft_model(model, config)\n","\n","    if resume_from_checkpoint:\n","        # Check the available weights and load them\n","        checkpoint_name = os.path.join(\n","            resume_from_checkpoint, \"pytorch_model.bin\"\n","        )  # Full checkpoint\n","        if not os.path.exists(checkpoint_name):\n","            checkpoint_name = os.path.join(\n","                resume_from_checkpoint, \"adapter_model.bin\"\n","            )  # only LoRA model - LoRA config above has to fit\n","            resume_from_checkpoint = (\n","                False  # So the trainer won't try loading its state\n","            )\n","        # The two files above have a different name depending on how they were saved, but are actually the same.\n","        if os.path.exists(checkpoint_name):\n","            print(f\"Restarting from {checkpoint_name}\")\n","            adapters_weights = torch.load(checkpoint_name)\n","            set_peft_model_state_dict(model, adapters_weights)\n","        else:\n","            print(f\"Checkpoint {checkpoint_name} not found\")\n","\n","    model.print_trainable_parameters()  # Be more transparent about the % of trainable params.\n","\n","    for name, param in model.named_parameters():\n","        if param.requires_grad:\n","            print(name, param.shape)\n","\n","    def preprocess_function(examples):\n","        return tokenizer(examples[\"text\"], truncation=True)\n","\n","    train_data = load_dataset(\"csv\", data_files=train_data_path, split=f'train[:{split}%]')\n","    test_data = load_dataset(\"csv\", data_files=val_data_path, split=f'train[:{split}%]')\n","\n","    # train_data= train_data.shard(num_shards=20000, index=0)\n","    # test_data= test_data.shard(num_shards=500, index=0)\n","\n","    tokenized_train = train_data.map(preprocess_function, batched=True).remove_columns([\"text\"]).rename_column(\"label\", \"labels\")\n","    tokenized_test = test_data.map(preprocess_function, batched=True).remove_columns([\"text\"]).rename_column(\"label\", \"labels\")\n","\n","    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n","\n","    def compute_metrics(eval_pred):\n","        predictions, labels = eval_pred\n","        return cls_metrics(predictions, labels, class_num=num_labels)\n","\n","    training_args = TrainingArguments(\n","        output_dir=output_dir,\n","        learning_rate=learning_rate,\n","        per_device_train_batch_size=micro_batch_size,\n","        per_device_eval_batch_size=micro_batch_size,\n","        num_train_epochs=num_epochs,\n","        weight_decay=0.01,\n","        fp16=True,\n","        evaluation_strategy=\"epoch\",\n","        save_strategy=\"epoch\",\n","        save_total_limit=3,\n","        load_best_model_at_end=True,\n","        push_to_hub=False,\n","        remove_unused_columns=False,\n","        label_names=[\"labels\"],\n","        ddp_find_unused_parameters=False if ddp else None,\n","        report_to=\"wandb\" if use_wandb else None,\n","        run_name=wandb_run_name if use_wandb else None,\n","        )\n","\n","    if not ddp and torch.cuda.device_count() > 1:\n","        # keeps Trainer from trying its own DataParallelism when more than 1 gpu is available\n","        model.is_parallelizable = True\n","        model.model_parallel = True\n","\n","\n","    trainer = Trainer(\n","        model=model,\n","        args=training_args,\n","        train_dataset=tokenized_train,\n","        eval_dataset=tokenized_test,\n","        tokenizer=tokenizer,\n","        data_collator=data_collator,\n","        compute_metrics=compute_metrics,\n","        )\n","\n","    model.config.use_cache = False\n","\n","    trainer.train(resume_from_checkpoint=resume_from_checkpoint)\n","\n","    model.save_pretrained(output_dir)\n","\n","\n","if __name__ == \"__main__\":\n","\n","    fire.Fire(train)"]},{"cell_type":"code","execution_count":null,"id":"4277ef28","metadata":{"id":"4277ef28"},"outputs":[],"source":["import os\n","from typing import List\n","import pandas as pd\n","from datetime import datetime\n","\n","\n","import fire\n","import torch\n","from datasets import load_dataset, Dataset\n","\n","from transformers import DataCollatorWithPadding, TrainingArguments, Trainer\n","from transformers import LlamaTokenizer, LlamaForSequenceClassification\n","\n","from torch.nn import CrossEntropyLoss\n","from transformers.modeling_outputs import SequenceClassifierOutputWithPast\n","from utils.eval_utils import cls_metrics_multi\n","\n","from peft import (\n","    LoraConfig,\n","    get_peft_model,\n","    prepare_model_for_int8_training,\n","    set_peft_model_state_dict,\n","    TaskType\n",")\n","import torch\n","import json\n","import numpy as np\n","\n","from utils.gen_utils import create_folder\n","\n","with open('paths.json', 'r') as f:\n","        path = json.load(f)\n","        multi_train_set_path = path[\"multi_train_set_path\"]\n","        multi_test_set_path = path[\"multi_test_set_path\"]\n","        catche_path = path[\"catche_path\"]\n","        output_path = path[\"output_path\"]\n","        drg_34_dissection_path = path[\"drg_34_dissection_path\"]\n","\n","def train(\n","    base_model: str = \"decapoda-research/llama-7b-hf\",  # the only required argument\n","    model_size: str = \"7b\",\n","    train_data_path: str = multi_train_set_path,\n","    val_data_path: str = multi_test_set_path,\n","    drg_mapping_path: str = drg_34_dissection_path,\n","    cache_dir: str = catche_path,\n","    split: int = 100,\n","    micro_batch_size: int = 4,\n","    num_epochs: int = 3,\n","    learning_rate: float = 2e-5,# 3e-4 is the learning rate used in the LLaMA paper\n","    cutoff_len: int = 512, # consider changing to 1024\n","    lora_r: int = 8,\n","    lora_alpha: int = 16,\n","    lora_dropout: float = 0.05,\n","    lora_target_modules: List[str] = [\n","        \"q_proj\",\n","        \"k_proj\",\n","        \"v_proj\",\n","        \"o_proj\",\n","        \"score\"\n","    ],\n","    padding_side: str = \"right\",\n","    wandb_project: str = \"multilabel-classification\", #other options: \"generative\", \"multilabel-classification\",\n","    wandb_watch: str = \"gradients\",  # options: false | gradients | all ; issues when using all: I have since bypassed this issue by only logging gradient and instead of all.\n","    wandb_log_model: str = \"\",  # options: false | true\n","    resume_from_checkpoint: str = None,  # either training checkpoint or final adapter\n","):\n","\n","    now = datetime.now()\n","    date_string = now.strftime(\"%B-%d-%H-%M\")\n","    wandb_run_name = f\"{model_size}-{cutoff_len}-{micro_batch_size}-{learning_rate}-{padding_side}-{date_string}\"\n","    output_dir = create_folder(f'{output_path}/{wandb_project}', wandb_run_name)\n","\n","    # load file from train_data_path and find out the unique number of labels\n","    num_labels_pc = pd.read_csv(drg_mapping_path).principal_diagnosis_lable.nunique()\n","    num_labels_cc = pd.read_csv(drg_mapping_path)[\"CC/MCC\"].nunique()\n","    num_labels = num_labels_pc + num_labels_cc\n","\n","    train_data = pd.read_csv(train_data_path, converters={\"label\": lambda x: np.fromstring(x[1:-1], dtype=float, sep=\" \")})\n","    test_data = pd.read_csv(val_data_path, converters={\"label\": lambda x: np.fromstring(x[1:-1], dtype=float, sep=\" \")})\n","\n","    if int(os.environ.get(\"LOCAL_RANK\", 0)) == 0:\n","        print(\n","            f\"Training LLaMA-LoRA model with params:\\n\"\n","            f\"base_model: {base_model}\\n\"\n","            f\"model_size: {model_size}\\n\"\n","            f\"train_data_path: {train_data_path}\\n\"\n","            f\"val_data_path: {val_data_path}\\n\"\n","            f\"output_dir: {output_dir}\\n\"\n","            f\"cache_dir: {cache_dir}\\n\"\n","            f\"micro_batch_size: {micro_batch_size}\\n\"\n","            f\"split: {split}\\n\"\n","            f\"num_labels_pc: {num_labels_pc}\\n\"\n","            f\"num_labels_cc: {num_labels_cc}\\n\"\n","            f\"num_labels: {num_labels}\\n\"\n","            f\"num_epochs: {num_epochs}\\n\"\n","            f\"num_train_data: {len(train_data)}\\n\"\n","            f\"num_test_data: {len(test_data)}\\n\"\n","            f\"learning_rate: {learning_rate}\\n\"\n","            f\"cutoff_len: {cutoff_len}\\n\"\n","            f\"lora_r: {lora_r}\\n\"\n","            f\"lora_alpha: {lora_alpha}\\n\"\n","            f\"lora_dropout: {lora_dropout}\\n\"\n","            f\"lora_target_modules: {lora_target_modules}\\n\"\n","            f\"padding_side: {padding_side}\\n\"\n","            f\"wandb_project: {wandb_project}\\n\"\n","            f\"wandb_run_name: {wandb_run_name}\\n\"\n","            f\"wandb_watch: {wandb_watch}\\n\"\n","            f\"wandb_log_model: {wandb_log_model}\\n\"\n","            f\"resume_from_checkpoint: {resume_from_checkpoint or False}\\n\"\n","        )\n","    assert (\n","        base_model\n","    ), \"Please specify a --base_model, e.g. --base_model='huggyllama/llama-7b'\"\n","\n","\n","    device_map = \"auto\"\n","    world_size = int(os.environ.get(\"WORLD_SIZE\", 1))\n","    ddp = world_size != 1\n","    if ddp:\n","        device_map = {\"\": int(os.environ.get(\"LOCAL_RANK\") or 0)}\n","\n","    # Check if parameter passed or if set within environ\n","    use_wandb = len(wandb_project) > 0 or (\n","        \"WANDB_PROJECT\" in os.environ and len(os.environ[\"WANDB_PROJECT\"]) > 0\n","    )\n","    # Only overwrite environ if wandb param passed\n","    if len(wandb_project) > 0:\n","        os.environ[\"WANDB_PROJECT\"] = wandb_project\n","    if len(wandb_watch) > 0:\n","        os.environ[\"WANDB_WATCH\"] = wandb_watch\n","    if len(wandb_log_model) > 0:\n","        os.environ[\"WANDB_LOG_MODEL\"] = wandb_log_model\n","\n","\n","    class LlamaForMultilabelSequenceClassification(LlamaForSequenceClassification):\n","        def __init__(self, config):\n","            super().__init__(config)\n","\n","        def forward(self,\n","            input_ids=None,\n","            attention_mask=None,\n","            position_ids=None,\n","            past_key_values=None,\n","            inputs_embeds=None,\n","            labels=None,\n","            use_cache = None,\n","            output_attentions=None,\n","            output_hidden_states=None,\n","            return_dict=None):\n","            return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n","\n","            transformer_outputs = self.model(\n","                input_ids,\n","                attention_mask=attention_mask,\n","                position_ids=position_ids,\n","                past_key_values=past_key_values,\n","                inputs_embeds=inputs_embeds,\n","                use_cache=use_cache,\n","                output_attentions=output_attentions,\n","                output_hidden_states=output_hidden_states,\n","                return_dict=return_dict,\n","            )\n","            hidden_states = transformer_outputs[0]\n","            logits = self.score(hidden_states)\n","\n","            if input_ids is not None:\n","                batch_size = input_ids.shape[0]\n","            else:\n","                batch_size = inputs_embeds.shape[0]\n","\n","            if self.config.pad_token_id is None and batch_size != 1:\n","                raise ValueError(\"Cannot handle batch sizes > 1 if no padding token is defined.\")\n","            if self.config.pad_token_id is None:\n","                sequence_lengths = -1\n","            else:\n","                if input_ids is not None:\n","                    sequence_lengths = (torch.ne(input_ids, self.config.pad_token_id).sum(-1) - 1).to(logits.device)\n","                else:\n","                    sequence_lengths = -1\n","\n","            pooled_logits = logits[torch.arange(batch_size, device=logits.device), sequence_lengths]\n","\n","            loss = None\n","            if labels is not None:\n","                labels = labels.to(logits.device)\n","                loss_fct_pc = CrossEntropyLoss()\n","                loss_fct_cc = CrossEntropyLoss()\n","\n","                logits_pc = pooled_logits[:, :num_labels_pc]\n","                labels_onehot_pc = labels[:, :num_labels_pc]\n","                labels_pc = torch.argmax(labels_onehot_pc, axis=1)\n","\n","                logits_cc = pooled_logits[:, num_labels_pc:]\n","                labels_onehot_cc = labels[:, num_labels_pc:]\n","                labels_cc = torch.argmax(labels_onehot_cc, axis=1)\n","\n","                loss_pc = loss_fct_pc(logits_pc, labels_pc)\n","                loss_cc = loss_fct_cc(logits_cc, labels_cc)\n","                loss = loss_pc + 0.5*loss_cc\n","            if not return_dict:\n","                output = (pooled_logits,) + transformer_outputs[1:]\n","                return ((loss,) + output) if loss is not None else output\n","\n","            return SequenceClassifierOutputWithPast(\n","                loss=loss,\n","                logits=pooled_logits,\n","                past_key_values=transformer_outputs.past_key_values,\n","                hidden_states=transformer_outputs.hidden_states,\n","                attentions=transformer_outputs.attentions,\n","            )\n","\n","\n","    model = LlamaForMultilabelSequenceClassification.from_pretrained(\n","        base_model,\n","        num_labels=num_labels,\n","        load_in_8bit=True,\n","        problem_type=\"multi_label_classification\",\n","        torch_dtype=torch.float16,\n","        device_map=device_map,\n","        cache_dir=cache_dir)\n","\n","    tokenizer = LlamaTokenizer.from_pretrained(\n","        base_model,\n","        model_max_length=cutoff_len,\n","        cache_dir=cache_dir)\n","\n","    # This is to fix the bad token in \"decapoda-research/llama-7b-hf\"\n","    model.config.pad_token_id = tokenizer.pad_token_id = 0  # unk\n","    model.config.bos_token_id = 1\n","    model.config.eos_token_id = 2\n","\n","    model = prepare_model_for_int8_training(model)\n","\n","    config = LoraConfig(\n","        r=lora_r,\n","        lora_alpha=lora_alpha,\n","        target_modules=lora_target_modules,\n","        lora_dropout=lora_dropout,\n","        bias=\"none\",\n","        task_type=TaskType.SEQ_CLS,\n","        modules_to_save=None\n","    )\n","    model = get_peft_model(model, config)\n","\n","    if resume_from_checkpoint:\n","        # Check the available weights and load them\n","        checkpoint_name = os.path.join(\n","            resume_from_checkpoint, \"pytorch_model.bin\"\n","        )  # Full checkpoint\n","        if not os.path.exists(checkpoint_name):\n","            checkpoint_name = os.path.join(\n","                resume_from_checkpoint, \"adapter_model.bin\"\n","            )  # only LoRA model - LoRA config above has to fit\n","            resume_from_checkpoint = (\n","                False  # So the trainer won't try loading its state\n","            )\n","        # The two files above have a different name depending on how they were saved, but are actually the same.\n","        if os.path.exists(checkpoint_name):\n","            print(f\"Restarting from {checkpoint_name}\")\n","            adapters_weights = torch.load(checkpoint_name)\n","            set_peft_model_state_dict(model, adapters_weights)\n","        else:\n","            print(f\"Checkpoint {checkpoint_name} not found\")\n","\n","    model.print_trainable_parameters()  # Be more transparent about the % of trainable params.\n","\n","    for name, param in model.named_parameters():\n","        if param.requires_grad:\n","            print(name, param.shape)\n","\n","    def preprocess_function(examples):\n","        return tokenizer(examples[\"text\"], truncation=True)\n","\n","    train_data = Dataset.from_pandas(train_data)\n","    test_data = Dataset.from_pandas(test_data)\n","\n","    # train_data= train_data.shard(num_shards=5000, index=0)\n","    # test_data= test_data.shard(num_shards=5000, index=0)\n","\n","    tokenized_train = train_data.map(preprocess_function, batched=True).remove_columns([\"text\"]).rename_column(\"label\", \"labels\")\n","    tokenized_test = test_data.map(preprocess_function, batched=True).remove_columns([\"text\"]).rename_column(\"label\", \"labels\")\n","\n","    # default is padding to longest\n","    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n","\n","    def compute_metrics_multi(eval_pred):\n","        predictions, labels = eval_pred\n","        return cls_metrics_multi(y_pred=predictions, y=labels)\n","\n","    # Other hyperparameters to consider here is gradient_accumulation_steps, weight decay, learning rate, adam etype\n","    training_args = TrainingArguments(\n","        output_dir=output_dir,\n","        learning_rate=learning_rate,\n","        per_device_train_batch_size=micro_batch_size,\n","        per_device_eval_batch_size=micro_batch_size,\n","        num_train_epochs=num_epochs,\n","        weight_decay=0.01,\n","        fp16=True,\n","        evaluation_strategy=\"epoch\",\n","        save_strategy=\"epoch\",\n","        save_total_limit=3,\n","        load_best_model_at_end=True,\n","        push_to_hub=False,\n","        remove_unused_columns=False,\n","        label_names=[\"labels\"],\n","        ddp_find_unused_parameters=False if ddp else None,\n","        report_to=\"wandb\" if use_wandb else None,\n","        run_name=wandb_run_name if use_wandb else None,\n","        )\n","\n","    if not ddp and torch.cuda.device_count() > 1:\n","        # keeps Trainer from trying its own DataParallelism when more than 1 gpu is available\n","        model.is_parallelizable = True\n","        model.model_parallel = True\n","\n","\n","    trainer = Trainer(\n","        model=model,\n","        args=training_args,\n","        train_dataset=tokenized_train,\n","        eval_dataset=tokenized_test,\n","        tokenizer=tokenizer,\n","        data_collator=data_collator,\n","        compute_metrics=compute_metrics_multi,\n","        )\n","\n","    model.config.use_cache = False\n","\n","    trainer.train(resume_from_checkpoint=resume_from_checkpoint)\n","\n","    model.save_pretrained(output_dir)\n","\n","if __name__ == \"__main__\":\n","    fire.Fire(train)"]},{"cell_type":"code","execution_count":null,"id":"ef33fa42","metadata":{"id":"ef33fa42"},"outputs":[],"source":["# Adopted from https://github.com/JHLiu7/EarlyDRGPrediction\n","\n","\n","import math\n","import pandas as pd\n","import numpy as np\n","import pickle as pk\n","import json\n","\n","\n","from sklearn.metrics import auc, roc_curve, precision_recall_curve, f1_score, accuracy_score\n","from sklearn.metrics import mean_absolute_error, mean_squared_error\n","from scipy.stats import pearsonr, spearmanr\n","\n","with open('paths.json', 'r') as f:\n","    path = json.load(f)\n","    drg_34_dissection_path = path[\"drg_34_dissection_path\"]\n","\n","# read a csv file but only read in the column of principal_diagnosis_lable and CC/MCC\n","pc_cc_mapping = pd.read_csv(drg_34_dissection_path)[[\"principal_diagnosis_lable\", \"CC/MCC\"]]\n","num_labels_pc = pc_cc_mapping.principal_diagnosis_lable.nunique()\n","\n","# make a dictinoary where key is principal_diagnosis_lable and value is CC/MCC. For one key there can be multiple values\n","pc_cc_dict = {}\n","for index, row in pc_cc_mapping.iterrows():\n","    if row[\"principal_diagnosis_lable\"] not in pc_cc_dict:\n","        pc_cc_dict[row[\"principal_diagnosis_lable\"]] = [row[\"CC/MCC\"]]\n","    else:\n","        pc_cc_dict[row[\"principal_diagnosis_lable\"]].append(row[\"CC/MCC\"])\n","\n","\n","\n","def map_rule(pred_pc, label_pc, pred_cc, label_cc):\n","    if pred_pc == label_pc:\n","        if pred_cc == label_cc:\n","            return True\n","        # if there's only one cc/MCC code of this principal diagnosis code, then any predcitons would be right\n","        elif len(pc_cc_dict[label_pc]) == 1:\n","            return True\n","        elif pred_cc in pc_cc_dict[label_pc] and pred_cc != label_cc:\n","            return False\n","        # for this group, default is to group 0\n","        elif set(pc_cc_dict[label_pc]) == {2, 1, 0}:\n","            mark_cc = 0\n","            if mark_cc == label_cc:\n","                return True\n","            else:\n","                return False\n","        # for this group, default is to group 3: without MCC\n","        elif set(pc_cc_dict[label_pc]) == {2, 3}:\n","            mark_cc = 3\n","            if mark_cc == label_cc:\n","                return True\n","            else:\n","                return False\n","        # for this group, there are two scenario. With MCC wil default to group 1, others will default to group 0\n","        elif set(pc_cc_dict[label_pc]) == {1, 0}:\n","            if pred_cc == 2:\n","                mark_cc = 1\n","            else:\n","                mark_cc = 0\n","            if mark_cc == label_cc:\n","                return True\n","            else:\n","                return False\n","    return False\n","\n","map_rule(12,12,1,2)\n","\n","\n","def accuracies_map(y_pred_pc, labels_pc, y_pred_cc, labels_cc):\n","    acc = 0.0\n","    num = len(y_pred_pc)\n","\n","    for i in range(num):\n","        if map_rule(y_pred_pc[i], labels_pc[i], y_pred_cc[i], labels_cc[i]):\n","            acc += 1.\n","    acc /= num\n","\n","    return acc\n","\n","\n","# full evaluation\n","def full_metrics(y_pred, y, drg_rule, d2i):\n","    y_pred_w, y_w = map2weight(y_pred, y, drg_rule=drg_rule, d2i=d2i)\n","\n","    reg_dict = reg_metrics(y_pred_w, y_w)\n","\n","    full_dict = {}\n","    full_dict.update(reg_dict)\n","\n","    cls_dict = cls_metrics(y_pred, y, len(d2i))\n","    full_dict.update(cls_dict)\n","\n","    return full_dict\n","\n","def cls_metrics(y_pred, y, class_num):\n","    # class_num = args.Y\n","    y_pred_ = softmax(y_pred)\n","    y_ = onehot_encode(y, class_num)\n","\n","    macroAUC, microAUC, appeared, cases = ave_auc_scores(y_pred_, y_)\n","    macroF1, microF1 = ave_f1_scores(y_pred, y)\n","\n","    metric_dict = {\n","        'microF1':microF1, 'macroF1':macroF1,\n","        'microAUC':microAUC, 'macroAUC':macroAUC,\n","        'labels': appeared, 'count': cases\n","    }\n","\n","    metric_dict['acc10'], metric_dict['acc5'], metric_dict['acc'], _ = accuracies(y_pred, y)\n","    return metric_dict\n","\n","def cls_metrics_eval(y_pred, y, class_num):\n","    # class_num = args.Y\n","    y_pred_ = softmax(y_pred)\n","    y_ = onehot_encode(y, class_num)\n","\n","    macroAUC, microAUC, appeared, cases = ave_auc_scores(y_pred_, y_)\n","    macroF1, microF1 = ave_f1_scores(y_pred, y)\n","\n","    metric_dict = {\n","        'microF1':microF1, 'macroF1':macroF1,\n","        'microAUC':microAUC, 'macroAUC':macroAUC,\n","        'labels': appeared, 'count': cases\n","    }\n","\n","    metric_dict['acc10'], metric_dict['acc5'], metric_dict['acc'], _ = accuracies(y_pred, y)\n","    metric_dict['y_label'] = y\n","    metric_dict['y_raw'] = y_pred\n","    # https://stackoverflow.com/questions/16486252/is-it-possible-to-use-argsort-in-descending-order\n","    metric_dict['y_raw_top5'] = (-y_pred).argsort(axis=1)[:, :5]\n","    metric_dict['y_pred'] = np.argmax(y_pred_, axis=1)\n","\n","    return metric_dict\n","\n","def cls_metrics_multi(y_pred, y):\n","    # class_num = args.Y\n","    predictions_pc = y_pred[:, :num_labels_pc]\n","    y_pred_pc = softmax(predictions_pc)\n","    labels_onehot_pc = y[:, :num_labels_pc]\n","    labels_pc = np.argmax(labels_onehot_pc, axis=1)\n","    predictions_cc = y_pred[:, num_labels_pc:]\n","    y_pred_cc = softmax(predictions_cc)\n","    labels_onehot_cc = y[:, num_labels_pc:]\n","    labels_cc = np.argmax(labels_onehot_cc, axis=1)\n","\n","    ## Need to double check it mirrows the original methods\n","\n","    macroAUC_pc, microAUC_pc, appeared_pc, cases_pc = ave_auc_scores(y_pred_pc, labels_onehot_pc)\n","    macroF1_pc, microF1_pc = ave_f1_scores(predictions_pc, labels_pc)\n","    acc10_pc, acc5_pc, acc_pc, _ = accuracies(predictions_pc, labels_pc)\n","\n","    macroAUC_cc, microAUC_cc, appeared_cc, cases_cc = ave_auc_scores(y_pred_cc, labels_onehot_cc)\n","    macroF1_cc, microF1_cc = ave_f1_scores(predictions_cc, labels_cc)\n","    acc10_cc, acc5_cc, acc_cc, _ = accuracies(predictions_cc, labels_cc)\n","\n","    y_pred_pc_single = np.argmax(y_pred_pc, axis=1)\n","    y_pred_cc_single = np.argmax(y_pred_cc, axis=1)\n","\n","    acc_map = accuracies_map(y_pred_pc_single, labels_pc, y_pred_cc_single, labels_cc)\n","\n","    metric_dict = {\n","        'acc_map': acc_map,\n","        'microF1_pc':microF1_pc, 'macroF1_pc':macroF1_pc,\n","        'microAUC_pc':microAUC_pc, 'macroAUC_pc':macroAUC_pc,\n","        'labels_pc': appeared_pc, 'count_pc': cases_pc,\n","        'acc10_pc': acc10_pc, 'acc5_pc': acc5_pc, 'acc_pc': acc_pc,\n","        'microF1_cc':microF1_cc, 'macroF1_cc':macroF1_cc,\n","        'microAUC_cc':microAUC_cc, 'macroAUC_cc':macroAUC_cc,\n","        'labels_cc': appeared_cc, 'count_cc': cases_cc,\n","        'acc10_cc': acc10_cc, 'acc5_cc': acc5_cc, 'acc_cc': acc_cc\n","    }\n","\n","    return metric_dict\n","\n","def reg_metrics(y_pred, y):\n","    mae = mean_absolute_error(y_pred, y)\n","    mse = mean_squared_error(y_pred,  y)\n","    spearman, p = spearmanr(y_pred, y)\n","\n","    metric_dict = {\n","        'MAE': mae, 'MSE': mse, 'RMSE': math.sqrt(mse),\n","        'spearman': spearman, 'corr_p': p\n","    }\n","\n","    dist= y_pred - y\n","    cmi = np.mean(dist)\n","    overshot, undershot = len(dist[dist>0]), len(dist[dist<0])\n","\n","    metric_dict.update({\n","        'CMI_error': cmi/np.mean(y), 'CMI_raw':cmi, 'overshot': overshot, 'undershot': undershot\n","    })\n","    return metric_dict\n","\n","def cls_metrics_multi_eval(y_pred, y):\n","    # class_num = args.Y\n","\n","    predictions_pc = y_pred[:, :num_labels_pc]\n","    y_pred_pc = softmax(predictions_pc)\n","    labels_onehot_pc = y[:, :num_labels_pc]\n","    labels_pc = np.argmax(labels_onehot_pc, axis=1)\n","    predictions_cc = y_pred[:, num_labels_pc:]\n","    y_pred_cc = softmax(predictions_cc)\n","    labels_onehot_cc = y[:, num_labels_pc:]\n","    labels_cc = np.argmax(labels_onehot_cc, axis=1)\n","\n","    ## Need to double check it mirrows the original methods\n","\n","    macroAUC_pc, microAUC_pc, appeared_pc, cases_pc = ave_auc_scores(y_pred_pc, labels_onehot_pc)\n","    macroF1_pc, microF1_pc = ave_f1_scores(predictions_pc, labels_pc)\n","    acc10_pc, acc5_pc, acc_pc, _ = accuracies(predictions_pc, labels_pc)\n","\n","    macroAUC_cc, microAUC_cc, appeared_cc, cases_cc = ave_auc_scores(y_pred_cc, labels_onehot_cc)\n","    macroF1_cc, microF1_cc = ave_f1_scores(predictions_cc, labels_cc)\n","    acc10_cc, acc5_cc, acc_cc, _ = accuracies(predictions_cc, labels_cc)\n","\n","    y_pred_pc_single = np.argmax(y_pred_pc, axis=1)\n","    y_pred_cc_single = np.argmax(y_pred_cc, axis=1)\n","\n","    acc_map = accuracies_map(y_pred_pc_single, labels_pc, y_pred_cc_single, labels_cc)\n","\n","    metric_dict = {\n","        'acc_map': acc_map,\n","        'microF1_pc':microF1_pc, 'macroF1_pc':macroF1_pc,\n","        'microAUC_pc':microAUC_pc, 'macroAUC_pc':macroAUC_pc,\n","        'labels_pc': appeared_pc, 'count_pc': cases_pc,\n","        'acc10_pc': acc10_pc, 'acc5_pc': acc5_pc, 'acc_pc': acc_pc,\n","        'microF1_cc':microF1_cc, 'macroF1_cc':macroF1_cc,\n","        'microAUC_cc':microAUC_cc, 'macroAUC_cc':macroAUC_cc,\n","        'labels_cc': appeared_cc, 'count_cc': cases_cc,\n","        'acc10_cc': acc10_cc, 'acc5_cc': acc5_cc, 'acc_cc': acc_cc\n","    }\n","\n","    metric_dict['y_label'] = y\n","    metric_dict['y_raw'] = y_pred\n","\n","    return metric_dict\n","\n","\n","# to print out results\n","def result2str(d):\n","    try:\n","        mif, maf = d['microF1'], d['macroF1']\n","        mia, maa = d['microAUC'], d['macroAUC']\n","        a10, a5, a = d['acc10'], d['acc5'], d['acc']\n","        la, ct = d['labels'], d['count']\n","    except:\n","        pass\n","    ma, rm = d['MAE'], d['RMSE']\n","    sp, p = d['spearman'], d['corr_p']\n","    cm,ov,ud = d['CMI_error'], d['overshot'], d['undershot']\n","\n","    title = \"****\" * 5 + '\\n'\n","    try:\n","        s1 = \"{} cases, {} labels\".format(ct, la)\n","        s2 = \"MACRO-AUC     \\tMICRO-AUC      \\tMACRO-F1     \\tMICRO-F1  \"\n","        s3 = \"{:.4f}  \\t{:.4f}  \\t{:.4f}  \\t{:.4f}\".format(maa, mia, maf, mif)\n","        s4 = \"Acc10  \\tAcc5  \\tAcc \"\n","        s5 = \"{:.4f}  \\t{:.4f}  \\t{:.4f}  \\n\".format(a10, a5, a)\n","        title = title+'\\n'.join([s1, s2, s3, s4, s5])\n","    except:\n","        pass\n","    r1 = \"MAE: {:.4f}  RMSE: {:.4f}  Corr: {:.4f}  \\n\".format(ma, rm, sp)\n","    r2 = \"CMI_error: {:.2%}  overshot: {}  undershot: {}  \\n\\n\".format(cm,ov,ud)\n","\n","    title = title+'\\n'.join([r1, r2])\n","\n","    return title\n","\n","\n","# running evaluation\n","def score_f1(y_pred, y):\n","    \"\"\"\n","        y_pred: logit\n","    \"\"\"\n","    y_flat = np.argmax(y_pred, axis=1)\n","    return f1_score(y, y_flat, average='micro')\n","\n","def score_mae(y_pred, y):\n","    return mean_absolute_error(y_pred, y)\n","\n","\n","# utils\n","def map2weight(y_pred, y, drg_rule, d2i):\n","\n","    idx2drg = {v:k for k,v in d2i.items()}\n","    drg2weight = {}\n","    for _, row in drg_rule.iterrows():\n","        drg2weight[row['DRG_CODE']] = row['WEIGHT']\n","\n","    y_pred = [drg2weight[idx2drg[d]] for d in np.argmax(y_pred, axis=1)]\n","    y = [drg2weight[idx2drg[d]] for d in y]\n","    return np.array(y_pred), np.array(y)\n","\n","def softmax(x):\n","    e_x = np.exp(x)\n","    return e_x / np.expand_dims(e_x.sum(axis=1), 1)\n","\n","def onehot_encode(y, class_num):\n","    \"\"\"\n","        y: a flat array of labels\n","    \"\"\"\n","    yone = []\n","    for i in y:\n","        onehot = np.zeros(class_num)\n","        onehot[i] = 1\n","        yone.append(onehot)\n","    return np.array(yone)\n","\n","def accuracies(y_pred, y, onlyAcc=False):\n","    \"\"\"\n","    y_pred: logits\n","    y: a list of labels\n","    \"\"\"\n","    acc10 = 0.0\n","    acc5 = 0.0\n","    acc1 = 0.0\n","    num = len(y)\n","\n","    for i in range(num):\n","\n","        pred = y_pred[i]\n","        top10_pred = set(pred.argsort()[-10:])\n","        top5_pred = set(pred.argsort()[-5:])\n","        top1_pred = set(pred.argsort()[-1:])\n","\n","        label = y[i]\n","        # label = np.argmax(y[i])\n","\n","        if label in top10_pred:\n","            acc10 += 1.\n","        if label in top5_pred:\n","            acc5 += 1.\n","        if label in top1_pred:\n","            acc1 += 1.\n","\n","    acc10 /= num\n","    acc5 /= num\n","    acc1 /= num\n","\n","    if onlyAcc:\n","        return acc1\n","    return acc10, acc5, acc1, num\n","\n","def ave_auc_scores(y_pred, y):\n","    # micro/macro auc based on classes\n","    \"\"\"\n","        y.shape: [sample, classes] float\n","        y_pred.shape: [sample, classes] int\n","        numpy\n","    \"\"\"\n","\n","    aucroc_cases = {}\n","    for i in range(y.shape[1]):\n","        if y[:, i].sum()>0: # class appears in test set\n","            fp, tp, _ = roc_curve(y[:, i], y_pred[:, i])\n","            if len(fp) >1 and len(tp) >1:\n","                auc_roc = auc(fp, tp)\n","                aucroc_cases[i] = auc_roc\n","\n","    fp_mic, tp_mic, _ = roc_curve(y.ravel(), y_pred.ravel())\n","\n","    # appearing classes\n","    labels = list(aucroc_cases.keys())\n","\n","    # roc\n","    auc_roc_macro = np.mean(list(aucroc_cases.values()))\n","    auc_roc_micro = auc(fp_mic, tp_mic)\n","    return auc_roc_macro, auc_roc_micro, len(labels), len(y)\n","\n","def ave_f1_scores(y_pred, y):\n","    # f1\n","    # require y_pred, y being flat list\n","    y_flat = np.argmax(y_pred, axis=1)\n","\n","    f1_macro = f1_score(y, y_flat, average='macro', labels=np.unique(y))\n","    f1_micro = f1_score(y, y_flat, average='micro', labels=np.unique(y))\n","\n","    return f1_macro, f1_micro\n"]},{"cell_type":"code","execution_count":null,"id":"1f405343","metadata":{"id":"1f405343"},"outputs":[],"source":["import os\n","\n","def create_folder(parent_path, folder):\n","    if not parent_path.endswith('/'):\n","        parent_path += '/'\n","    folder_path = parent_path + folder\n","    if not os.path.exists(folder_path):\n","        os.makedirs(folder_path)\n","    return folder_path"]}],"metadata":{"colab":{"provenance":[{"file_id":"1aKrI9p_ubdupi_95PZLK3XmFoNv3_lvU","timestamp":1718093654355}]},"language_info":{"name":"python"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"nbformat":4,"nbformat_minor":5}