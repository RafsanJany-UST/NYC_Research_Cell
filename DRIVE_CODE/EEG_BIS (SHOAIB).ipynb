{"cells":[{"cell_type":"markdown","metadata":{"id":"CwUK7UHlTBXj"},"source":["[<font color = 'coral'>References Code</font>](https://github.com/vitaldb/examples/blob/master/eeg_mac.ipynb)"]},{"cell_type":"markdown","metadata":{"id":"Yy0WHpW3X9oX"},"source":["# Prediction of anesthetic concentration from EEG\n","In this example, we will build a model to predict anesthetic concentration (age-related MAC) from EEG during Sevoflurane anesthesia.\n","\n","> Note that <b>all users who use Vital DB, an open biosignal dataset, must agree to the Data Use Agreement below.\n","</b> If you do not agree, please close this window.\n","Click here: [Data Use Agreement](https://vitaldb.net/dataset/?query=overview&documentId=13qqajnNZzkN7NZ9aXnaQ-47NWy7kx-a6gbrcEsi-gak&sectionId=h.vcpgs1yemdb5)"]},{"cell_type":"markdown","metadata":{"id":"9SwIjOX9frk6"},"source":["## Required libraries"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ch6czkFZfw_G","outputId":"1d55beda-dd5a-4fb9-d7c1-a37166e3ce2c","executionInfo":{"status":"ok","timestamp":1706369624957,"user_tz":-360,"elapsed":7814,"user":{"displayName":"Rafsan Jany","userId":"08721334090885411304"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting vitaldb\n","  Downloading vitaldb-1.4.7-py3-none-any.whl (56 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/56.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from vitaldb) (1.23.5)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from vitaldb) (1.5.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from vitaldb) (2.31.0)\n","Collecting wfdb (from vitaldb)\n","  Downloading wfdb-4.1.2-py3-none-any.whl (159 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.0/160.0 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->vitaldb) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->vitaldb) (2023.3.post1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->vitaldb) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->vitaldb) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->vitaldb) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->vitaldb) (2023.11.17)\n","Requirement already satisfied: SoundFile>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from wfdb->vitaldb) (0.12.1)\n","Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from wfdb->vitaldb) (3.7.1)\n","Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wfdb->vitaldb) (1.11.4)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->wfdb->vitaldb) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->wfdb->vitaldb) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->wfdb->vitaldb) (4.47.2)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->wfdb->vitaldb) (1.4.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->wfdb->vitaldb) (23.2)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->wfdb->vitaldb) (9.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->wfdb->vitaldb) (3.1.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->vitaldb) (1.16.0)\n","Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from SoundFile>=0.10.0->wfdb->vitaldb) (1.16.0)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->SoundFile>=0.10.0->wfdb->vitaldb) (2.21)\n","Installing collected packages: wfdb, vitaldb\n","Successfully installed vitaldb-1.4.7 wfdb-4.1.2\n"]}],"source":["!pip install vitaldb\n","import vitaldb\n","import random\n","import numpy as np\n","import pandas as pd\n","import scipy.signal\n","import matplotlib.pyplot as plt"]},{"cell_type":"markdown","metadata":{"id":"ZjxFdZTXBZWb"},"source":["## Preprocessing"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0b_TyfelWg6e","outputId":"ef285992-916a-4a64-f0f0-bb27396736af","executionInfo":{"status":"ok","timestamp":1706369631493,"user_tz":-360,"elapsed":3005,"user":{"displayName":"Rafsan Jany","userId":"08721334090885411304"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Total 5800 cases found\n"]}],"source":["SRATE = 128  # in hz\n","SEGLEN = 4 * SRATE  # segment samples\n","MAX_CASES = 100\n","\n","df_trks = pd.read_csv(\"https://api.vitaldb.net/trks\")  # track information\n","df_cases = pd.read_csv(\"https://api.vitaldb.net/cases\")  # patient information\n","\n","# track names and column order when loading data\n","track_names = ['BIS/EEG1_WAV', 'BIS/BIS']\n","\n","\n","# Inclusion & Exclusion criteria\n","caseids = set(df_cases.loc[df_cases['age'] > 18, 'caseid'])\n","caseids &= set(df_trks.loc[df_trks['tname'] == 'BIS/EEG1_WAV', 'caseid'])\n","caseids &= set(df_trks.loc[df_trks['tname'] == 'BIS/BIS', 'caseid'])\n","caseids = list(caseids)\n","print(f'Total {len(caseids)} cases found')"]},{"cell_type":"markdown","metadata":{"id":"NwwLDouezDLc"},"source":["## Filtering input data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bHa2fte0zGEv","outputId":"e5bb869e-8a8e-4738-deae-db79e1d8ec58"},"outputs":[{"name":"stdout","output_type":"stream","text":["invalid samples..."]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_25392\\2705416851.py:4: RuntimeWarning: All-NaN slice encountered\n","  valid_mask &= (np.nanmax(x, axis=1) - np.nanmin(x, axis=1) > 12)  # bis impedence check\n","C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_25392\\2705416851.py:5: RuntimeWarning: All-NaN slice encountered\n","  valid_mask &= (np.nanmax(np.abs(x), axis=1) < 100)  # noisy sample\n"]},{"name":"stdout","output_type":"stream","text":["12.7% removed\n"]}],"source":[]},{"cell_type":"markdown","metadata":{"id":"VpMowosc0Bzf"},"source":["## Splitting samples into training and testing dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AjdvjsJ10JAe","outputId":"9368e57c-8fe1-45cb-d183-14b39381b8b3"},"outputs":[{"name":"stdout","output_type":"stream","text":["====================================================\n","total: 100 cases 496346 samples\n","train: 80 cases 384419 samples\n","test 20 cases 111927 samples\n","====================================================\n"]}],"source":["# caseid\n","caseids = list(np.unique(c))\n","#random.shuffle(caseids)\n","\n","# Split dataset into training and testing data\n","ntest = max(1, int(len(caseids) * 0.2))\n","caseids_train = caseids[ntest:]\n","caseids_test = caseids[:ntest]\n","\n","train_mask = np.isin(c, caseids_train)\n","test_mask = np.isin(c, caseids_test)\n","x_train = x[train_mask]\n","y_train = y[train_mask]\n","x_test = x[test_mask]\n","y_test = y[test_mask]\n","b_test = b[test_mask]\n","c_test = c[test_mask]\n","\n","print('====================================================')\n","print(f'total: {len(caseids)} cases {len(y)} samples')\n","print(f'train: {len(np.unique(c[train_mask]))} cases {len(y_train)} samples')\n","print(f'test {len(np.unique(c_test))} cases {len(y_test)} samples')\n","print('====================================================')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IZqloQ4i81SS","outputId":"e66b6157-3a3a-47e6-8cd6-344af515fffe"},"outputs":[{"data":{"text/plain":["((384419, 512), (384419,))"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["x_train.shape, y_train.shape"]},{"cell_type":"markdown","metadata":{"id":"iPi6FIbB0NkF"},"source":["## Modeling and Evaluation"]},{"cell_type":"markdown","metadata":{"id":"AnBJRhMz5XrF"},"source":["#LSTM"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BgAFXWMYd092"},"outputs":[],"source":["X = x_train\n","y = y_train"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":391},"id":"ycWVJWUB-Dnr","outputId":"d2107e5c-27c9-41cf-ebde-fe0738f67e95"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_2 (InputLayer)        [(None, 512, 1)]          0         \n","                                                                 \n"," conv1d_4 (Conv1D)           (None, 512, 32)           256       \n","                                                                 \n"," activation_4 (Activation)   (None, 512, 32)           0         \n","                                                                 \n"," max_pooling1d_4 (MaxPoolin  (None, 256, 32)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_5 (Conv1D)           (None, 256, 32)           7200      \n","                                                                 \n"," activation_5 (Activation)   (None, 256, 32)           0         \n","                                                                 \n"," max_pooling1d_5 (MaxPoolin  (None, 128, 32)           0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_6 (Conv1D)           (None, 128, 32)           7200      \n","                                                                 \n"," activation_6 (Activation)   (None, 128, 32)           0         \n","                                                                 \n"," max_pooling1d_6 (MaxPoolin  (None, 64, 32)            0         \n"," g1D)                                                            \n","                                                                 \n"," conv1d_7 (Conv1D)           (None, 64, 32)            7200      \n","                                                                 \n"," activation_7 (Activation)   (None, 64, 32)            0         \n","                                                                 \n"," max_pooling1d_7 (MaxPoolin  (None, 32, 32)            0         \n"," g1D)                                                            \n","                                                                 \n"," global_max_pooling1d_1 (Gl  (None, 32)                0         \n"," obalMaxPooling1D)                                               \n","                                                                 \n"," dense_3 (Dense)             (None, 128)               4224      \n","                                                                 \n"," dropout_1 (Dropout)         (None, 128)               0         \n","                                                                 \n"," dense_4 (Dense)             (None, 1)                 129       \n","                                                                 \n","=================================================================\n","Total params: 26209 (102.38 KB)\n","Trainable params: 26209 (102.38 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","Epoch 1/3\n","76/76 [==============================] - ETA: 0s - loss: 0.5767 - accuracy: 0.0047\n","Epoch 1: val_accuracy improved from -inf to 0.00164, saving model to model.x\n","INFO:tensorflow:Assets written to: model.x\\assets\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Assets written to: model.x\\assets\n"]},{"name":"stdout","output_type":"stream","text":["76/76 [==============================] - 98s 1s/step - loss: 0.5767 - accuracy: 0.0047 - val_loss: 0.3512 - val_accuracy: 0.0016\n","Epoch 2/3\n","76/76 [==============================] - ETA: 0s - loss: 0.2618 - accuracy: 4.6499e-04\n","Epoch 2: val_accuracy did not improve from 0.00164\n","76/76 [==============================] - 106s 1s/step - loss: 0.2618 - accuracy: 4.6499e-04 - val_loss: 0.3488 - val_accuracy: 0.0012\n","Epoch 3/3\n","14/76 [====>.........................] - ETA: 1:20 - loss: 0.2383 - accuracy: 0.0016"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn[10], line 29\u001b[0m\n\u001b[0;32m     19\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_absolute_error\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     21\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     22\u001b[0m     ModelCheckpoint(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     23\u001b[0m                     filepath\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel.x\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     26\u001b[0m     EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     27\u001b[0m ]\n\u001b[1;32m---> 29\u001b[0m hist \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4096\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mE:\\Conda\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[1;32mE:\\Conda\\Lib\\site-packages\\keras\\src\\engine\\training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1740\u001b[0m ):\n\u001b[0;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n","File \u001b[1;32mE:\\Conda\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[1;32mE:\\Conda\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n","File \u001b[1;32mE:\\Conda\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    854\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    855\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    856\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    859\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    860\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n","File \u001b[1;32mE:\\Conda\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    146\u001b[0m   (concrete_function,\n\u001b[0;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mE:\\Conda\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs)\u001b[0m\n\u001b[0;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1351\u001b[0m     args,\n\u001b[0;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1353\u001b[0m     executing_eagerly)\n\u001b[0;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n","File \u001b[1;32mE:\\Conda\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n","File \u001b[1;32mE:\\Conda\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1458\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1459\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1460\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1461\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1462\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1463\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1472\u001b[0m   )\n","File \u001b[1;32mE:\\Conda\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["import keras.models\n","import tensorflow as tf\n","from keras.models import Model\n","from keras.layers import Dense, Dropout, Conv1D, MaxPooling1D, GlobalMaxPooling1D, Input, Activation\n","from keras.callbacks import EarlyStopping, ModelCheckpoint\n","\n","out = inp = Input(shape=(x_train.shape[1], 1))\n","for i in range(4):\n","    out = Conv1D(filters=32, kernel_size=7, padding='same')(out)\n","    out = Activation('relu')(out)\n","    out = MaxPooling1D(2, padding='same')(out)\n","out = GlobalMaxPooling1D()(out)\n","out = Dense(128)(out)\n","out = Dropout(0.2)(out)\n","out = Dense(1)(out)\n","\n","model = Model(inputs=[inp], outputs=[out])\n","model.summary()\n","model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['accuracy'])\n","\n","callbacks = [\n","    ModelCheckpoint(monitor='val_accuracy',\n","                    filepath='model.x',\n","                    verbose=1,\n","                    save_best_only=True),\n","    EarlyStopping(monitor='val_loss', patience=2, verbose=1, mode='auto')\n","]\n","\n","hist = model.fit(x_train, y_train, validation_split=0.2, epochs=3, batch_size=4096, callbacks=callbacks)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oeHcbz5yajTg","outputId":"33cf52f6-039a-4af4-da1d-440b64ca518f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm_1 (LSTM)               (None, 50)                10400     \n","                                                                 \n"," dense_5 (Dense)             (None, 128)               6528      \n","                                                                 \n"," dropout_2 (Dropout)         (None, 128)               0         \n","                                                                 \n"," dense_6 (Dense)             (None, 1)                 129       \n","                                                                 \n","=================================================================\n","Total params: 17057 (66.63 KB)\n","Trainable params: 17057 (66.63 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","Epoch 1/3\n","76/76 [==============================] - ETA: 0s - loss: 0.3185 - mean_absolute_error: 0.3185\n","Epoch 1: val_loss improved from inf to 0.42138, saving model to model_lstm.h5\n","76/76 [==============================] - 287s 4s/step - loss: 0.3185 - mean_absolute_error: 0.3185 - val_loss: 0.4214 - val_mean_absolute_error: 0.4214\n","Epoch 2/3\n"]},{"name":"stderr","output_type":"stream","text":["E:\\Conda\\Lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"name":"stdout","output_type":"stream","text":["76/76 [==============================] - ETA: 0s - loss: 0.2651 - mean_absolute_error: 0.2651\n","Epoch 2: val_loss improved from 0.42138 to 0.41848, saving model to model_lstm.h5\n","76/76 [==============================] - 287s 4s/step - loss: 0.2651 - mean_absolute_error: 0.2651 - val_loss: 0.4185 - val_mean_absolute_error: 0.4185\n","Epoch 3/3\n","76/76 [==============================] - ETA: 0s - loss: 0.2582 - mean_absolute_error: 0.2582\n","Epoch 3: val_loss improved from 0.41848 to 0.41708, saving model to model_lstm.h5\n","76/76 [==============================] - 418s 6s/step - loss: 0.2582 - mean_absolute_error: 0.2582 - val_loss: 0.4171 - val_mean_absolute_error: 0.4171\n","3498/3498 [==============================] - 103s 29ms/step\n","Test MAE: 0.26340937388276275\n"]}],"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import LSTM, Dense, Dropout\n","\n","# Assuming x_train, y_train, x_test, y_test are your training and test data\n","\n","# Reshape data for LSTM input (assuming x_train and x_test are 3D tensors)\n","# The input shape should be (number_of_samples, time_steps, features)\n","x_train_reshaped = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))\n","x_test_reshaped = x_test.reshape((x_test.shape[0], x_test.shape[1], 1))\n","\n","# Define the LSTM model\n","model = Sequential()\n","model.add(LSTM(units=50, input_shape=(x_train_reshaped.shape[1], 1)))\n","model.add(Dense(units=128, activation='relu'))\n","model.add(Dropout(0.2))\n","model.add(Dense(units=1))\n","\n","# Compile the model\n","model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])\n","\n","# Print a summary of the model architecture\n","model.summary()\n","\n","# Fit the model\n","hist = model.fit(x_train_reshaped, y_train, validation_split=0.2, epochs=3, batch_size=4096,\n","                 callbacks=[tf.keras.callbacks.ModelCheckpoint('model_lstm.h5', monitor='val_loss', verbose=1, save_best_only=True),\n","                            tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2, verbose=1, mode='auto')])\n","\n","# Make predictions\n","pred_test = model.predict(x_test_reshaped).flatten()\n","\n","# Apply post-processing if needed\n","# ...\n","\n","# Calculate the performance\n","test_mae = np.mean(np.abs(y_test - pred_test))\n","print(f'Test MAE: {test_mae}')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T5h8_YEtgQSQ","outputId":"7fc1a385-d5dc-44a8-c353-cc4cf3689874"},"outputs":[{"ename":"NameError","evalue":"name 'y_test' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m r2_score\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Assuming y_test contains the true BIS scores and pred_test contains the predicted scores\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m r2 \u001b[38;5;241m=\u001b[39m r2_score(\u001b[43my_test\u001b[49m, pred_test)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mR-squared: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mr2\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n","\u001b[1;31mNameError\u001b[0m: name 'y_test' is not defined"]}],"source":["from sklearn.metrics import r2_score\n","\n","# Assuming y_test contains the true BIS scores and pred_test contains the predicted scores\n","r2 = r2_score(y_test, pred_test)\n","print(f'R-squared: {r2}')\n"]},{"cell_type":"markdown","metadata":{"id":"_I94fusR2M3z"},"source":["## Classification approach CNN\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D9NmIcnFuZY-","outputId":"aeba436a-32b5-4095-e681-cafbb6b87306"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential_3\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d_8 (Conv1D)           (None, 506, 32)           256       \n","                                                                 \n"," max_pooling1d_8 (MaxPoolin  (None, 253, 32)           0         \n"," g1D)                                                            \n","                                                                 \n"," flatten (Flatten)           (None, 8096)              0         \n","                                                                 \n"," dense_8 (Dense)             (None, 128)               1036416   \n","                                                                 \n"," dropout_3 (Dropout)         (None, 128)               0         \n","                                                                 \n"," dense_9 (Dense)             (None, 5)                 645       \n","                                                                 \n","=================================================================\n","Total params: 1037317 (3.96 MB)\n","Trainable params: 1037317 (3.96 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","Epoch 1/3\n","76/76 [==============================] - ETA: 0s - loss: 0.0415 - accuracy: 0.9934\n","Epoch 1: val_loss improved from inf to 0.00000, saving model to model_cnn_classification.h5\n","76/76 [==============================] - 45s 586ms/step - loss: 0.0415 - accuracy: 0.9934 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n","Epoch 2/3\n"]},{"name":"stderr","output_type":"stream","text":["E:\\Conda\\Lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"name":"stdout","output_type":"stream","text":["76/76 [==============================] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n","Epoch 2: val_loss did not improve from 0.00000\n","76/76 [==============================] - 44s 578ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n","Epoch 3/3\n","76/76 [==============================] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n","Epoch 3: val_loss did not improve from 0.00000\n","76/76 [==============================] - 43s 562ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n","Epoch 3: early stopping\n","3498/3498 [==============================] - 12s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n","Test Accuracy: 1.0\n"]}],"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n","\n","# Assuming x_train, y_train, x_test, y_test are your training and test data\n","\n","# Convert BIS scores to classes (you need to define your own bins or thresholds)\n","num_classes = 5  # Adjust based on your specific classification setup\n","y_train_classes = np.digitize(y_train, bins=np.linspace(0, 100, num_classes))\n","y_test_classes = np.digitize(y_test, bins=np.linspace(0, 100, num_classes))\n","\n","# Reshape data for CNN input (assuming x_train and x_test are 3D tensors)\n","x_train_reshaped = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))\n","x_test_reshaped = x_test.reshape((x_test.shape[0], x_test.shape[1], 1))\n","\n","# Define the CNN model for classification\n","model = Sequential()\n","model.add(Conv1D(filters=32, kernel_size=7, activation='relu', input_shape=(x_train_reshaped.shape[1], 1)))\n","model.add(MaxPooling1D(pool_size=2))\n","model.add(Flatten())\n","model.add(Dense(units=128, activation='relu'))\n","model.add(Dropout(0.2))\n","model.add(Dense(units=num_classes, activation='softmax'))\n","\n","# Compile the model for classification\n","model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","# Print a summary of the model architecture\n","model.summary()\n","\n","# Fit the model for classification\n","hist = model.fit(x_train_reshaped, y_train_classes, validation_split=0.2, epochs=3, batch_size=4096,\n","                 callbacks=[tf.keras.callbacks.ModelCheckpoint('model_cnn_classification.h5', monitor='val_loss', verbose=1, save_best_only=True),\n","                            tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2, verbose=1, mode='auto')])\n","\n","# Evaluate the model on the test set using accuracy\n","test_results = model.evaluate(x_test_reshaped, y_test_classes)\n","print(f'Test Accuracy: {test_results[1]}')\n"]},{"cell_type":"markdown","metadata":{"id":"SfWzKObJajTj"},"source":["# LSTM non regression"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ga95qa25ajTj","outputId":"ed9dd614-4037-4bec-bc08-fdb77a34d0ae"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential_4\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm_3 (LSTM)               (None, 50)                10400     \n","                                                                 \n"," dense_10 (Dense)            (None, 128)               6528      \n","                                                                 \n"," dropout_4 (Dropout)         (None, 128)               0         \n","                                                                 \n"," dense_11 (Dense)            (None, 5)                 645       \n","                                                                 \n","=================================================================\n","Total params: 17573 (68.64 KB)\n","Trainable params: 17573 (68.64 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","Epoch 1/3\n","76/76 [==============================] - ETA: 0s - loss: 0.1706 - accuracy: 0.9908\n","Epoch 1: val_loss improved from inf to 0.00088, saving model to model_lstm_classification.h5\n","76/76 [==============================] - 637s 8s/step - loss: 0.1706 - accuracy: 0.9908 - val_loss: 8.8241e-04 - val_accuracy: 1.0000\n","Epoch 2/3\n","40/76 [==============>...............] - ETA: 5:33 - loss: 9.7630e-04 - accuracy: 1.0000"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn[16], line 31\u001b[0m\n\u001b[0;32m     28\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Fit the model for classification\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m hist \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train_reshaped\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_classes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4096\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mModelCheckpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel_lstm_classification.h5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmonitor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mval_loss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_best_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEarlyStopping\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmonitor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mval_loss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Evaluate the model on the test set using accuracy\u001b[39;00m\n\u001b[0;32m     36\u001b[0m test_results \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(x_test_reshaped, y_test_classes)\n","File \u001b[1;32mE:\\Conda\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[1;32mE:\\Conda\\Lib\\site-packages\\keras\\src\\engine\\training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1740\u001b[0m ):\n\u001b[0;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n","File \u001b[1;32mE:\\Conda\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[1;32mE:\\Conda\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n","File \u001b[1;32mE:\\Conda\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    854\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    855\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    856\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    859\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    860\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n","File \u001b[1;32mE:\\Conda\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    146\u001b[0m   (concrete_function,\n\u001b[0;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mE:\\Conda\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs)\u001b[0m\n\u001b[0;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1351\u001b[0m     args,\n\u001b[0;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1353\u001b[0m     executing_eagerly)\n\u001b[0;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n","File \u001b[1;32mE:\\Conda\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n","File \u001b[1;32mE:\\Conda\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1458\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1459\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1460\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1461\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1462\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1463\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1472\u001b[0m   )\n","File \u001b[1;32mE:\\Conda\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import LSTM, Dense, Dropout\n","\n","# Assuming x_train, y_train, x_test, y_test are your training and test data\n","\n","# Convert BIS scores to classes (you need to define your own bins or thresholds)\n","num_classes = 5  # Adjust based on your specific classification setup\n","y_train_classes = np.digitize(y_train, bins=np.linspace(0, 100, num_classes))\n","y_test_classes = np.digitize(y_test, bins=np.linspace(0, 100, num_classes))\n","\n","# Reshape data for LSTM input (assuming x_train and x_test are 3D tensors)\n","x_train_reshaped = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))\n","x_test_reshaped = x_test.reshape((x_test.shape[0], x_test.shape[1], 1))\n","\n","# Define the LSTM model for classification\n","model = Sequential()\n","model.add(LSTM(units=50, input_shape=(x_train_reshaped.shape[1], 1)))\n","model.add(Dense(units=128, activation='relu'))\n","model.add(Dropout(0.2))\n","model.add(Dense(units=num_classes, activation='softmax'))\n","\n","# Compile the model for classification\n","model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","# Print a summary of the model architecture\n","model.summary()\n","\n","# Fit the model for classification\n","hist = model.fit(x_train_reshaped, y_train_classes, validation_split=0.2, epochs=3, batch_size=4096,\n","                 callbacks=[tf.keras.callbacks.ModelCheckpoint('model_lstm_classification.h5', monitor='val_loss', verbose=1, save_best_only=True),\n","                            tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2, verbose=1, mode='auto')])\n","\n","# Evaluate the model on the test set using accuracy\n","test_results = model.evaluate(x_test_reshaped, y_test_classes)\n","print(f'Test Accuracy: {test_results[1]}')\n"]},{"cell_type":"markdown","metadata":{"id":"rZ0wGsMv-OIw"},"source":["#RNN"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MOhUAaxu-Q2L"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import SimpleRNN, Dense\n","\n","model = Sequential()\n","model.add(SimpleRNN(50, input_shape=(512,1)))\n","model.add(Dense(1, activation='sigmoid'))\n","\n","model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n","model.summary()\n","\n","# Train the model (Assuming X_train and y_train are your training data)\n","model.fit(x_train, y_train, epochs=10, batch_size=32)\n"]},{"cell_type":"markdown","metadata":{"id":"ZXmZAWP7-nyc"},"source":["#Temporal Convolutional Network (TCN)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z89kiN2_-mkD"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv1D, Dense, Flatten\n","\n","model = Sequential()\n","model.add(Conv1D(32, kernel_size=3, activation='relu', input_shape=(512,1)))\n","model.add(Flatten())\n","model.add(Dense(1, activation='sigmoid'))\n","\n","model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n","model.summary()\n","\n","# Train the model (Assuming X_train and y_train are your training data)\n","model.fit(x_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n","#model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)"]},{"cell_type":"markdown","metadata":{"id":"PD1qBJQk_mmM"},"source":["#Gated Recurrent Units (GRUs)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NFoxcxDB-mYR"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import GRU, Dense\n","\n","model = Sequential()\n","model.add(GRU(50, input_shape=(512,1)))\n","model.add(Dense(1, activation='sigmoid'))\n","\n","model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n","model.summary()\n","\n","# Train the model (Assuming X_train and y_train are your training data)\n","model.fit(x_train, y_train, epochs=10, batch_size=32)\n"]},{"cell_type":"markdown","metadata":{"id":"6Z_Qib3nAbir"},"source":["#Transformer-based Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FdfSuTsL-mP1"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Transformer, Dense\n","\n","model = Sequential()\n","model.add(Transformer(num_heads=2, d_model=512, ff_dim=256, input_shape=(512, 1)))\n","model.add(Dense(1, activation='sigmoid'))\n","\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","model.summary()\n","\n","# Train the model (Assuming X_train and y_train are your training data)\n","model.fit(X_train, y_train, epochs=10, batch_size=32)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"51XLC2Lg-l_-"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZCGiCq72-lw3"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2kCLhbJm-lmu"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WBZO_nfl-lZb"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cRZXFjbD-lPa"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"UUY46NDsobLE"},"source":["#CNN"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xnPDQ5NzpWWf"},"outputs":[],"source":["from keras.models import Sequential\n","from keras.layers import Conv2D, Flatten, Dense\n","\n","model = Sequential()\n","model.add(Conv2D(32, kernel_size=7, activation='relu', input_shape=(512, 1)))\n","model.add(Flatten())\n","model.add(Dense(1, activation='linear'))\n","\n","# Compile the model\n","model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n","\n","# Train the model\n","model.fit(x_train, y_train, epochs=10, batch_size=32)"]},{"cell_type":"markdown","metadata":{"id":"2qHDDxWjgaIj"},"source":["# Default"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uytYU2Fu0rPi"},"outputs":[],"source":["import keras.models\n","import tensorflow as tf\n","from keras.models import Model\n","from keras.layers import Dense, Dropout, Conv1D, MaxPooling1D, GlobalMaxPooling1D, Input, Activation\n","from keras.callbacks import EarlyStopping, ModelCheckpoint\n","\n","\n","\n","\n","out = inp = Input(shape=(x_train.shape[1], 1))\n","for i in range(4):\n","    out = Conv1D(filters=32, kernel_size=7, padding='same')(out)\n","    out = Activation('relu')(out)\n","    out = MaxPooling1D(2, padding='same')(out)\n","out = GlobalMaxPooling1D()(out)\n","out = Dense(128)(out)\n","out = Dropout(0.2)(out)\n","out = Dense(1)(out)\n","\n","model = Model(inputs=[inp], outputs=[out])\n","model.summary()\n","model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])\n","# fit model. the last 20% of the segments will be used for early stopping\n","hist = model.fit(x_train, y_train, validation_split=0.2, epochs=100, batch_size=4096,\n","                callbacks=[ModelCheckpoint(monitor='val_loss', filepath='model.x', verbose=1, save_best_only=True),\n","                            EarlyStopping(monitor='val_loss', patience=2, verbose=1, mode='auto')])\n","\n","# prediction\n","pred_test = model.predict(x_test).flatten()\n","for caseid in np.unique(c_test):\n","    case_mask = (c_test == caseid)\n","    pred_test[case_mask] = scipy.signal.medfilt(pred_test[case_mask], 15)\n","\n","# calculate the performance\n","test_mae = np.mean(np.abs(y_test - pred_test))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IHkwzS9aDEoD"},"outputs":[],"source":["# pearson correlation coefficient\n","bis_corr = np.corrcoef(y_test, b_test)[0, 1]\n","our_corr = np.corrcoef(y_test, pred_test)[0, 1]\n","\n","# scatter plot\n","plt.figure(figsize=(10, 5))\n","plt.subplot(1, 2, 1)\n","plt.scatter(y_test, b_test, s=1, alpha=0.5, c='violet', label=f'BIS ({bis_corr:4f})')\n","plt.xlim([0, 2])\n","plt.legend(loc=\"upper right\")\n","plt.subplot(1, 2, 2)\n","plt.scatter(y_test, pred_test, s=1, alpha=0.5, c='orange', label=f'Ours ({our_corr:.4f})')\n","plt.xlim([0, 2])\n","plt.legend(loc=\"upper left\")\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zSXTiUERT0tm"},"outputs":[],"source":["# plot for each case\n","for caseid in np.unique(c_test):\n","    case_mask = (c_test == caseid)\n","    case_len = np.sum(case_mask)\n","    if case_len == 0:\n","        continue\n","\n","    our_mae = np.mean(np.abs(y_test[case_mask] - pred_test[case_mask]))\n","    print(f'Total MAE={test_mae:.4f}, CaseID {caseid}, MAE={our_mae:.4f}')\n","\n","    t = np.arange(0, case_len)\n","    plt.figure(figsize=(20, 5))\n","    plt.plot(t, y_test[case_mask], label='MAC')\n","    plt.plot(t, pred_test[case_mask], label=f'Ours ({our_mae:.4f})')\n","    plt.legend(loc=\"upper left\")\n","    plt.tight_layout()\n","    plt.xlim([0, case_len])\n","    plt.ylim([0, 2])\n","    plt.show()"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["Yy0WHpW3X9oX","9SwIjOX9frk6","ZjxFdZTXBZWb","aBusNmsKpc2Z","NwwLDouezDLc","VpMowosc0Bzf"],"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":0}