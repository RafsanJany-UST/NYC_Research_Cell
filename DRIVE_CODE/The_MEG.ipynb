{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25718,"status":"ok","timestamp":1679845587649,"user":{"displayName":"Rafsan Jany","userId":"08721334090885411304"},"user_tz":-360},"id":"zdFOS9nFlpsU","outputId":"9da0c06c-ef21-4a1d-f30d-170a2dc9447c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":[],"metadata":{"id":"sBgjkkgqNXAn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SEsFaHeE2Pss"},"source":["###Function"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ESoueLt11P_w"},"outputs":[],"source":["!pip install imbalanced-learn\n","\n","from imblearn.over_sampling import SMOTE\n","\n","def balance(X_temp, y_temp):\n","  smote = SMOTE()\n","  X_temp, y_temp= smote.fit_resample(X_temp, y_temp)\n","  return pd.concat([pd.DataFrame(X_temp), pd.DataFrame(y_temp)], axis=1)\n","\n","\n","\n","def models_check_box(models):\n","  import ipywidgets as widgets\n","  from IPython.display import display\n","  new_keys=[]\n","  for i in models:\n","    i=widgets.Checkbox(\n","      value=False,\n","      description=str(i),\n","      disabled=False,\n","      indent=False\n","      )\n","    display(i)\n","    new_keys.append(i)\n","  return new_keys"]},{"cell_type":"markdown","metadata":{"id":"A1B_8Nsw9-1Q"},"source":["#Starting"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M0AmIUwSmLfj"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","#dataset=pd.read_csv(\"/content/drive/MyDrive/Sleep Stage XAI/EEG_HMC_FeatureExtraction_2023.01.19.csv\")\n","#dataset=pd.read_excel(\"/content/EEG_CNU_Control_Resting, walking, working and Reading_2023.01.07.xlsx\")\n","\n","dataset = pd.read_csv(\"/content/drive/MyDrive/Iqram Sir/EEG_HMC_FeatureExtraction_2023.01.19.csv\")\n","\n","target = \"Sleep Stage\"\n","result = {}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4YN_C8yxm1ho"},"outputs":[],"source":["dataset.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0SDC0qL01iJd"},"outputs":[],"source":["dataset.shape"]},{"cell_type":"markdown","source":["Removing NULL values"],"metadata":{"id":"A3HDJubYkzut"}},{"cell_type":"code","source":["dataset.dropna(axis=0, how='any', inplace = True)\n","dataset = dataset.reset_index(drop=True)"],"metadata":{"id":"oPb1X8ktk3yG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Observing shape of dataset"],"metadata":{"id":"ziEv61mYL9hK"}},{"cell_type":"code","source":["dataset.shape"],"metadata":{"id":"3GZXJQDFk8sj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["target value count"],"metadata":{"id":"TuhzOMrgMDBY"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"NicZ_GzN1mTL"},"outputs":[],"source":["dataset[target].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VS4iUbnyYaDH"},"outputs":[],"source":["set(list(dataset[target]))"]},{"cell_type":"markdown","source":["Label Encoding"],"metadata":{"id":"hulHTqVxMJky"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ljyj9yuIf-tX"},"outputs":[],"source":["from sklearn.preprocessing import LabelEncoder\n","encoder=LabelEncoder()\n","dataset[target]=encoder.fit_transform(dataset[target])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"42si00q3SLh5"},"outputs":[],"source":["set(list(dataset[target]))"]},{"cell_type":"markdown","metadata":{"id":"TXMKr8bi2JnW"},"source":["###Spliting into X and y"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tIf-rcIB11o1"},"outputs":[],"source":["X =  dataset.loc[:,dataset.columns != target]  # removing Sleep Stage\n","X =  X.loc[:,X.columns != \"Subject\"]            # removing Subject\n","X =  X.loc[:,X.columns != \"Epoch\"]             # removing Epoch\n","y = dataset[target]\n","\n","X.head(10)\n"]},{"cell_type":"markdown","metadata":{"id":"7G108WUM2Di_"},"source":["###USing SMOTE for balancing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WvJIm4Co2ApP"},"outputs":[],"source":["new_dataset =  balance(X,y)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wUzLAHJqACBH"},"outputs":[],"source":["new_dataset[target].value_counts()"]},{"cell_type":"markdown","metadata":{"id":"FZLedhGD91Cv"},"source":["#Feature Selection"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V1m6UgTv92XU"},"outputs":[],"source":["number_of_feat = 30"]},{"cell_type":"markdown","metadata":{"id":"XkC7pB1v-Gsp"},"source":["###ANOVA with f classifciation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Rafbj3rl-GWZ"},"outputs":[],"source":["from sklearn.datasets import make_classification\n","from sklearn.feature_selection import SelectKBest\n","from sklearn.feature_selection import f_classif\n","import pandas as pd\n","\n","\n","\n","fs = SelectKBest(score_func=f_classif, k=5)\n","fit = fs.fit(X,y)\n","dfscores = pd.DataFrame(fit.scores_)\n","dfcolumns = pd.DataFrame(X.columns)\n","\n","featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n","\n","featureScores.columns = ['Best_columns','Score_ANOVA'] \n","\n","lyst = featureScores.nlargest(number_of_feat,'Score_ANOVA')\n","\n","#lyst.to_csv('Filter_Method_ANOVA_with_f_classif.csv')\n","\n","list_of_feat = list(lyst[\"Best_columns\"])"]},{"cell_type":"markdown","metadata":{"id":"xCkHXMQQ-PoJ"},"source":["###Embedded Method"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PZJcRlL7-So6"},"outputs":[],"source":["''''\n","from sklearn.linear_model import LassoCV\n","reg = LassoCV()\n","reg.fit(X, y)\n","print(\"Best alpha using built-in LassoCV: %f\" % reg.alpha_)\n","print(\"Best score using built-in LassoCV: %f\" %reg.score(X,y))\n","coef = pd.Series(reg.coef_, index = X.columns)\n","\n","print(\"Lasso picked \" + str(sum(coef != 0)) + \" variables and eliminated the other \" +  str(sum(coef == 0)) + \" variables\")\n","\n","imp_coef = coef.sort_values()\n","\n","list_of_feat=[]\n","\n","\n","for i in range(coef.shape[0]):\n","  if coef[i]!=0:\n","    list_of_feat.append(dataset.iloc[:0,i+3].name)\n","    \n","df = pd.DataFrame(list_of_feat, columns=['Best_Features'])\n","\n","#df.to_csv(\"Embedded_Method.csv\")\n","\n","list_of_feat = list(df[\"Best_Features\"])\n","if number_of_feat < len(list_of_feat):\n","  list_of_feat = list_of_feat[:number_of_feat]\n","'''"]},{"cell_type":"markdown","metadata":{"id":"rrR11h2K-aJn"},"source":["###Pearson's with f regression"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qH6yDZiP-a9K"},"outputs":[],"source":["'''\n","from sklearn.datasets import make_regression\n","from sklearn.feature_selection import SelectKBest\n","from sklearn.feature_selection import f_regression\n","import pandas as pd\n","\n","\n","fs = SelectKBest(score_func=f_regression, k=5)\n","fit = fs.fit(X,y)\n","\n","dfscores = pd.DataFrame(fit.scores_)\n","dfcolumns = pd.DataFrame(dataset.columns)\n","featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n","\n","featureScores.columns = ['Best_columns','Score_pearsons'] \n","\n","\n","lyst = featureScores.nlargest(number_of_feat,'Score_pearsons')\n","\n","#lyst.to_csv('Filter_Method_Pearsonâ€™s_with_f_regression.csv')\n","\n","list_of_feat = list(lyst[\"Best_columns\"])\n","'''"]},{"cell_type":"markdown","metadata":{"id":"85wbxGFW-kGZ"},"source":["###Sequential Feature Selection"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MtP9AHew-k1i"},"outputs":[],"source":["''''\n","from sklearn.feature_selection import SequentialFeatureSelector\n","from sklearn.neighbors import KNeighborsClassifier\n","knn = KNeighborsClassifier(n_neighbors=3)\n","sfs = SequentialFeatureSelector(knn, n_features_to_select=number_of_feat)\n","sfs.fit(X, y)\n","list_of_feat=[]\n","list_of_feat=list(sfs.get_feature_names_out(X.columns))\n","\n","df = pd.DataFrame(list_of_feat, columns=['Best_Features'])\n","\n","#df.to_csv(\"Filter_Method_Sequential_feat_Selection_KNN.csv\")\n","\n","list_of_feat = list(df[\"Best_Features\"])\n","if number_of_feat < len(list_of_feat):\n","  list_of_feat = list_of_feat[:number_of_feat]\n","  '''"]},{"cell_type":"markdown","source":["###All features"],"metadata":{"id":"cOSqGvJv7wOQ"}},{"cell_type":"code","source":["list_of_feat = list(X.columns)"],"metadata":{"id":"nyQhnST17zbL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YAQ71nBV-p7E"},"source":["###Feature list"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JKwGHUuo-qnn"},"outputs":[],"source":["dfcolumns = pd.DataFrame(list_of_feat)\n","print(dfcolumns)"]},{"cell_type":"markdown","metadata":{"id":"C0Akgb_na7NU"},"source":["#Data Spliting"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uL-Rbjkl_Ath"},"outputs":[],"source":["X_new = new_dataset[list_of_feat]\n","y_new = new_dataset[target]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C5l3a377_FOs"},"outputs":[],"source":["X_new.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Akn6fiaQ_JON"},"outputs":[],"source":["y_new.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dLN_vK-s_QnK"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X_new, y_new, test_size = 0.2, random_state = 0)"]},{"cell_type":"markdown","metadata":{"id":"bqYsoblRogp2"},"source":["\n","\n","---\n","\n"]},{"cell_type":"markdown","metadata":{"id":"IqElxazTzXxp"},"source":["# **Training**"]},{"cell_type":"markdown","metadata":{"id":"BydV84Diooxp"},"source":["\n","\n","---\n","\n"]},{"cell_type":"markdown","metadata":{"id":"jEe2R0yAoifa"},"source":["#ADABOOST"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Bz_yVJaXod8O"},"outputs":[],"source":["from sklearn.ensemble import AdaBoostClassifier\n","\n","ada_defult = AdaBoostClassifier(random_state=0)\n","ada_defult.fit(X_train, y_train)\n","y_pred = ada_defult.predict(X_test)\n","\n","from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n","print(confusion_matrix(y_test, y_pred))\n","print(classification_report(y_test,y_pred))\n","print(\"Accurecy: \",accuracy_score(y_test, y_pred))\n","result[(ada_defult,1,'AdaBoostClassifier')]=accuracy_score(y_test, y_pred)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_3wRG3rxotzH"},"outputs":[],"source":["from sklearn.ensemble import AdaBoostClassifier\n","N=50\n","k_range = range (1,N+1)\n","scores={}\n","scores_list = []\n","for k in k_range:\n","  classifier = AdaBoostClassifier(n_estimators=k,random_state=0)\n","  classifier.fit(X_train, y_train)\n","  y_pred=classifier.predict(X_test)\n","  scores[k] = accuracy_score(y_test,y_pred)\n","  scores_list.append(accuracy_score(y_test,y_pred))\n","  print(str(k)+\"/\"+str(N)+\" round completed......................... Accurecy: \"+str(accuracy_score(y_test,y_pred)))\n","\n","\n","\n","%matplotlib inline\n","import matplotlib.pyplot as plt\n","#plot the relationship between K and the testing accuracy\n","plt.figure(figsize = (25,10))\n","plt.plot(k_range,scores_list)\n","plt.xlabel('Value of n_estimators')\n","plt.ylabel ('Testing Accuracy')\n","\n","\n","\n","print(\"The best n_estimators:\")\n","best_estimator=list(scores.keys())[scores_list.index(max(scores_list))]\n","print(best_estimator)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ctzoGCmFo0In"},"outputs":[],"source":["from sklearn.ensemble import AdaBoostClassifier\n","\n","ada_best_estimator = AdaBoostClassifier(n_estimators=best_estimator,random_state=0)\n","ada_best_estimator.fit(X_train, y_train)\n","y_pred = ada_best_estimator.predict(X_test)\n","\n","from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n","print(confusion_matrix(y_test, y_pred))\n","print(classification_report(y_test,y_pred))\n","print(\"Accurecy: \",accuracy_score(y_test, y_pred))\n","result[(ada_best_estimator,1,'AdaBoostClassifier')]=accuracy_score(y_test, y_pred)"]},{"cell_type":"markdown","metadata":{"id":"JQhATacCo1AD"},"source":["\n","\n","---\n","\n","\n","\n","---\n","\n"]},{"cell_type":"markdown","metadata":{"id":"FJybpt_UvCU0"},"source":["#Graddient Boosting"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sgmvc8A_o18j"},"outputs":[],"source":["from sklearn.ensemble import GradientBoostingClassifier\n","from sklearn.model_selection import RepeatedStratifiedKFold\n","\n","gradBoost_default = GradientBoostingClassifier(random_state=0)\n","gradBoost_default.fit(X_train, y_train)\n","y_pred = gradBoost_default.predict(X_test)\n","\n","from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n","print(confusion_matrix(y_test, y_pred))\n","print(classification_report(y_test,y_pred))\n","print(\"Accurecy: \",accuracy_score(y_test, y_pred))\n","result[(gradBoost_default,2,'GradientBoostingClassifier')]=accuracy_score(y_test, y_pred)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9brp-qNgo-tX"},"outputs":[],"source":["from sklearn.ensemble import GradientBoostingClassifier\n","from sklearn.metrics import accuracy_score\n","N=50\n","k_range = range (1,N+1)\n","scores={}\n","scores_list = []\n","for k in k_range:\n","  classifier = GradientBoostingClassifier(n_estimators=k,random_state=0)\n","  classifier.fit(X_train, y_train)\n","  y_pred=classifier.predict(X_test)\n","  scores[k] = accuracy_score(y_test,y_pred)\n","  scores_list.append(accuracy_score(y_test,y_pred))\n","  print(str(k)+\"/\"+str(N)+\" round completed......................... Accurecy: \"+str(accuracy_score(y_test,y_pred)))\n","\n","\n","\n","%matplotlib inline\n","import matplotlib.pyplot as plt\n","\n","plt.figure(figsize = (25,10))\n","plt.plot(k_range,scores_list)\n","plt.xlabel('Value of n_estimators')\n","plt.ylabel ('Testing Accuracy')\n","\n","\n","\n","print(\"The best n_estimators:\")\n","best_estimator=list(scores.keys())[scores_list.index(max(scores_list))]\n","print(best_estimator)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JtO5QAkHpDAy"},"outputs":[],"source":["from sklearn.ensemble import GradientBoostingClassifier\n","from sklearn.metrics import accuracy_score\n","N=14\n","k_range = range (1,N+1)\n","scores={}\n","scores_list = []\n","for k in k_range:\n","  classifier = GradientBoostingClassifier(max_depth=k,random_state=0)\n","  classifier.fit(X_train, y_train)\n","  y_pred=classifier.predict(X_test)\n","  scores[k] = accuracy_score(y_test,y_pred)\n","  scores_list.append(accuracy_score(y_test,y_pred))\n","  print(str(k)+\"/\"+str(N)+\" round completed......................... Accurecy: \"+str(accuracy_score(y_test,y_pred)))\n","\n","\n","\n","%matplotlib inline\n","import matplotlib.pyplot as plt\n","\n","plt.figure(figsize = (25,10))\n","plt.plot(k_range,scores_list)\n","plt.xlabel('Value of n_estimators')\n","plt.ylabel ('Testing Accuracy')\n","\n","\n","\n","print(\"The best Depth:\")\n","best_depth=list(scores.keys())[scores_list.index(max(scores_list))]\n","print(best_depth)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EFg4mMYepGXx"},"outputs":[],"source":["from sklearn.ensemble import GradientBoostingClassifier\n","\n","gradBoost_estimator = GradientBoostingClassifier(n_estimators=best_estimator,random_state=0)\n","gradBoost_estimator.fit(X_train, y_train)\n","y_pred = gradBoost_estimator.predict(X_test)\n","\n","from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n","print(confusion_matrix(y_test, y_pred))\n","print(classification_report(y_test,y_pred))\n","print(\"Accurecy: \",accuracy_score(y_test, y_pred))\n","result[(gradBoost_estimator,2,'GradientBoostingClassifier')]=accuracy_score(y_test, y_pred)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oS_ycrCQpI09"},"outputs":[],"source":["from sklearn.ensemble import GradientBoostingClassifier\n","\n","gradBoost_depth = GradientBoostingClassifier(max_depth=best_depth,random_state=0)\n","gradBoost_depth.fit(X_train, y_train)\n","y_pred = gradBoost_depth.predict(X_test)\n","\n","from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n","print(confusion_matrix(y_test, y_pred))\n","print(classification_report(y_test,y_pred))\n","print(\"Accurecy: \",accuracy_score(y_test, y_pred))\n","\n","result[(gradBoost_depth,2,'GradientBoostingClassifier')]=accuracy_score(y_test, y_pred)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GU8wNje3pJjR"},"outputs":[],"source":["from sklearn.ensemble import GradientBoostingClassifier\n","\n","gradBoost_all = GradientBoostingClassifier(n_estimators=best_estimator,max_depth=best_depth,random_state=0)\n","gradBoost_all.fit(X_train, y_train)\n","y_pred = gradBoost_all.predict(X_test)\n","\n","from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n","print(confusion_matrix(y_test, y_pred))\n","print(classification_report(y_test,y_pred))\n","print(\"Accurecy: \",accuracy_score(y_test, y_pred))\n","\n","result[(gradBoost_all,2,'GradientBoostingClassifier')]=accuracy_score(y_test, y_pred)"]},{"cell_type":"markdown","metadata":{"id":"ThoTlhc4pRJT"},"source":["\n","\n","---\n","\n","\n","\n","---\n","\n"]},{"cell_type":"markdown","metadata":{"id":"AgMT_U8gvM7F"},"source":["#Random Forest"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-4GMunEvtWk2"},"outputs":[],"source":["from sklearn.ensemble import RandomForestClassifier\n","rf_default = RandomForestClassifier(random_state=0)\n","rf_default.fit(X_train, y_train)\n","y_pred=rf_default.predict(X_test)\n","\n","\n","from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n","print(confusion_matrix(y_test, y_pred))\n","print(classification_report(y_test,y_pred))\n","print(\"Accurecy: \",accuracy_score(y_test, y_pred))\n","result[(rf_default,3,'RandomForestClassifier')]=accuracy_score(y_test, y_pred)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ve34YgestieE"},"outputs":[],"source":["from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score\n","N=150\n","k_range = range (1,N+1)\n","scores={}\n","scores_list = []\n","for k in k_range:\n","  classifier = RandomForestClassifier(n_estimators=k,random_state=0)\n","  classifier.fit(X_train, y_train)\n","  y_pred=classifier.predict(X_test)\n","  scores[k] = accuracy_score(y_test,y_pred)\n","  scores_list.append(accuracy_score(y_test,y_pred))\n","  print(str(k)+\"/\"+str(N)+\" round completed......................... Accurecy: \"+str(accuracy_score(y_test,y_pred)))\n","\n","\n","\n","%matplotlib inline\n","import matplotlib.pyplot as plt\n","\n","plt.figure(figsize = (25,10))\n","plt.plot(k_range,scores_list)\n","plt.xlabel('Value of n_estimators')\n","plt.ylabel ('Testing Accuracy')\n","\n","\n","\n","print(\"The best n_estimators:\")\n","best_estimator=list(scores.keys())[scores_list.index(max(scores_list))]\n","print(best_estimator)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eVfKbSTWtnny"},"outputs":[],"source":["from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score\n","N=30\n","k_range = range (1,N+1)\n","scores={}\n","scores_list = []\n","for k in k_range:\n","  classifier = RandomForestClassifier(max_depth=k,random_state=0)\n","  classifier.fit(X_train, y_train)\n","  y_pred=classifier.predict(X_test)\n","  scores[k] = accuracy_score(y_test,y_pred)\n","  scores_list.append(accuracy_score(y_test,y_pred))\n","  print(str(k)+\"/\"+str(N)+\" round completed......................... Accurecy: \"+str(accuracy_score(y_test,y_pred)))\n","\n","\n","\n","%matplotlib inline\n","import matplotlib.pyplot as plt\n","\n","plt.figure(figsize = (25,10))\n","plt.plot(k_range,scores_list)\n","plt.xlabel('Value of n_estimators')\n","plt.ylabel ('Testing Accuracy')\n","\n","\n","\n","print(\"The best Depth:\")\n","best_depth=list(scores.keys())[scores_list.index(max(scores_list))]\n","print(best_depth)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LMUwwEqUt2-T"},"outputs":[],"source":["from sklearn.ensemble import RandomForestClassifier\n","rf_estimator = RandomForestClassifier(n_estimators=best_estimator,random_state=0)\n","rf_estimator.fit(X_train, y_train)\n","y_pred=rf_estimator.predict(X_test)\n","\n","\n","from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n","print(confusion_matrix(y_test, y_pred))\n","print(classification_report(y_test,y_pred))\n","print(\"Accurecy: \",accuracy_score(y_test, y_pred))\n","result[(rf_estimator,3,'RandomForestClassifier')]=accuracy_score(y_test, y_pred)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NRybS4-nt_vO"},"outputs":[],"source":["from sklearn.ensemble import RandomForestClassifier\n","rf_depth = RandomForestClassifier(max_depth=best_depth,random_state=0)\n","rf_depth.fit(X_train, y_train)\n","y_pred=rf_depth.predict(X_test)\n","\n","\n","from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n","print(confusion_matrix(y_test, y_pred))\n","print(classification_report(y_test,y_pred))\n","print(\"Accurecy: \",accuracy_score(y_test, y_pred))\n","result[(rf_depth,3,'RandomForestClassifier')]=accuracy_score(y_test, y_pred)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G9p0fJyBtrdZ"},"outputs":[],"source":["from sklearn.ensemble import RandomForestClassifier\n","rf_all = RandomForestClassifier(n_estimators=best_estimator,max_depth=best_depth,random_state=0)\n","rf_all.fit(X_train, y_train)\n","y_pred=rf_all.predict(X_test)\n","\n","\n","from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n","print(confusion_matrix(y_test, y_pred))\n","print(classification_report(y_test,y_pred))\n","print(\"Accurecy: \",accuracy_score(y_test, y_pred))\n","result[(rf_all,3,'RandomForestClassifier')]=accuracy_score(y_test, y_pred)"]},{"cell_type":"markdown","metadata":{"id":"G_DChNuquB92"},"source":["\n","\n","---\n","\n","\n","\n","---\n","\n"]},{"cell_type":"markdown","metadata":{"id":"jRG4cBnKvZU2"},"source":["#XGB"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sC1lAZeeuCw8"},"outputs":[],"source":["\n","\n","import xgboost as xgb\n","xgb_deafult = xgb.XGBClassifier(random_state=0)\n","xgb_deafult.fit(X_train.values,y_train.values)\n","y_pred = xgb_deafult.predict(X_test.values)\n","\n","\n","from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n","print(confusion_matrix(y_test, y_pred))\n","print(classification_report(y_test,y_pred))\n","print(\"Accurecy: \",accuracy_score(y_test, y_pred))\n","result[(xgb_deafult,4,'xgboost')]=accuracy_score(y_test, y_pred)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YQYsfVO0uPMA"},"outputs":[],"source":["import xgboost as xgb\n","from sklearn.metrics import accuracy_score\n","N=250\n","k_range = range (1,N+1)\n","scores={}\n","scores_list = []\n","for k in k_range:\n","  xgb_classifier = xgb.XGBClassifier(n_estimators=k,random_state=0)\n","  xgb_classifier.fit(X_train.values, y_train.values)\n","  y_pred=xgb_classifier.predict(X_test.values)\n","  scores[k] = accuracy_score(y_test,y_pred)\n","  scores_list.append(accuracy_score(y_test,y_pred))\n","  print(str(k)+\"/\"+str(N)+\" round completed......................... Accurecy: \"+str(accuracy_score(y_test,y_pred)))\n","\n","\n","%matplotlib inline\n","import matplotlib.pyplot as plt\n","\n","plt.figure(figsize = (25,10))\n","plt.plot(k_range,scores_list)\n","plt.xlabel('Value of n_estimators')\n","plt.ylabel ('Testing Accuracy')\n","\n","\n","\n","print(\"The best n_estimators:\")\n","best_estimator=list(scores.keys())[scores_list.index(max(scores_list))]\n","print(best_estimator)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ABex6e-3kxuX"},"outputs":[],"source":["import xgboost as xgb\n","from sklearn.metrics import accuracy_score\n","N=30\n","k_range = range (1,N+1)\n","scores={}\n","scores_list = []\n","for k in k_range:\n","  xgb_classifier = xgb.XGBClassifier(max_depth=k,random_state=0)\n","  xgb_classifier.fit(X_train.values, y_train.values)\n","  y_pred=xgb_classifier.predict(X_test.values)\n","  scores[k] = accuracy_score(y_test,y_pred)\n","  scores_list.append(accuracy_score(y_test,y_pred))\n","  print(str(k)+\"/\"+str(N)+\" round completed......................... Accurecy: \"+str(accuracy_score(y_test,y_pred)))\n","\n","\n","%matplotlib inline\n","import matplotlib.pyplot as plt\n","\n","plt.figure(figsize = (25,10))\n","plt.plot(k_range,scores_list)\n","plt.xlabel('Value of n_estimators')\n","plt.ylabel ('Testing Accuracy')\n","\n","\n","\n","print(\"The best depth:\")\n","best_depth=list(scores.keys())[scores_list.index(max(scores_list))]\n","print(best_depth)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lfBp-uGXuaKY"},"outputs":[],"source":["import xgboost as xgb\n","xgb_depth = xgb.XGBClassifier(max_depth=best_depth,random_state=0)\n","xgb_depth.fit(X_train.values,y_train.values)\n","y_pred = xgb_depth.predict(X_test.values)\n","\n","\n","from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n","print(confusion_matrix(y_test, y_pred))\n","print(classification_report(y_test,y_pred))\n","print(\"Accurecy: \",accuracy_score(y_test, y_pred))\n","result[(xgb_depth,4,'xgboost')]=accuracy_score(y_test, y_pred)\n","print(xgb_depth)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_qBm-yTqzOsi"},"outputs":[],"source":["import xgboost as xgb\n","xgb_estimator = xgb.XGBClassifier(n_estimators=best_estimator,random_state=0)\n","xgb_estimator.fit(X_train.values,y_train.values)\n","y_pred = xgb_estimator.predict(X_test.values)\n","\n","\n","from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n","print(confusion_matrix(y_test, y_pred))\n","print(classification_report(y_test,y_pred))\n","print(\"Accurecy: \",accuracy_score(y_test, y_pred))\n","result[(xgb_estimator,4,'xgboost')]=accuracy_score(y_test, y_pred)\n","print(xgb_estimator)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zW-0PfT-zX3C"},"outputs":[],"source":["import xgboost as xgb\n","xgb_all = xgb.XGBClassifier(n_estimators=best_estimator,max_depth=best_depth,random_state=0)\n","xgb_all.fit(X_train.values,y_train.values)\n","y_pred = xgb_all.predict(X_test.values)\n","\n","\n","from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n","print(confusion_matrix(y_test, y_pred))\n","print(classification_report(y_test,y_pred))\n","print(\"Accurecy: \",accuracy_score(y_test, y_pred))\n","result[(xgb_all,4,'xgboost')]=accuracy_score(y_test, y_pred)"]},{"cell_type":"markdown","metadata":{"id":"K6_icFWdauSI"},"source":["#KNN"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6GALUBYbaz1z"},"outputs":[],"source":["from sklearn.neighbors import KNeighborsClassifier\n","knn_default = KNeighborsClassifier()\n","knn_default.fit(X_train, y_train)\n","y_pred=knn_default.predict(X_test)\n","\n","\n","from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n","print(confusion_matrix(y_test, y_pred))\n","print(classification_report(y_test,y_pred))\n","print(\"Accurecy: \",accuracy_score(y_test, y_pred))\n","result[(knn_default,5,'KNeighborsClassifier')]=accuracy_score(y_test, y_pred)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CpSsmYDHa-VF"},"outputs":[],"source":["from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.metrics import accuracy_score\n","Neighbors=105\n","k_range = range (1,Neighbors+1)\n","scores={}\n","scores_list = []\n","for k in k_range:\n","  knn = KNeighborsClassifier(n_neighbors=k)\n","  knn.fit(X_train, y_train)\n","  y_pred=knn.predict(X_test)\n","  scores[k] = accuracy_score(y_test,y_pred)\n","  scores_list.append(accuracy_score(y_test,y_pred))\n","  print(str(k)+\"/\"+str(Neighbors)+\" round completed......................... Accurecy: \"+str(accuracy_score(y_test,y_pred)))\n","\n","\n","%matplotlib inline\n","import matplotlib.pyplot as plt\n","\n","plt.figure(figsize = (25,10))\n","plt.plot(k_range,scores_list)\n","plt.xlabel('Value of n_estimators')\n","plt.ylabel ('Testing Accuracy')\n","\n","\n","\n","print(\"The best Depth:\")\n","best=list(scores.keys())[scores_list.index(max(scores_list))]\n","print(best)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MIVJZYV8bCjo"},"outputs":[],"source":["from sklearn.neighbors import KNeighborsClassifier\n","knn_neighbors = KNeighborsClassifier(n_neighbors=best)\n","knn_neighbors.fit(X_train, y_train)\n","y_pred=knn_neighbors.predict(X_test)\n","\n","\n","from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n","print(confusion_matrix(y_test, y_pred))\n","print(classification_report(y_test,y_pred))\n","print(\"Accurecy: \",accuracy_score(y_test, y_pred))\n","result[(knn_neighbors,5,'KNeighborsClassifier')]=accuracy_score(y_test, y_pred)"]},{"cell_type":"markdown","metadata":{"id":"_Btki9jRvc1Y"},"source":["#NB"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iRmd7ve-ubcd"},"outputs":[],"source":["from sklearn.naive_bayes import GaussianNB\n","\n","nb_deafult = GaussianNB()\n","nb_deafult.fit(X_train, y_train)\n","y_pred = nb_deafult.predict(X_test)\n","\n","\n","from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n","print(confusion_matrix(y_test, y_pred))\n","print(classification_report(y_test,y_pred))\n","print(\"Accurecy: \",accuracy_score(y_test, y_pred))\n","result[(nb_deafult,6,'GaussianNB')]=accuracy_score(y_test, y_pred)"]},{"cell_type":"markdown","metadata":{"id":"qqsWPAB3uv72"},"source":["\n","\n","---\n","\n","\n","\n","---\n","\n"]},{"cell_type":"markdown","metadata":{"id":"6FEsxCdvkg2D"},"source":["#Result"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rx7qCLU14Aim"},"outputs":[],"source":["\n","models=[]\n","\n","for i in result:\n","  models.append(i[0])\n","  print(i[0],i[1],\" : \",result[i])\n","  print(\"---------------------------------------------------------------\")\n","  print()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"slItYG8uLOFi"},"outputs":[],"source":["sorted_list=[]\n","sorted_list = sorted(result, key=result.get,reverse=True)\n","\n","for i in sorted_list:\n","  print(i,\"  : \",result[i])\n","  print(\"-------------------------------------------------------------------------------------------------\")\n","\n","print(sorted_list)\n","\n","\n","flage=[]\n","best_models=[]\n","it=0\n","\n","for i in sorted_list:\n","  if it==4:\n","    break\n","\n","  if i[1] not in flage:\n","    best_models.append((i[0],i[2]))\n","    flage.append(i[1])\n","    it+=1\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SR0XBsJDMi_1"},"outputs":[],"source":["print(\"best_models:\")\n","for i in best_models:\n","  print(i)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VQCaVYKA5acD"},"outputs":[],"source":["len(best_models)"]},{"cell_type":"markdown","metadata":{"id":"6PooiLPlL9WO"},"source":["#Performance parameter for each class"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S9nWU11PMDQ8"},"outputs":[],"source":["\n","def confusion_details(y_test,y_pred):\n","    labels = list(set(y_test))\n","    labels.sort()\n","\n","    print(\"Total labels: %s -> %s\" % (len(labels), labels))\n","\n","    df = pd.DataFrame(\n","        data=confusion_matrix(y_test, y_pred, labels=labels),\n","        columns=labels,\n","        index=labels\n","    )\n","\n","    print(df)\n","\n","    print()\n","    print(\"----------------------------------------------------------------------------------------\")\n","    print(\"----------------------------------------------------------------------------------------\")\n","    print()\n","    #\n","    # Local (metrics per class)\n","    #\n","    tps = {}\n","    fps = {}\n","    fns = {}\n","    tns = {}\n","\n","    precision_local = {}\n","    recall_local = {}\n","    f1_local = {}\n","    accuracy_local = {}\n","    specificity_local={}\n","\n","    for label in labels:\n","        tps[label] = df.loc[label, label]\n","        fps[label] = df[label].sum() - tps[label]\n","        fns[label] = df.loc[label].sum() - tps[label]\n","        tns[label]=len(y_test) - (tps[label] + fps[label] + fns[label])\n","        \n","        tp, fp, fn, tn = tps[label], fps[label], fns[label], tns[label]\n","        \n","        precision_local[label] = tp / (tp + fp) if (tp + fp) > 0. else 0.\n","        specificity_local[label] = tn / (tn + fp) if (tn + fp) > 0. else 0.\n","        recall_local[label] = tp / (tp + fn) if (tp + fp) > 0. else 0.\n","        p, r = precision_local[label], recall_local[label]\n","        \n","        f1_local[label] = 2. * p * r / (p + r) if (p + r) > 0. else 0.\n","        accuracy_local[label] = tp / (tp + fp + fn) if (tp + fp + fn) > 0. else 0.\n","\n","\n","\n","    print(\"#-- Local measures --#\")\n","    print(\"True Positives(TP):\", tps)\n","    print(\"False Positives(FP):\", fps)\n","    print(\"True Negatives(TN):\", tns)\n","    print(\"False Negatives(FN):\", fns)\n","    print(\"----------------------------\")\n","\n","    print(\"Precision:\", precision_local)\n","    print(\"Recall/Sensitivity:\", recall_local)\n","    print(\"Specificity:\",specificity_local)\n","    print(\"F1-Score:\", f1_local)\n","    print(\"Accuracy:\", accuracy_local)\n","\n","\n","    print()\n","    print(\"----------------------------------------------------------------------------------------\")\n","    print(\"----------------------------------------------------------------------------------------\")\n","    print()\n","    #\n","    # Global\n","    #\n","    micro_averages = {}\n","    macro_averages = {}\n","\n","    correct_predictions = sum(tps.values())\n","    true_negative=sum(tns.values())\n","\n","    den = sum(list(tps.values()) + list(fps.values()))\n","    micro_averages[\"Precision\"] = 1. * correct_predictions / den if den > 0. else 0.\n","\n","    den = sum(list(tps.values()) + list(fns.values()))\n","    micro_averages[\"Recall\"] = 1. * correct_predictions / den if den > 0. else 0.\n","\n","    den = sum(list(tns.values()) + list(fps.values()))\n","    micro_averages[\"Specificity\"] = 1. * true_negative / den if den > 0. else 0.\n","\n","\n","    micro_avg_p, micro_avg_r = micro_averages[\"Precision\"], micro_averages[\"Recall\"]\n","    micro_averages[\"F1-score\"] = 2. * micro_avg_p * micro_avg_r / (micro_avg_p + micro_avg_r) if (micro_avg_p + micro_avg_r) > 0. else 0.\n","\n","    macro_averages[\"Precision\"] = np.mean(list(precision_local.values()))\n","    macro_averages[\"Recall\"] = np.mean(list(recall_local.values()))\n","    macro_averages[\"Specificity\"]=np.mean(list(specificity_local.values()))\n","\n","\n","    macro_avg_p, macro_avg_r = macro_averages[\"Precision\"], macro_averages[\"Recall\"]\n","    macro_averages[\"F1-Score\"] = 2. * macro_avg_p * macro_avg_r / (macro_avg_p + macro_avg_r) if (macro_avg_p + macro_avg_r) > 0. else 0.\n","\n","    total_predictions = df.values.sum()\n","    accuracy_global = correct_predictions / total_predictions if total_predictions > 0. else 0.\n","\n","    print(\"#-- Global measures --#\")\n","    print(\"Micro-Averages:\", micro_averages)\n","    print(\"Macro-Averages:\", macro_averages)\n","    print(\"Correct predictions:\", correct_predictions)\n","    print(\"Total predictions:\", total_predictions)\n","    print(\"Accuracy:\", accuracy_global)\n","\n","\n","    print()\n","    print(\"----------------------------------------------------------------------------------------\")\n","    print(\"----------------------------------------------------------------------------------------\")\n","    print()\n","\n","\n","\n","    accuracy_local_new = {}\n","    for label in labels:\n","        tp, fp, fn, tn = tps[label], fps[label], fns[label], tns[label]\n","        accuracy_local_new[label] = (tp + tn) / (tp + fp + fn + tn) if (tp + fp + fn + tn) > 0. else 0.\n","\n","    total_true = sum(list(tps.values()) + list(tns.values()))\n","    total_predictions = sum(list(tps.values()) + list(tns.values()) + list(fps.values()) + list(fns.values()))\n","    accuracy_global_new = 1. * total_true / total_predictions if total_predictions > 0. else 0.\n","\n","    print(\"Accuracy (per class), with TNs:\", accuracy_local_new)\n","    print(\"Accuracy (per class), without TNs:\", accuracy_local)\n","    print(\"Accuracy (global), with TNs:\", accuracy_global_new)\n","    print(\"Accuracy (global), without TNs:\", accuracy_global)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8mKUfZr2MaMp"},"outputs":[],"source":["new_keys_10=models_check_box(models)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LnHsPRwOMIGQ"},"outputs":[],"source":["for i in range(len(new_keys_10)):\n","  if new_keys_10[i].value ==True:\n","    print(\"\\n\")\n","    print(\"_________________________________________________\",models[i],\"_______________________________________________\")\n","\n","    if str(models[i])[:3] == \"XGB\":\n","      y_pred = models[i].predict(X_test.values)\n","      confusion_details(y_test,y_pred)\n","    \n","    else:\n","      y_pred = models[i].predict(X_test)\n","      confusion_details(y_test,y_pred)\n","    print('\\n')\n","    print(\"-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\")\n","    print(\"-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\")\n","    print(\"-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\")\n","    print('\\n')\n","    print('\\n')"]},{"cell_type":"markdown","metadata":{"id":"znXNx2bgUvtd"},"source":["#Testing Accuracy For Best 4 Models"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2j9CXuBkUuiR"},"outputs":[],"source":["\n","for i in best_models:\n","  print(\"--------------------------------------------------\")\n","  print()\n","  if str(i[0])[:3] == \"XGB\":\n","    y_pred=i[0].predict(X_test.values)\n","  else:\n","    y_pred=i[0].predict(X_test)\n","  print(confusion_matrix(y_test, y_pred))\n","  print(classification_report(y_test,y_pred))\n","  print(\"Accurecy: \",accuracy_score(y_test, y_pred))"]},{"cell_type":"markdown","metadata":{"id":"zxxWSX26jsGT"},"source":["#SHAP"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YUhJ7dWajur-"},"outputs":[],"source":["!pip install shap\n","import shap"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"POk0kUrdB-Y4"},"outputs":[],"source":["\n","def SHAP_EXP(model,graph_feat):\n","  print(\"Models: \",model)\n","\n","  explainer = shap.Explainer(model.predict, X_test)\n","\n","  shap_values1 = explainer(X_test)\n","  features_names=list_of_feat\n","\n","  if 'Subjects' in features_names:\n","    features_names.pop(0)\n","\n","\n","  shap.plots.bar(shap_values1,max_display=graph_feat[\"max_display\"])\n","\n","  print(\"---------------------\")\n","\n","  shap.summary_plot(shap_values1,max_display=graph_feat[\"max_display\"],feature_names=features_names)\n","\n","  print(\"---------------------\")\n","\n","  print(\"Local Explaination\")\n","  shap.plots.waterfall(shap_values1[graph_feat[\"shap_values Index\"]],max_display=graph_feat[\"max_display\"])\n","\n","\n","  print(\"---------------------\")\n","\n","  shap.plots.bar(shap_values1[graph_feat[\"shap_values Index\"]],max_display=graph_feat[\"max_display\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V-G5szfQDiz1"},"outputs":[],"source":["new_keys_7=models_check_box(models)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JeD8HT_iDodb"},"outputs":[],"source":["graph_feat={\n","    \"max_display\":20,\n","    \"shap_values Index\":2\n","}\n","\n","for i in range(len(new_keys_7)):\n","  if new_keys_7[i].value ==True:\n","    SHAP_EXP(models[i],graph_feat)\n","    print(\"---------------------------------------------------------\")\n","    print(\"---------------------------------------------------------\")\n","    print(\"---------------------------------------------------------\")\n","    print(\"---------------------------------------------------------\")"]},{"cell_type":"markdown","metadata":{"id":"23z3A3f1ol6d"},"source":["#Confusion Matrix For Testing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_NfXI6K5aqG6"},"outputs":[],"source":["def Conf_Mat(X_,y_,attb,keys):\n","\n","  import matplotlib.pyplot as plt\n","  from yellowbrick.classifier import ConfusionMatrix\n","  import matplotlib.dates as dates\n","\n","  fig = plt.figure(figsize=(attb[\"Fig Height\"],attb[\"Fig weidth\"]))\n","  ax = fig.add_subplot(111)\n","\n","\n","  for i in range(len(keys)):\n","    if keys[i].value ==True:\n","      cm = ConfusionMatrix(models[i], classes=['Reading', 'Resting', 'Walking', 'Working'],fontsize=attb[\"Confusion Matrix Inner Fontsize\"],ax=ax)\n","\n","      if str(models[i])[:3] == \"XGB\":\n","        cm.fit(X_train.values, y_train.values)\n","        cm.score(X_.values, y_.values)\n","      else:\n","        cm.fit(X_train, y_train)\n","        cm.score(X_, y_)\n","      \n","      cm.ax.set_xlabel(\"Predicted Class\", fontsize=attb[\"X Axis Fontsize\"],fontweight=\"bold\")\n","      cm.ax.set_ylabel(\"True Class\", fontsize=attb[\"Y Axis Fontsize\"],fontweight=\"bold\")\n","      cm.ax.xaxis.set_tick_params(labelsize=attb[\"X Label Fontsize\"])\n","      cm.ax.yaxis.set_tick_params(labelsize=attb[\"Y Label Fontsize\"])\n","      for label in ax.get_xticklabels():\n","        label.set_fontweight(550)\n","      for label in ax.get_yticklabels():\n","        label.set_fontweight(550)\n","      \n","      plt.savefig(attb[\"type\"]+\"_Confusion_mat(\"+str(models[i])+\").png\")\n","      cm.show()\n","      print(\"--------------------\")\n","      print(\"--------------------\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b3tHiraMBr_C"},"outputs":[],"source":["new_keys_6=models_check_box(models)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5vsqEYhponhI"},"outputs":[],"source":["attributes={\n","   \"Fig Height\": 10,\n","   \"Fig weidth\": 10, \n","    \n","  \"Y Axis Fontsize\" : 20,\n","  \"X Axis Fontsize\" : 20,\n","\n","  \"Y Label Fontsize\" : 20,\n","  \"X Label Fontsize\" : 20,\n","\n","  \"Confusion Matrix Inner Fontsize\": 18,\n","  \"type\"  : \"Testing\"\n","\n","}\n","\n","Conf_Mat(X_test,y_test,attributes,new_keys_6)"]},{"cell_type":"markdown","source":["#Confusion Matrix for Testing ( with Percent)"],"metadata":{"id":"HdAPZkWvp08K"}},{"cell_type":"code","source":["def Conf_Mat_percent(X_,y_,attb,keys):\n","\n","  import matplotlib.pyplot as plt\n","  from yellowbrick.classifier import ConfusionMatrix\n","  import matplotlib.dates as dates\n","\n","  fig = plt.figure(figsize=(attb[\"Fig Height\"],attb[\"Fig weidth\"]))\n","  ax = fig.add_subplot(111)\n","\n","\n","  for i in range(len(keys)):\n","    if keys[i].value ==True:\n","      cm = ConfusionMatrix(models[i], classes=['Reading', 'Resting', 'Walking', 'Working'],fontsize=attb[\"Confusion Matrix Inner Fontsize\"],ax=ax,percent=True)\n","\n","      if str(models[i])[:3] == \"XGB\":\n","        cm.fit(X_train.values, y_train.values)\n","        cm.score(X_.values, y_.values)\n","      else:\n","        cm.fit(X_train, y_train)\n","        cm.score(X_, y_)\n","      \n","      cm.ax.set_xlabel(\"Predicted Class\", fontsize=attb[\"X Axis Fontsize\"],fontweight=\"bold\")\n","      cm.ax.set_ylabel(\"True Class\", fontsize=attb[\"Y Axis Fontsize\"],fontweight=\"bold\")\n","      cm.ax.xaxis.set_tick_params(labelsize=attb[\"X Label Fontsize\"])\n","      cm.ax.yaxis.set_tick_params(labelsize=attb[\"Y Label Fontsize\"])\n","      for label in ax.get_xticklabels():\n","        label.set_fontweight(550)\n","      for label in ax.get_yticklabels():\n","        label.set_fontweight(550)\n","      \n","      plt.savefig(attb[\"type\"]+\"_Confusion_mat(\"+str(models[i])+\").png\")\n","      cm.show()\n","      print(\"--------------------\")\n","      print(\"--------------------\")"],"metadata":{"id":"NjmCvk6Sp_vm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["new_keys_20=models_check_box(models)"],"metadata":{"id":"zkPx8YfsqHUr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["attributes={\n","   \"Fig Height\": 10,\n","   \"Fig weidth\": 10, \n","    \n","  \"Y Axis Fontsize\" : 20,\n","  \"X Axis Fontsize\" : 20,\n","\n","  \"Y Label Fontsize\" : 20,\n","  \"X Label Fontsize\" : 20,\n","\n","  \"Confusion Matrix Inner Fontsize\": 18,\n","  \"type\"  : \"Training\"\n","\n","}\n","\n","Conf_Mat_percent(X_test,y_test,attributes,new_keys_20)"],"metadata":{"id":"gGdVSMcXqIK4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"57cQ8dzJX0Lp"},"source":["#Confusion Matrix For Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tDrF5oTkBcZ_"},"outputs":[],"source":["new_keys_5=models_check_box(models)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jhzRUmq9X4CZ"},"outputs":[],"source":["attributes={\n","   \"Fig Height\": 10,\n","   \"Fig weidth\": 10, \n","    \n","  \"Y Axis Fontsize\" : 20,\n","  \"X Axis Fontsize\" : 20,\n","\n","  \"Y Label Fontsize\" : 20,\n","  \"X Label Fontsize\" : 20,\n","\n","  \"Confusion Matrix Inner Fontsize\": 18,\n","  \"type\"  : \"Training\"\n","\n","}\n","\n","Conf_Mat(X_train,y_train,attributes,new_keys_5)"]},{"cell_type":"markdown","source":["#Confusion Matrix for Training ( with Percent)"],"metadata":{"id":"yl_6PJLpqXKk"}},{"cell_type":"code","source":["new_keys_21=models_check_box(models)"],"metadata":{"id":"9OHxb3AAqYXU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["attributes={\n","   \"Fig Height\": 10,\n","   \"Fig weidth\": 10, \n","    \n","  \"Y Axis Fontsize\" : 20,\n","  \"X Axis Fontsize\" : 20,\n","\n","  \"Y Label Fontsize\" : 20,\n","  \"X Label Fontsize\" : 20,\n","\n","  \"Confusion Matrix Inner Fontsize\": 18,\n","  \"type\"  : \"Training\"\n","\n","}\n","\n","Conf_Mat_percent(X_train,y_train,attributes,new_keys_21)"],"metadata":{"id":"hSNapvifqbdJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"igsy215JGzfg"},"source":["#ROC FOR MULTICLASS"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UoPKNwlqG3ge"},"outputs":[],"source":["!pip install plotly==5.11.0\n","!pip install -U kaleido\n","\n","\n","import plotly.graph_objects as go\n","import plotly.express as px\n","import numpy as np\n","import pandas as pd\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import roc_curve, roc_auc_score\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","def ploty_ROC(model,X,y,fig_name,graph_attributes):\n","    \n","    lebel_dict={\n","    0: 'Reading',\n","    1: 'Resting',\n","    2: 'Walking',\n","    3: 'Working'\n","    }\n","    if str(model)[:3] == \"XGB\":\n","      y_scores = model.predict_proba(X.values)\n","    else:\n","      y_scores = model.predict_proba(X)\n","    #y_scores = model.predict_proba(X)\n","\n","    y_onehot = pd.get_dummies(y, columns=model.classes_)\n","\n","    fig = go.Figure()\n","    fig.add_shape(\n","        type='line', line=dict(dash='dash', width=5),        \n","        x0=0, x1=1, y0=0, y1=1\n","    )\n","\n","    for i in range(y_scores.shape[1]):\n","        y_true = y_onehot.iloc[:, i]\n","        y_score = y_scores[:, i]\n","\n","        fpr, tpr, _ = roc_curve(y_true, y_score)\n","        auc_score = roc_auc_score(y_true, y_score)\n","        name = f\"{lebel_dict[y_onehot.columns[i]]} (AUC={auc_score:.2f})\"\n","        fig.add_trace(go.Scatter(x=fpr, y=tpr, name=name, mode='lines'))\n","\n","    fig.update_layout(\n","        xaxis_title='False Positive Rate',\n","        yaxis_title='True Positive Rate',\n","        yaxis=dict(scaleanchor=\"x\", scaleratio=1),\n","        xaxis=dict(constrain='domain'),\n","        width=1000, height=1000,\n","        font=dict(\n","            family=\"Arial Black, monospace\",\n","            size=graph_attributes[\"Font Size\"],\n","            color=graph_attributes[\"Font Color\"]\n","        ),\n","        legend=dict(\n","            x=0.62,\n","            y=0.05,\n","            traceorder=\"reversed\",\n","            title_font_family=\"Arial Black\",\n","            font=dict(\n","                family=\"Arial Black, monospace\",\n","                size=graph_attributes[\"Legend Font Size\"],\n","                color=graph_attributes[\"Legend Font Color\"]\n","            ),\n","            bgcolor=graph_attributes[\"Legend bgcolor\"],\n","            bordercolor=graph_attributes[\"Legend bordercolor\"],\n","            borderwidth=graph_attributes[\"Legend borderwidth\"]\n","        ),\n","        #plot_bgcolor=\"\",\n","    )\n","    fig.update_xaxes(showline=True, linewidth=2, linecolor='black', tickfont_family=\"Arial Black\")\n","    fig.update_yaxes(showline=True, linewidth=2, linecolor='black',tickfont_family=\"Arial Black\")\n","\n","    fig.show()\n","    fig.write_image(fig_name+\".png\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wa81Tk8naet6"},"outputs":[],"source":["new_keys_9=models_check_box(models)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aBCyRaVyZ-rG"},"outputs":[],"source":["\n","#Change the attriutes for graph\n","graph_attributes={\n","    \"Font Size\"  : 25,\n","    \"Font Color\" : \"black\",\n","    \"Legend Font Size\"  : 25,\n","    \"Legend Font Color\" : \"black\",\n","    \"Legend bgcolor\"    : \"LightSteelBlue\",\n","    \"Legend bordercolor\": \"White\",\n","    \"Legend borderwidth\": 1\n","\n","}\n","\n","\n","\n","for i in range(len(new_keys_9)):\n","  if new_keys_9[i].value ==True:\n","    print(models[i])\n","    fig1=ploty_ROC(models[i],X_train,y_train,str(models[i]),graph_attributes)\n","    fig2=ploty_ROC(models[i],X_test,y_test,str(models[i]),graph_attributes)\n","    print(\"---------------------------------------------------------\")\n","    print(\"---------------------------------------------------------\")\n","    print(\"---------------------------------------------------------\")\n","    print(\"---------------------------------------------------------\")"]},{"cell_type":"markdown","metadata":{"id":"XtgWbvJsEwMt"},"source":["#Cross_val_score function"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3unb_F6vE39m"},"outputs":[],"source":["from sklearn.model_selection import cross_val_score\n","\n","k=5\n","for i in result:\n","  print(i[0],\" -> Accuracy: \",result[i])\n","  l=list(cross_val_score(i[0],X_new, y_new,cv=k))\n","  avg=sum(l)/k\n","  print(i[0],\" -> AVG Accurecy After CV: \"+str(avg)+ \" (For \"+str(k)+\" Fold)\")\n","  print(\"--------------------------------------------------------------------------\")"]},{"cell_type":"markdown","metadata":{"id":"iDu8Ipdm8qaV"},"source":["# **LIME**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aokroGxh8oj9"},"outputs":[],"source":["!pip install lime"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5FaSwsYC4hL9"},"outputs":[],"source":["\n","  def LIME_EXP(model,row):\n","    import lime\n","    from lime import lime_tabular\n","\n","\n","    if str(model)[:3] == \"XGB\":\n","\n","      \"\"\"explainer = lime.lime_tabular.LimeTabularExplainer(\n","        X_train.values,\n","        feature_names=list(list(X_new.columns)),                                         \n","        class_names=['Reading', 'Resting', 'Walking', 'Working']\n","        )\n","      \n","      exp = explainer.explain_instance(X_test.iloc[row, :].values,\n","                                 model.predict_proba,\n","                                 num_features=6,\n","                                 top_labels=2)\"\"\"\n","      print(\"Plz RUN XGboost cell....\")\n","      return None\n","\n","\n","\n","    else:\n","      explainer = lime_tabular.LimeTabularExplainer(\n","        training_data=np.array(X_train),\n","        feature_names=list(X_new.columns),\n","        class_names=['Reading', 'Resting', 'Walking', 'Working'],\n","        mode='classification'\n","        )\n","\n","      exp = explainer.explain_instance(X_test.iloc[row],\n","                                      model.predict_proba,               \n","                                      num_features=6,\n","                                      top_labels=4)\n","    \n","\n","\n","    exp.show_in_notebook(show_table=True, show_all=True)\n","\n","\n","\n","    import matplotlib.pyplot as plt\n","    with plt.style.context(\"ggplot\"):\n","        exp.as_pyplot_figure()\n","\n","\n","    from IPython.display import HTML\n","    html_data = exp.as_html()\n","    HTML(data=html_data)\n","\n","    exp.save_to_file(str(model)+\".html\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"32KcHp_C40qQ"},"outputs":[],"source":["row = int(input(\"Enter the index of row to explain: \"))      # the index of row to be explained in LIME\n","\n","\n","new_keys_8=models_check_box(models)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T0b1o-1mBtnW"},"outputs":[],"source":["for i in range(len(new_keys_8)):\n","  if new_keys_8[i].value ==True:\n","    print(models[i])\n","    LIME_EXP(models[i],row)\n","    print(\"---------------------------------------------------------\")\n","    print(\"---------------------------------------------------------\")\n","    print(\"---------------------------------------------------------\")\n","    print(\"---------------------------------------------------------\")"]},{"cell_type":"markdown","metadata":{"id":"uShYm2_JU-kn"},"source":["### LIME for XGboost"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UiCt6pXuYhQU"},"outputs":[],"source":["row = 18  ## the index of row to be explained in LIME\n","\n","import lime\n","from lime import lime_tabular\n","explainer = lime.lime_tabular.LimeTabularExplainer(X_train.values,\n","                                                   feature_names=list(list(X_new.columns)),\n","                                                   class_names=['Reading', 'Resting', 'Walking', 'Working'])"]},{"cell_type":"markdown","metadata":{"id":"JV98gDirYqlI"},"source":["####Default"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"db_NRU-cVDfk"},"outputs":[],"source":["\n","exp = explainer.explain_instance(X_test.iloc[row, :].values,\n","                                 xgb_deafult.predict_proba,\n","                                 num_features=6,\n","                                 top_labels=4)\n","\n","exp.show_in_notebook(show_table=True, show_all=False)\n","\n","import matplotlib.pyplot as plt\n","with plt.style.context(\"ggplot\"):\n","    exp.as_pyplot_figure()\n","\n","\n","from IPython.display import HTML\n","html_data = exp.as_html()\n","HTML(data=html_data)\n","\n","exp.save_to_file(str(xgb_deafult)+\".html\")"]},{"cell_type":"markdown","metadata":{"id":"HCtRZ2soYvmm"},"source":["####Best Max Depth"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wmErRPogYdxA"},"outputs":[],"source":["\n","exp = explainer.explain_instance(X_test.iloc[row, :].values,\n","                                 xgb_depth.predict_proba,\n","                                 num_features=6,\n","                                 top_labels=4)\n","\n","exp.show_in_notebook(show_table=True, show_all=False)\n","\n","import matplotlib.pyplot as plt\n","with plt.style.context(\"ggplot\"):\n","    exp.as_pyplot_figure()\n","\n","\n","from IPython.display import HTML\n","html_data = exp.as_html()\n","HTML(data=html_data)\n","\n","exp.save_to_file(str(xgb_depth)+\".html\")"]},{"cell_type":"markdown","metadata":{"id":"Db6bDLDKZBu6"},"source":["####Best N Estimator"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nqJ6uclBYeb2"},"outputs":[],"source":["\n","\n","exp = explainer.explain_instance(X_test.iloc[row, :].values,\n","                                 xgb_estimator.predict_proba,\n","                                 num_features=6,\n","                                 top_labels=4)\n","\n","exp.show_in_notebook(show_table=True, show_all=False)\n","\n","import matplotlib.pyplot as plt\n","with plt.style.context(\"ggplot\"):\n","    exp.as_pyplot_figure()\n","\n","\n","from IPython.display import HTML\n","html_data = exp.as_html()\n","HTML(data=html_data)\n","\n","exp.save_to_file(str(xgb_estimator)+\".html\")"]},{"cell_type":"markdown","metadata":{"id":"oGZFn8-bZJoK"},"source":["####Best Depth and Best Estimator"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qPeJmpyvYfAW"},"outputs":[],"source":["\n","exp = explainer.explain_instance(X_test.iloc[row, :].values,\n","                                 xgb_all.predict_proba,\n","                                 num_features=6,\n","                                 top_labels=4)\n","\n","exp.show_in_notebook(show_table=True, show_all=False)\n","\n","\n","import matplotlib.pyplot as plt\n","with plt.style.context(\"ggplot\"):\n","    exp.as_pyplot_figure()\n","\n","\n","from IPython.display import HTML\n","html_data = exp.as_html()\n","HTML(data=html_data)\n","\n","exp.save_to_file(str(xgb_all)+\".html\")"]}],"metadata":{"colab":{"collapsed_sections":["rrR11h2K-aJn","85wbxGFW-kGZ","YAQ71nBV-p7E","jEe2R0yAoifa","FJybpt_UvCU0","AgMT_U8gvM7F","jRG4cBnKvZU2","K6_icFWdauSI","_Btki9jRvc1Y","znXNx2bgUvtd","zxxWSX26jsGT","XtgWbvJsEwMt"],"provenance":[{"file_id":"1HMurEFREQQX0ioOw4YSeuZ_ZIUnNuC8T","timestamp":1673273167705},{"file_id":"11vHt2UvW9sKj6WVLI0BehZoOcdQRh4Ei","timestamp":1673160611599}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}