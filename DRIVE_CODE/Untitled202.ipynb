{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOQnQwooZyByYNtYjBeeVc7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/tutorial7/GNN_overview.html"],"metadata":{"id":"RHuTM7sEIS3_"}},{"cell_type":"code","source":["!git lfs install"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XsjWzd2ZP_80","executionInfo":{"status":"ok","timestamp":1719165550538,"user_tz":-360,"elapsed":11,"user":{"displayName":"Rafsan Jany","userId":"08721334090885411304"}},"outputId":"f9702694-5dd3-44dc-ed20-ad53376ce398"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Git LFS initialized.\n"]}]},{"cell_type":"code","source":["!git clone https://huggingface.co/datasets/Skylion007/openwebtext"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uVElBciVQQyd","executionInfo":{"status":"ok","timestamp":1719165708408,"user_tz":-360,"elapsed":74921,"user":{"displayName":"Rafsan Jany","userId":"08721334090885411304"}},"outputId":"6055c193-2007-48a0-a31d-c3f439a6f6fc"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'openwebtext'...\n","remote: Enumerating objects: 90, done.\u001b[K\n","remote: Counting objects: 100% (26/26), done.\u001b[K\n","remote: Compressing objects: 100% (11/11), done.\u001b[K\n","remote: Total 90 (delta 19), reused 15 (delta 15), pack-reused 64 (from 1)\u001b[K\n","Unpacking objects: 100% (90/90), 21.15 KiB | 802.00 KiB/s, done.\n","warning: Clone succeeded, but checkout failed.\n","You can inspect what was checked out with 'git status'\n","and retry with 'git restore --source=HEAD :/'\n","\n","\n","Exiting because of \"interrupt\" signal.\n","^C\n"]}]},{"cell_type":"code","source":["!git clone https://huggingface.co/datasets/Skylion007/openwebtext /content/Open\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5WnHuxdRQzHZ","executionInfo":{"status":"ok","timestamp":1719165834526,"user_tz":-360,"elapsed":68575,"user":{"displayName":"Rafsan Jany","userId":"08721334090885411304"}},"outputId":"7009a8f6-52f0-4dc3-993b-683f25b4091e"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into '/content/Open'...\n","remote: Enumerating objects: 90, done.\u001b[K\n","remote: Counting objects: 100% (26/26), done.\u001b[K\n","remote: Compressing objects: 100% (15/15), done.\u001b[K\n","remote: Total 90 (delta 19), reused 11 (delta 11), pack-reused 64 (from 1)\u001b[K\n","Unpacking objects: 100% (90/90), 21.38 KiB | 912.00 KiB/s, done.\n","warning: Clone succeeded, but checkout failed.\n","You can inspect what was checked out with 'git status'\n","and retry with 'git restore --source=HEAD :/'\n","\n","\n","Exiting because of \"interrupt\" signal.\n","^C\n"]}]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FxYcSC3HGBgr","executionInfo":{"status":"ok","timestamp":1718743602566,"user_tz":-360,"elapsed":76573,"user":{"displayName":"Rafsan Jany","userId":"08721334090885411304"}},"outputId":"80ba9048-867f-4cab-c5d5-68725d99d824"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-1-ebf0b716a7e6>:12: DeprecationWarning: `set_matplotlib_formats` is deprecated since IPython 7.23, directly use `matplotlib_inline.backend_inline.set_matplotlib_formats()`\n","  set_matplotlib_formats('svg', 'pdf') # For export\n","INFO:lightning_fabric.utilities.seed:Seed set to 42\n"]},{"output_type":"stream","name":"stdout","text":["cuda:0\n"]}],"source":["## Standard libraries\n","import os\n","import json\n","import math\n","import numpy as np\n","import time\n","\n","## Imports for plotting\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","from IPython.display import set_matplotlib_formats\n","set_matplotlib_formats('svg', 'pdf') # For export\n","from matplotlib.colors import to_rgb\n","import matplotlib\n","matplotlib.rcParams['lines.linewidth'] = 2.0\n","import seaborn as sns\n","sns.reset_orig()\n","sns.set()\n","\n","## Progress bar\n","from tqdm.notebook import tqdm\n","\n","## PyTorch\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.utils.data as data\n","import torch.optim as optim\n","# Torchvision\n","import torchvision\n","from torchvision.datasets import CIFAR10\n","from torchvision import transforms\n","# PyTorch Lightning\n","try:\n","    import pytorch_lightning as pl\n","except ModuleNotFoundError: # Google Colab does not have PyTorch Lightning installed by default. Hence, we do it here if necessary\n","    !pip install --quiet pytorch-lightning>=1.4\n","    import pytorch_lightning as pl\n","from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\n","\n","# Path to the folder where the datasets are/should be downloaded (e.g. CIFAR10)\n","DATASET_PATH = \"../data\"\n","# Path to the folder where the pretrained models are saved\n","CHECKPOINT_PATH = \"../saved_models/tutorial7\"\n","\n","# Setting the seed\n","pl.seed_everything(42)\n","\n","# Ensure that all operations are deterministic on GPU (if used) for reproducibility\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","\n","device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n","print(device)"]},{"cell_type":"code","source":["import urllib.request\n","from urllib.error import HTTPError\n","# Github URL where saved models are stored for this tutorial\n","base_url = \"https://raw.githubusercontent.com/phlippe/saved_models/main/tutorial7/\"\n","# Files to download\n","pretrained_files = [\"NodeLevelMLP.ckpt\", \"NodeLevelGNN.ckpt\", \"GraphLevelGraphConv.ckpt\"]\n","\n","# Create checkpoint path if it doesn't exist yet\n","os.makedirs(CHECKPOINT_PATH, exist_ok=True)\n","\n","# For each file, check whether it already exists. If not, try downloading it.\n","for file_name in pretrained_files:\n","    file_path = os.path.join(CHECKPOINT_PATH, file_name)\n","    if \"/\" in file_name:\n","        os.makedirs(file_path.rsplit(\"/\",1)[0], exist_ok=True)\n","    if not os.path.isfile(file_path):\n","        file_url = base_url + file_name\n","        print(f\"Downloading {file_url}...\")\n","        try:\n","            urllib.request.urlretrieve(file_url, file_path)\n","        except HTTPError as e:\n","            print(\"Something went wrong. Please try to download the file from the GDrive folder, or contact the author with the full output including the following error:\\n\", e)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ypTArEbgGKKn","executionInfo":{"status":"ok","timestamp":1718743634453,"user_tz":-360,"elapsed":1480,"user":{"displayName":"Rafsan Jany","userId":"08721334090885411304"}},"outputId":"f0a08e72-6fbb-459a-e859-976b6149a3e6"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading https://raw.githubusercontent.com/phlippe/saved_models/main/tutorial7/NodeLevelMLP.ckpt...\n","Downloading https://raw.githubusercontent.com/phlippe/saved_models/main/tutorial7/NodeLevelGNN.ckpt...\n","Downloading https://raw.githubusercontent.com/phlippe/saved_models/main/tutorial7/GraphLevelGraphConv.ckpt...\n"]}]},{"cell_type":"code","source":["class GCNLayer(nn.Module):\n","\n","    def __init__(self, c_in, c_out):\n","        super().__init__()\n","        self.projection = nn.Linear(c_in, c_out)\n","\n","    def forward(self, node_feats, adj_matrix):\n","        \"\"\"\n","        Inputs:\n","            node_feats - Tensor with node features of shape [batch_size, num_nodes, c_in]\n","            adj_matrix - Batch of adjacency matrices of the graph. If there is an edge from i to j, adj_matrix[b,i,j]=1 else 0.\n","                         Supports directed edges by non-symmetric matrices. Assumes to already have added the identity connections.\n","                         Shape: [batch_size, num_nodes, num_nodes]\n","        \"\"\"\n","        # Num neighbours = number of incoming edges\n","        num_neighbours = adj_matrix.sum(dim=-1, keepdims=True)\n","        node_feats = self.projection(node_feats)\n","        node_feats = torch.bmm(adj_matrix, node_feats)\n","        node_feats = node_feats / num_neighbours\n","        return node_feats"],"metadata":{"id":"8lbFeT7EGLC_","executionInfo":{"status":"ok","timestamp":1718743650275,"user_tz":-360,"elapsed":1000,"user":{"displayName":"Rafsan Jany","userId":"08721334090885411304"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["node_feats = torch.arange(8, dtype=torch.float32).view(1, 4, 2)\n","adj_matrix = torch.Tensor([[[1, 1, 0, 0],\n","                            [1, 1, 1, 1],\n","                            [0, 1, 1, 1],\n","                            [0, 1, 1, 1]]])\n","\n","print(\"Node features:\\n\", node_feats)\n","print(\"\\nAdjacency matrix:\\n\", adj_matrix)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w6zrKhnFGK-_","executionInfo":{"status":"ok","timestamp":1718743677429,"user_tz":-360,"elapsed":731,"user":{"displayName":"Rafsan Jany","userId":"08721334090885411304"}},"outputId":"1ebc4ff5-bbb9-4622-a7ec-7d2e5c284d1f"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Node features:\n"," tensor([[[0., 1.],\n","         [2., 3.],\n","         [4., 5.],\n","         [6., 7.]]])\n","\n","Adjacency matrix:\n"," tensor([[[1., 1., 0., 0.],\n","         [1., 1., 1., 1.],\n","         [0., 1., 1., 1.],\n","         [0., 1., 1., 1.]]])\n"]}]},{"cell_type":"code","source":["layer = GCNLayer(c_in=2, c_out=2)\n","layer.projection.weight.data = torch.Tensor([[1., 0.], [0., 1.]])\n","layer.projection.bias.data = torch.Tensor([0., 0.])\n","\n","with torch.no_grad():\n","    out_feats = layer(node_feats, adj_matrix)\n","\n","print(\"Adjacency matrix\", adj_matrix)\n","print(\"Input features\", node_feats)\n","print(\"Output features\", out_feats)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y_R15S2AGwix","executionInfo":{"status":"ok","timestamp":1718743682015,"user_tz":-360,"elapsed":5,"user":{"displayName":"Rafsan Jany","userId":"08721334090885411304"}},"outputId":"fce9568f-393e-4ac9-f8f6-db35e8ac5e7d"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Adjacency matrix tensor([[[1., 1., 0., 0.],\n","         [1., 1., 1., 1.],\n","         [0., 1., 1., 1.],\n","         [0., 1., 1., 1.]]])\n","Input features tensor([[[0., 1.],\n","         [2., 3.],\n","         [4., 5.],\n","         [6., 7.]]])\n","Output features tensor([[[1., 2.],\n","         [3., 4.],\n","         [4., 5.],\n","         [4., 5.]]])\n"]}]},{"cell_type":"code","source":["class GATLayer(nn.Module):\n","\n","    def __init__(self, c_in, c_out, num_heads=1, concat_heads=True, alpha=0.2):\n","        \"\"\"\n","        Inputs:\n","            c_in - Dimensionality of input features\n","            c_out - Dimensionality of output features\n","            num_heads - Number of heads, i.e. attention mechanisms to apply in parallel. The\n","                        output features are equally split up over the heads if concat_heads=True.\n","            concat_heads - If True, the output of the different heads is concatenated instead of averaged.\n","            alpha - Negative slope of the LeakyReLU activation.\n","        \"\"\"\n","        super().__init__()\n","        self.num_heads = num_heads\n","        self.concat_heads = concat_heads\n","        if self.concat_heads:\n","            assert c_out % num_heads == 0, \"Number of output features must be a multiple of the count of heads.\"\n","            c_out = c_out // num_heads\n","\n","        # Sub-modules and parameters needed in the layer\n","        self.projection = nn.Linear(c_in, c_out * num_heads)\n","        self.a = nn.Parameter(torch.Tensor(num_heads, 2 * c_out)) # One per head\n","        self.leakyrelu = nn.LeakyReLU(alpha)\n","\n","        # Initialization from the original implementation\n","        nn.init.xavier_uniform_(self.projection.weight.data, gain=1.414)\n","        nn.init.xavier_uniform_(self.a.data, gain=1.414)\n","\n","    def forward(self, node_feats, adj_matrix, print_attn_probs=False):\n","        \"\"\"\n","        Inputs:\n","            node_feats - Input features of the node. Shape: [batch_size, c_in]\n","            adj_matrix - Adjacency matrix including self-connections. Shape: [batch_size, num_nodes, num_nodes]\n","            print_attn_probs - If True, the attention weights are printed during the forward pass (for debugging purposes)\n","        \"\"\"\n","        batch_size, num_nodes = node_feats.size(0), node_feats.size(1)\n","\n","        # Apply linear layer and sort nodes by head\n","        node_feats = self.projection(node_feats)\n","        node_feats = node_feats.view(batch_size, num_nodes, self.num_heads, -1)\n","\n","        # We need to calculate the attention logits for every edge in the adjacency matrix\n","        # Doing this on all possible combinations of nodes is very expensive\n","        # => Create a tensor of [W*h_i||W*h_j] with i and j being the indices of all edges\n","        edges = adj_matrix.nonzero(as_tuple=False) # Returns indices where the adjacency matrix is not 0 => edges\n","        node_feats_flat = node_feats.view(batch_size * num_nodes, self.num_heads, -1)\n","        edge_indices_row = edges[:,0] * num_nodes + edges[:,1]\n","        edge_indices_col = edges[:,0] * num_nodes + edges[:,2]\n","        a_input = torch.cat([\n","            torch.index_select(input=node_feats_flat, index=edge_indices_row, dim=0),\n","            torch.index_select(input=node_feats_flat, index=edge_indices_col, dim=0)\n","        ], dim=-1) # Index select returns a tensor with node_feats_flat being indexed at the desired positions along dim=0\n","\n","        # Calculate attention MLP output (independent for each head)\n","        attn_logits = torch.einsum('bhc,hc->bh', a_input, self.a)\n","        attn_logits = self.leakyrelu(attn_logits)\n","\n","        # Map list of attention values back into a matrix\n","        attn_matrix = attn_logits.new_zeros(adj_matrix.shape+(self.num_heads,)).fill_(-9e15)\n","        attn_matrix[adj_matrix[...,None].repeat(1,1,1,self.num_heads) == 1] = attn_logits.reshape(-1)\n","\n","        # Weighted average of attention\n","        attn_probs = F.softmax(attn_matrix, dim=2)\n","        if print_attn_probs:\n","            print(\"Attention probs\\n\", attn_probs.permute(0, 3, 1, 2))\n","        node_feats = torch.einsum('bijh,bjhc->bihc', attn_probs, node_feats)\n","\n","        # If heads should be concatenated, we can do this by reshaping. Otherwise, take mean\n","        if self.concat_heads:\n","            node_feats = node_feats.reshape(batch_size, num_nodes, -1)\n","        else:\n","            node_feats = node_feats.mean(dim=2)\n","\n","        return node_feats"],"metadata":{"id":"wj7adrIXGweg","executionInfo":{"status":"ok","timestamp":1718743707947,"user_tz":-360,"elapsed":613,"user":{"displayName":"Rafsan Jany","userId":"08721334090885411304"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["layer = GATLayer(2, 2, num_heads=2)\n","layer.projection.weight.data = torch.Tensor([[1., 0.], [0., 1.]])\n","layer.projection.bias.data = torch.Tensor([0., 0.])\n","layer.a.data = torch.Tensor([[-0.2, 0.3], [0.1, -0.1]])\n","\n","with torch.no_grad():\n","    out_feats = layer(node_feats, adj_matrix, print_attn_probs=True)\n","\n","print(\"Adjacency matrix\", adj_matrix)\n","print(\"Input features\", node_feats)\n","print(\"Output features\", out_feats)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_vy0sGe2Gwcl","executionInfo":{"status":"ok","timestamp":1718743725720,"user_tz":-360,"elapsed":689,"user":{"displayName":"Rafsan Jany","userId":"08721334090885411304"}},"outputId":"c5a42a43-2aa5-4938-c465-a67deaff9eef"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Attention probs\n"," tensor([[[[0.3543, 0.6457, 0.0000, 0.0000],\n","          [0.1096, 0.1450, 0.2642, 0.4813],\n","          [0.0000, 0.1858, 0.2885, 0.5257],\n","          [0.0000, 0.2391, 0.2696, 0.4913]],\n","\n","         [[0.5100, 0.4900, 0.0000, 0.0000],\n","          [0.2975, 0.2436, 0.2340, 0.2249],\n","          [0.0000, 0.3838, 0.3142, 0.3019],\n","          [0.0000, 0.4018, 0.3289, 0.2693]]]])\n","Adjacency matrix tensor([[[1., 1., 0., 0.],\n","         [1., 1., 1., 1.],\n","         [0., 1., 1., 1.],\n","         [0., 1., 1., 1.]]])\n","Input features tensor([[[0., 1.],\n","         [2., 3.],\n","         [4., 5.],\n","         [6., 7.]]])\n","Output features tensor([[[1.2913, 1.9800],\n","         [4.2344, 3.7725],\n","         [4.6798, 4.8362],\n","         [4.5043, 4.7351]]])\n"]}]},{"cell_type":"code","source":["# torch geometric\n","try:\n","    import torch_geometric\n","except ModuleNotFoundError:\n","    # Installing torch geometric packages with specific CUDA+PyTorch version.\n","    # See https://pytorch-geometric.readthedocs.io/en/latest/notes/installation.html for details\n","    TORCH = torch.__version__.split('+')[0]\n","    CUDA = 'cu' + torch.version.cuda.replace('.','')\n","\n","    !pip install torch-scatter     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n","    !pip install torch-sparse      -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n","    !pip install torch-cluster     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n","    !pip install torch-spline-conv -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n","    !pip install torch-geometric\n","    import torch_geometric\n","import torch_geometric.nn as geom_nn\n","import torch_geometric.data as geom_data"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2utqt6C6G-kK","executionInfo":{"status":"ok","timestamp":1718743777217,"user_tz":-360,"elapsed":34339,"user":{"displayName":"Rafsan Jany","userId":"08721334090885411304"}},"outputId":"4fdad2f2-31b6-4a41-9214-a337a4f8a1a2"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in links: https://pytorch-geometric.com/whl/torch-2.3.0+cu121.html\n","Collecting torch-scatter\n","  Downloading https://data.pyg.org/whl/torch-2.3.0%2Bcu121/torch_scatter-2.1.2%2Bpt23cu121-cp310-cp310-linux_x86_64.whl (10.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m86.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: torch-scatter\n","Successfully installed torch-scatter-2.1.2+pt23cu121\n","Looking in links: https://pytorch-geometric.com/whl/torch-2.3.0+cu121.html\n","Collecting torch-sparse\n","  Downloading https://data.pyg.org/whl/torch-2.3.0%2Bcu121/torch_sparse-0.6.18%2Bpt23cu121-cp310-cp310-linux_x86_64.whl (5.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m81.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-sparse) (1.11.4)\n","Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy->torch-sparse) (1.25.2)\n","Installing collected packages: torch-sparse\n","Successfully installed torch-sparse-0.6.18+pt23cu121\n","Looking in links: https://pytorch-geometric.com/whl/torch-2.3.0+cu121.html\n","Collecting torch-cluster\n","  Downloading https://data.pyg.org/whl/torch-2.3.0%2Bcu121/torch_cluster-1.6.3%2Bpt23cu121-cp310-cp310-linux_x86_64.whl (3.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-cluster) (1.11.4)\n","Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy->torch-cluster) (1.25.2)\n","Installing collected packages: torch-cluster\n","Successfully installed torch-cluster-1.6.3+pt23cu121\n","Looking in links: https://pytorch-geometric.com/whl/torch-2.3.0+cu121.html\n","Collecting torch-spline-conv\n","  Downloading https://data.pyg.org/whl/torch-2.3.0%2Bcu121/torch_spline_conv-1.2.2%2Bpt23cu121-cp310-cp310-linux_x86_64.whl (947 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m947.1/947.1 kB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: torch-spline-conv\n","Successfully installed torch-spline-conv-1.2.2+pt23cu121\n","Collecting torch-geometric\n","  Downloading torch_geometric-2.5.3-py3-none-any.whl (1.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.4)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.25.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.11.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2023.6.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.4)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.9.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.31.0)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.2)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.2.2)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (4.0.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2024.6.2)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.5.0)\n","Installing collected packages: torch-geometric\n","Successfully installed torch-geometric-2.5.3\n"]}]},{"cell_type":"code","source":["gnn_layer_by_name = {\n","    \"GCN\": geom_nn.GCNConv,\n","    \"GAT\": geom_nn.GATConv,\n","    \"GraphConv\": geom_nn.GraphConv\n","}"],"metadata":{"id":"r1lKfteFG-dV","executionInfo":{"status":"ok","timestamp":1718743824754,"user_tz":-360,"elapsed":3,"user":{"displayName":"Rafsan Jany","userId":"08721334090885411304"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["cora_dataset = torch_geometric.datasets.Planetoid(root=DATASET_PATH, name=\"Cora\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4eQFQiG3G-aT","executionInfo":{"status":"ok","timestamp":1718743834380,"user_tz":-360,"elapsed":8903,"user":{"displayName":"Rafsan Jany","userId":"08721334090885411304"}},"outputId":"f0902901-0863-45c0-b0e4-e4bbc51edc1e"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n","Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n","Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n","Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n","Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n","Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n","Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n","Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n","Processing...\n","Done!\n"]}]},{"cell_type":"code","source":["cora_dataset[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eE-ucMVjG-VS","executionInfo":{"status":"ok","timestamp":1718743834381,"user_tz":-360,"elapsed":49,"user":{"displayName":"Rafsan Jany","userId":"08721334090885411304"}},"outputId":"f8d36223-abde-4215-8e04-d688c1d42637"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["class GNNModel(nn.Module):\n","\n","    def __init__(self, c_in, c_hidden, c_out, num_layers=2, layer_name=\"GCN\", dp_rate=0.1, **kwargs):\n","        \"\"\"\n","        Inputs:\n","            c_in - Dimension of input features\n","            c_hidden - Dimension of hidden features\n","            c_out - Dimension of the output features. Usually number of classes in classification\n","            num_layers - Number of \"hidden\" graph layers\n","            layer_name - String of the graph layer to use\n","            dp_rate - Dropout rate to apply throughout the network\n","            kwargs - Additional arguments for the graph layer (e.g. number of heads for GAT)\n","        \"\"\"\n","        super().__init__()\n","        gnn_layer = gnn_layer_by_name[layer_name]\n","\n","        layers = []\n","        in_channels, out_channels = c_in, c_hidden\n","        for l_idx in range(num_layers-1):\n","            layers += [\n","                gnn_layer(in_channels=in_channels,\n","                          out_channels=out_channels,\n","                          **kwargs),\n","                nn.ReLU(inplace=True),\n","                nn.Dropout(dp_rate)\n","            ]\n","            in_channels = c_hidden\n","        layers += [gnn_layer(in_channels=in_channels,\n","                             out_channels=c_out,\n","                             **kwargs)]\n","        self.layers = nn.ModuleList(layers)\n","\n","    def forward(self, x, edge_index):\n","        \"\"\"\n","        Inputs:\n","            x - Input features per node\n","            edge_index - List of vertex index pairs representing the edges in the graph (PyTorch geometric notation)\n","        \"\"\"\n","        for l in self.layers:\n","            # For graph layers, we need to add the \"edge_index\" tensor as additional input\n","            # All PyTorch Geometric graph layer inherit the class \"MessagePassing\", hence\n","            # we can simply check the class type.\n","            if isinstance(l, geom_nn.MessagePassing):\n","                x = l(x, edge_index)\n","            else:\n","                x = l(x)\n","        return x"],"metadata":{"id":"nGGa210EG-Rd","executionInfo":{"status":"ok","timestamp":1718743902556,"user_tz":-360,"elapsed":842,"user":{"displayName":"Rafsan Jany","userId":"08721334090885411304"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["class MLPModel(nn.Module):\n","\n","    def __init__(self, c_in, c_hidden, c_out, num_layers=2, dp_rate=0.1):\n","        \"\"\"\n","        Inputs:\n","            c_in - Dimension of input features\n","            c_hidden - Dimension of hidden features\n","            c_out - Dimension of the output features. Usually number of classes in classification\n","            num_layers - Number of hidden layers\n","            dp_rate - Dropout rate to apply throughout the network\n","        \"\"\"\n","        super().__init__()\n","        layers = []\n","        in_channels, out_channels = c_in, c_hidden\n","        for l_idx in range(num_layers-1):\n","            layers += [\n","                nn.Linear(in_channels, out_channels),\n","                nn.ReLU(inplace=True),\n","                nn.Dropout(dp_rate)\n","            ]\n","            in_channels = c_hidden\n","        layers += [nn.Linear(in_channels, c_out)]\n","        self.layers = nn.Sequential(*layers)\n","\n","    def forward(self, x, *args, **kwargs):\n","        \"\"\"\n","        Inputs:\n","            x - Input features per node\n","        \"\"\"\n","        return self.layers(x)\n"],"metadata":{"id":"WLUMJZ7eGwZc","executionInfo":{"status":"ok","timestamp":1718743922829,"user_tz":-360,"elapsed":607,"user":{"displayName":"Rafsan Jany","userId":"08721334090885411304"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["class NodeLevelGNN(pl.LightningModule):\n","\n","    def __init__(self, model_name, **model_kwargs):\n","        super().__init__()\n","        # Saving hyperparameters\n","        self.save_hyperparameters()\n","\n","        if model_name == \"MLP\":\n","            self.model = MLPModel(**model_kwargs)\n","        else:\n","            self.model = GNNModel(**model_kwargs)\n","        self.loss_module = nn.CrossEntropyLoss()\n","\n","    def forward(self, data, mode=\"train\"):\n","        x, edge_index = data.x, data.edge_index\n","        x = self.model(x, edge_index)\n","\n","        # Only calculate the loss on the nodes corresponding to the mask\n","        if mode == \"train\":\n","            mask = data.train_mask\n","        elif mode == \"val\":\n","            mask = data.val_mask\n","        elif mode == \"test\":\n","            mask = data.test_mask\n","        else:\n","            assert False, f\"Unknown forward mode: {mode}\"\n","\n","        loss = self.loss_module(x[mask], data.y[mask])\n","        acc = (x[mask].argmax(dim=-1) == data.y[mask]).sum().float() / mask.sum()\n","        return loss, acc\n","\n","    def configure_optimizers(self):\n","        # We use SGD here, but Adam works as well\n","        optimizer = optim.SGD(self.parameters(), lr=0.1, momentum=0.9, weight_decay=2e-3)\n","        return optimizer\n","\n","    def training_step(self, batch, batch_idx):\n","        loss, acc = self.forward(batch, mode=\"train\")\n","        self.log('train_loss', loss)\n","        self.log('train_acc', acc)\n","        return loss\n","\n","    def validation_step(self, batch, batch_idx):\n","        _, acc = self.forward(batch, mode=\"val\")\n","        self.log('val_acc', acc)\n","\n","    def test_step(self, batch, batch_idx):\n","        _, acc = self.forward(batch, mode=\"test\")\n","        self.log('test_acc', acc)"],"metadata":{"id":"zizrh1mZGK5J","executionInfo":{"status":"ok","timestamp":1718743939639,"user_tz":-360,"elapsed":788,"user":{"displayName":"Rafsan Jany","userId":"08721334090885411304"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["def train_node_classifier(model_name, dataset, **model_kwargs):\n","    pl.seed_everything(42)\n","    node_data_loader = geom_data.DataLoader(dataset, batch_size=1)\n","\n","    # Create a PyTorch Lightning trainer with the generation callback\n","    root_dir = os.path.join(CHECKPOINT_PATH, \"NodeLevel\" + model_name)\n","    os.makedirs(root_dir, exist_ok=True)\n","    trainer = pl.Trainer(default_root_dir=root_dir,\n","                         callbacks=[ModelCheckpoint(save_weights_only=True, mode=\"max\", monitor=\"val_acc\")],\n","                         accelerator=\"gpu\" if str(device).startswith(\"cuda\") else \"cpu\",\n","                         devices=1,\n","                         max_epochs=200,\n","                         enable_progress_bar=False) # False because epoch size is 1\n","    trainer.logger._default_hp_metric = None # Optional logging argument that we don't need\n","\n","    # Check whether pretrained model exists. If yes, load it and skip training\n","    pretrained_filename = os.path.join(CHECKPOINT_PATH, f\"NodeLevel{model_name}.ckpt\")\n","    if os.path.isfile(pretrained_filename):\n","        print(\"Found pretrained model, loading...\")\n","        model = NodeLevelGNN.load_from_checkpoint(pretrained_filename)\n","    else:\n","        pl.seed_everything()\n","        model = NodeLevelGNN(model_name=model_name, c_in=dataset.num_node_features, c_out=dataset.num_classes, **model_kwargs)\n","        trainer.fit(model, node_data_loader, node_data_loader)\n","        model = NodeLevelGNN.load_from_checkpoint(trainer.checkpoint_callback.best_model_path)\n","\n","    # Test best model on the test set\n","    test_result = trainer.test(model, node_data_loader, verbose=False)\n","    batch = next(iter(node_data_loader))\n","    batch = batch.to(model.device)\n","    _, train_acc = model.forward(batch, mode=\"train\")\n","    _, val_acc = model.forward(batch, mode=\"val\")\n","    result = {\"train\": train_acc,\n","              \"val\": val_acc,\n","              \"test\": test_result[0]['test_acc']}\n","    return model, result"],"metadata":{"id":"qwnvnYS9HuKn","executionInfo":{"status":"ok","timestamp":1718743990260,"user_tz":-360,"elapsed":648,"user":{"displayName":"Rafsan Jany","userId":"08721334090885411304"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["# Small function for printing the test scores\n","def print_results(result_dict):\n","    if \"train\" in result_dict:\n","        print(f\"Train accuracy: {(100.0*result_dict['train']):4.2f}%\")\n","    if \"val\" in result_dict:\n","        print(f\"Val accuracy:   {(100.0*result_dict['val']):4.2f}%\")\n","    print(f\"Test accuracy:  {(100.0*result_dict['test']):4.2f}%\")"],"metadata":{"id":"6ywHeA_CHuFg","executionInfo":{"status":"ok","timestamp":1718744002056,"user_tz":-360,"elapsed":643,"user":{"displayName":"Rafsan Jany","userId":"08721334090885411304"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["node_mlp_model, node_mlp_result = train_node_classifier(model_name=\"MLP\",\n","                                                        dataset=cora_dataset,\n","                                                        c_hidden=16,\n","                                                        num_layers=2,\n","                                                        dp_rate=0.1)\n","\n","print_results(node_mlp_result)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FJAVXqB8HuB1","executionInfo":{"status":"ok","timestamp":1718744017905,"user_tz":-360,"elapsed":5767,"user":{"displayName":"Rafsan Jany","userId":"08721334090885411304"}},"outputId":"8de27367-364e-41ae-eff3-86dd44e85247"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:lightning_fabric.utilities.seed:Seed set to 42\n","/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n","  warnings.warn(out)\n","INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n","INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n","INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"]},{"output_type":"stream","name":"stdout","text":["Found pretrained model, loading...\n"]},{"output_type":"stream","name":"stderr","text":["INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.0.2 to v2.3.0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../saved_models/tutorial7/NodeLevelMLP.ckpt`\n","WARNING:pytorch_lightning.loggers.tensorboard:Missing logger folder: ../saved_models/tutorial7/NodeLevelMLP/lightning_logs\n","INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"]},{"output_type":"stream","name":"stdout","text":["Train accuracy: 97.14%\n","Val accuracy:   54.60%\n","Test accuracy:  60.60%\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/data.py:78: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 2708. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"]}]},{"cell_type":"code","source":["node_gnn_model, node_gnn_result = train_node_classifier(model_name=\"GNN\",\n","                                                        layer_name=\"GCN\",\n","                                                        dataset=cora_dataset,\n","                                                        c_hidden=16,\n","                                                        num_layers=2,\n","                                                        dp_rate=0.1)\n","print_results(node_gnn_result)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9JgOxIdbHt8m","executionInfo":{"status":"ok","timestamp":1718744028456,"user_tz":-360,"elapsed":1932,"user":{"displayName":"Rafsan Jany","userId":"08721334090885411304"}},"outputId":"5a05d868-4f75-4d0a-956d-7a1875bb8582"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:lightning_fabric.utilities.seed:Seed set to 42\n","INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n","INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n","INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n","INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.0.2 to v2.3.0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../saved_models/tutorial7/NodeLevelGNN.ckpt`\n"]},{"output_type":"stream","name":"stdout","text":["Found pretrained model, loading...\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:pytorch_lightning.loggers.tensorboard:Missing logger folder: ../saved_models/tutorial7/NodeLevelGNN/lightning_logs\n","INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"]},{"output_type":"stream","name":"stdout","text":["Train accuracy: 100.00%\n","Val accuracy:   78.60%\n","Test accuracy:  82.40%\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"5Jz4MCctHt2-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"7__KWi_lHtzn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"7D1BYh0ZHtyB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"cLxEdllKHts-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"iyEk0rjnHtpw"},"execution_count":null,"outputs":[]}]}