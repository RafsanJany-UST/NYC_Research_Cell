{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNLCftTR54dxUe9O/zzz3xq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":332},"id":"xlKKcB94kkMc","executionInfo":{"status":"error","timestamp":1732374766809,"user_tz":-360,"elapsed":366,"user":{"displayName":"Rafsan Jany","userId":"08721334090885411304"}},"outputId":"379f7192-9f21-4b67-cffa-371dcda52264"},"outputs":[{"output_type":"error","ename":"ValueError","evalue":"axes don't match array","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-54eb20eabd5d>\u001b[0m in \u001b[0;36m<cell line: 62>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;31m# Preprocess the EEG data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m \u001b[0mprocessed_eeg_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_eeg_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meeg_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;31m# Convert to PyTorch tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-3-54eb20eabd5d>\u001b[0m in \u001b[0;36mpreprocess_eeg_data\u001b[0;34m(eeg_data, sequence_length)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;31m# Reshape it into (samples, time_steps * channels) and normalize it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_time_points\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meeg_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mprocessed_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meeg_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_time_points\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;31m# Optional: Normalize the data (for example, using min-max normalization)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: axes don't match array"]}],"source":["import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader, TensorDataset\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error\n","import numpy as np\n","\n","# Define a custom transformer model for regression using a simple transformer architecture\n","class EEGTransformerForRegression(nn.Module):\n","    def __init__(self, input_dim, model_dim=64, num_labels=1, num_heads=8, num_layers=4):\n","        super(EEGTransformerForRegression, self).__init__()\n","\n","        # Transformer layers\n","        self.embedding = nn.Linear(input_dim, model_dim)\n","        self.positional_encoding = nn.Parameter(torch.randn(1, 512, model_dim))  # Max sequence length = 512\n","        self.transformer = nn.Transformer(d_model=model_dim, nhead=num_heads, num_encoder_layers=num_layers)\n","\n","        # Regression head\n","        self.fc = nn.Linear(model_dim, num_labels)\n","\n","    def forward(self, x):\n","        # x shape: (batch_size, seq_len, input_dim)\n","        seq_len = x.size(1)\n","\n","        # Embed input into the transformer model's dimension\n","        x = self.embedding(x)\n","\n","        # Add positional encoding (to give the transformer a sense of order)\n","        x = x + self.positional_encoding[:, :seq_len, :]\n","\n","        # Permute the input to (seq_len, batch_size, model_dim)\n","        x = x.permute(1, 0, 2)\n","\n","        # Pass through transformer\n","        x = self.transformer(x, x)\n","\n","        # Use the output corresponding to the [CLS] token (first token)\n","        x = x[0, :, :]\n","\n","        # Pass through the regression head\n","        x = self.fc(x)\n","\n","        return x\n","\n","# Function to preprocess EEG data\n","def preprocess_eeg_data(eeg_data, sequence_length=128):\n","    # Assume eeg_data is of shape (samples, channels, time_steps)\n","    # Reshape it into (samples, time_steps * channels) and normalize it\n","    num_samples, num_channels, num_time_points = eeg_data.shape\n","    processed_data = eeg_data.reshape(num_samples, num_channels, num_time_points).transpose(1, 2)\n","\n","    # Optional: Normalize the data (for example, using min-max normalization)\n","    processed_data = (processed_data - processed_data.min()) / (processed_data.max() - processed_data.min())\n","\n","    return processed_data\n","\n","# Load EEG data and labels (use your actual EEG data here)\n","eeg_data = np.random.randn(1000, 32, 128)  # 1000 samples, 32 channels, 128 time points\n","labels = np.random.randn(1000, 1)  # 1000 continuous regression labels\n","\n","# Preprocess the EEG data\n","processed_eeg_data = preprocess_eeg_data(eeg_data)\n","\n","# Convert to PyTorch tensors\n","inputs = torch.tensor(processed_eeg_data, dtype=torch.float32)\n","labels = torch.tensor(labels, dtype=torch.float32)\n","\n","# Split into train and validation sets\n","train_inputs, val_inputs, train_labels, val_labels = train_test_split(inputs, labels, test_size=0.2)\n","\n","# Create DataLoader for batching\n","train_dataset = TensorDataset(train_inputs, train_labels)\n","val_dataset = TensorDataset(val_inputs, val_labels)\n","\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n","\n","# Initialize the model\n","input_dim = train_inputs.shape[1]  # Time steps\n","model = EEGTransformerForRegression(input_dim=input_dim)\n","\n","# Set up optimizer and loss function\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n","criterion = nn.MSELoss()\n","\n","# Training loop\n","epochs = 5\n","for epoch in range(epochs):\n","    model.train()\n","    running_loss = 0.0\n","    for batch in train_loader:\n","        optimizer.zero_grad()\n","\n","        inputs, labels = batch\n","\n","        # Forward pass\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","\n","        # Backward pass\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item()\n","\n","    print(f\"Epoch {epoch+1}, Loss: {running_loss / len(train_loader):.4f}\")\n","\n","# Evaluation\n","model.eval()\n","with torch.no_grad():\n","    all_preds = []\n","    all_labels = []\n","    for batch in val_loader:\n","        inputs, labels = batch\n","        preds = model(inputs)\n","        all_preds.append(preds)\n","        all_labels.append(labels)\n","\n","    all_preds = torch.cat(all_preds, dim=0)\n","    all_labels = torch.cat(all_labels, dim=0)\n","\n","    # Calculate Mean Squared Error\n","    mse = mean_squared_error(all_labels.numpy(), all_preds.numpy())\n","    print(f\"Validation MSE: {mse:.4f}\")\n"]},{"cell_type":"code","source":[],"metadata":{"id":"vk2sciNjkq1f"},"execution_count":null,"outputs":[]}]}