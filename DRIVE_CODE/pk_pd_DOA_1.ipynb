{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyP3hzRU3+hLykq1/SqrCzr8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["\n","!pip install vitaldb\n","!pip install tensorboardX"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lb6updKSH0Sw","executionInfo":{"status":"ok","timestamp":1705761005571,"user_tz":-360,"elapsed":11812,"user":{"displayName":"Rafsan Jany","userId":"08721334090885411304"}},"outputId":"44b5a13a-0f0d-4d63-c46d-2e082a939da1"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting vitaldb\n","  Downloading vitaldb-1.4.7-py3-none-any.whl (56 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/56.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from vitaldb) (1.23.5)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from vitaldb) (1.5.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from vitaldb) (2.31.0)\n","Collecting wfdb (from vitaldb)\n","  Downloading wfdb-4.1.2-py3-none-any.whl (159 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.0/160.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->vitaldb) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->vitaldb) (2023.3.post1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->vitaldb) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->vitaldb) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->vitaldb) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->vitaldb) (2023.11.17)\n","Requirement already satisfied: SoundFile>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from wfdb->vitaldb) (0.12.1)\n","Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from wfdb->vitaldb) (3.7.1)\n","Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wfdb->vitaldb) (1.11.4)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->wfdb->vitaldb) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->wfdb->vitaldb) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->wfdb->vitaldb) (4.47.2)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->wfdb->vitaldb) (1.4.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->wfdb->vitaldb) (23.2)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->wfdb->vitaldb) (9.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->wfdb->vitaldb) (3.1.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->vitaldb) (1.16.0)\n","Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from SoundFile>=0.10.0->wfdb->vitaldb) (1.16.0)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->SoundFile>=0.10.0->wfdb->vitaldb) (2.21)\n","Installing collected packages: wfdb, vitaldb\n","Successfully installed vitaldb-1.4.7 wfdb-4.1.2\n","Collecting tensorboardX\n","  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (1.23.5)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (23.2)\n","Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (3.20.3)\n","Installing collected packages: tensorboardX\n","Successfully installed tensorboardX-2.6.2.2\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"YLNjCtd-E_4Z","executionInfo":{"status":"ok","timestamp":1705761009206,"user_tz":-360,"elapsed":3657,"user":{"displayName":"Rafsan Jany","userId":"08721334090885411304"}}},"outputs":[],"source":[" import pandas as pd\n","df_cases = pd.read_csv(\"https://api.vitaldb.net/cases\")  # clinical information\n","df_trks = pd.read_csv(\"https://api.vitaldb.net/trks\")    # track list\n","df_labs = pd.read_csv('https://api.vitaldb.net/labs')    # laboratory results"]},{"cell_type":"markdown","source":["# loader"],"metadata":{"id":"PpQ-CafIKIZ6"}},{"cell_type":"markdown","source":["## Class Dataloader"],"metadata":{"id":"3-GQysF_KbGN"}},{"cell_type":"code","source":["import torch\n","import numpy as np\n","from pandas import read_csv\n","import os\n","from tqdm import tqdm\n","import torch.utils.data as dat\n","import matplotlib.pyplot as plt\n","\n","\n","class Dataloader:\n","    def __init__(self, database_wdir, nums, time_step, tw):\n","        self.database_wdir = database_wdir\n","        self.nums = nums\n","        self.time_step = time_step\n","        self.tw = tw\n","\n","    def label_stat(self, case_nums=1, traindata=\"train\"):\n","        \"\"\"\n","        :param case_nums:一次性加载的样本数\n","        :return: 带有bis,生理特征,用药量信息的字典列表,列表长度为 case_nums\n","        case_id:样本id列表\n","        case_information:样本的生理信息表\n","        case_in_information:样本在信息表中的位置，如 case3:->[0], case30:->[13]\n","        \"\"\"\n","        case_information = read_csv(f'/HDD_data/HYK/bis/database/new_{traindata}_clean.csv')\n","        case_id = self.file_name(data=traindata)\n","        for i in range(len(case_id)):\n","            case_id[i] = case_id[i].split('.')[0]  # 字符串转数字\n","\n","        case_id = list(map(int, case_id))\n","        case_id.sort()\n","\n","        data_label = []\n","\n","        for i in tqdm(range(case_nums)):\n","            df = read_csv(f'{self.database_wdir}/{traindata}/{case_id[i]}.csv')\n","            x_len = int(len(df.BIS) / self.time_step)\n","\n","            label = np.zeros(x_len)\n","            for j in range(0, x_len, 1):\n","                label[int(j)] = df.BIS.values[j * self.time_step]\n","\n","            data_label.extend(label)\n","\n","        data_label.sort()\n","        for i in range(len(data_label)):\n","            data_label[i] = int(data_label[i])\n","        j = 0\n","        label_num = list(np.zeros(100))\n","        for i in range(100):\n","            while data_label[j] == i:\n","                label_num[i] += 1\n","                j += 1\n","                if j == len(data_label)-10:\n","                    break\n","\n","        import matplotlib.pyplot as plt\n","\n","        plt.grid(True)\n","        plt.autoscale(axis='x', tight=True)\n","        plt.bar(list(range(100)), label_num)\n","        plt.xlabel(\"bis index\")\n","        plt.ylabel(\"label nums\")\n","        plt.show()\n","\n","        return data_label, label_num\n","\n","    def dataload(self, case_nums=1, traindata=\"train\"):\n","        \"\"\"\n","        :param case_nums:一次性加载的样本数\n","        :return: 带有bis,生理特征,用药量信息的字典列表,列表长度为 case_nums\n","        case_id:样本id列表\n","        case_information:样本的生理信息表\n","        case_in_information:样本在信息表中的位置，如 case3:->[0], case30:->[13]\n","        x1:ppf_vol\n","        x2:rftn_vol\n","        x3:pkpd_bis\n","        X4:bis_history\n","        X5:RFTN_CP\n","        x6-x9:body information(age, sex, height, weight)\n","        \"\"\"\n","        # case_information = read_csv(f'/HDD_data/HYK/bis/database/new_{traindata}_clean.csv')\n","        case_information = read_csv(f'/HDD_data/HYK/bis/database/ni_dataset/info.csv')\n","        case_id = self.file_name(data=traindata)\n","        # for i in range(len(case_id)):\n","        #     case_id[i] = case_id[i].split('.')[0]  # 字符串转数字\n","\n","        # case_id = list(map(int, case_id))\n","\n","\n","        case_id.sort()\n","        print(\"file_name:\", case_id)\n","        case_in_information = self.information_deal(case_id, traindata)\n","\n","        data_seq = [0] * case_nums\n","        data_label = [0] * case_nums\n","\n","        for i in tqdm(range(case_nums)):\n","            df = read_csv(f'{self.database_wdir}/{traindata}/{case_id[i]}.csv')\n","            x_len = int(len(df.BIS) / self.time_step)\n","            # body信息读取\n","            age = case_information.age[case_in_information[i]]\n","            sex = case_information.sex[case_in_information[i]]\n","            height = case_information.height[case_in_information[i]]\n","            weight = case_information.weight[case_in_information[i]]\n","            body = torch.tensor([age, sex, height, weight]).float().reshape(1, 1, 4).repeat(x_len, self.tw, 1)\n","\n","            # 清除异常值\n","            modify_RFTN = df.RFTN20_VOL.values\n","            modify_PPF = df.PPF20_VOL.values\n","            diff_RFTN = np.diff(modify_RFTN)\n","            diff_PPF = np.diff(modify_PPF)\n","            for j in range(len(diff_RFTN)):\n","                if diff_RFTN[j] < 0:\n","                    temp = (modify_RFTN[j] + modify_RFTN[j + 2]) / 2\n","                    df.loc[j + 1, \"RFTN20_VOL\"] = temp\n","                if diff_PPF[j] < 0:\n","                    temp = (modify_PPF[j] + modify_PPF[j + 2]) / 2\n","                    df.loc[j + 1, \"PPF20_VOL\"] = temp\n","\n","            # 为0时刻补上-1800s的零数据\n","            PPF = list(np.zeros(self.tw * 10))\n","            PPF.extend(df.PPF20_VOL.values)\n","            RFTN = list(np.zeros(self.tw * 10))\n","            RFTN.extend(df.RFTN20_VOL.values)\n","\n","            ppf_cp = list(np.zeros(self.tw * 10))\n","            ppf_cp.extend(df.PPF_CP.values)\n","            rftn_cp = list(np.zeros(self.tw * 10))\n","            rftn_cp.extend(df.RFTN20_CP.values)\n","\n","            ppf_ce = df.PPF_CE.values\n","            rftn_ce = df.RFTN20_CE.values\n","\n","            pkpd_bis = self.pkpd(ppf_ce, rftn_ce)\n","            PKPD_bis = list(np.ones(self.tw * 10)*98)\n","            PKPD_bis.extend(pkpd_bis)\n","\n","            history_bis = df.BIS.values\n","            bis = list(np.zeros(self.tw * 10))\n","            bis.extend(history_bis)\n","\n","            # 特征制作\n","            X1 = torch.zeros((x_len, self.tw))\n","            X2 = torch.zeros((x_len, self.tw))\n","            X3 = torch.zeros((x_len, self.tw))\n","            X4 = torch.zeros((x_len, self.tw))\n","            X5 = torch.zeros((x_len, self.tw))\n","\n","            for x in range(self.tw*10, len(PPF) - self.time_step, self.time_step):\n","                # 从补完数据1800s（实际0s）时刻开始取数据段\n","                PPF_10s, RFTN_10s, BIS_10s, history_10s, RFTN_CP_10s = [], [], [], [], []\n","                for k in range(self.tw-1, -1, -1):\n","                    # 第k个10s片段, 共180个\n","                    PPF_10s.append((PPF[x - k * 10] - PPF[x - (k + 1) * 10]) * 0.1)\n","                    RFTN_10s.append((RFTN[x - k * 10] - RFTN[x - (k + 1) * 10]) * 0.1)\n","                    BIS_10s.append((PKPD_bis[x - k * 10]))\n","                    history_10s.append((bis[x - k * 10]))\n","                    RFTN_CP_10s.append((rftn_cp[x - k * 10]))\n","\n","\n","                X1[int((x - self.tw * 10) / self.time_step)] = torch.tensor(PPF_10s)\n","                X2[int((x - self.tw * 10) / self.time_step)] = torch.tensor(RFTN_10s)\n","                X3[int((x - self.tw * 10) / self.time_step)] = torch.tensor(BIS_10s)\n","                X4[int((x - self.tw * 10) / self.time_step)] = torch.tensor(history_10s)\n","                X5[int((x - self.tw * 10) / self.time_step)] = torch.tensor(RFTN_CP_10s)\n","\n","            # bis = torch.tensor(df.BIS.values)\n","            # for k in range(x_len):\n","            #     if k * self.time_step < self.tw:\n","            #         X4[k, :] = torch.cat((torch.ones(self.tw - k * self.time_step) * 98, bis[:k * self.time_step]), dim=0)\n","            #         # X3[k, :] = torch.cat((torch.zeros(self.tw - k * self.time_step), pkpd_bis[:k * self.time_step]), dim=0)\n","            #         # X5[k, :] = torch.cat((torch.zeros(180 - k * self.time_step), rftn_ce[:k * self.time_step]), dim=0)\n","            #\n","            #     else:\n","            #         X4[k, :] = bis[k * self.time_step - self.tw:k * self.time_step]\n","            #         # X3[k, :] = pkpd_bis[k * self.time_step - self.tw:k * self.time_step]\n","            #         # X5[k, :] = rftn_ce[k * self.time_step - 180:k * self.time_step]\n","\n","            seq = torch.zeros((x_len, self.tw, 5)).float()\n","            seq[:, :, 0] = X1  # ppf vol\n","            seq[:, :, 1] = X2  # rftn vol\n","            # 归一化\n","            mean = torch.mean(seq, dim=1).reshape((seq.shape[0], 1, seq.shape[2])).repeat(1, self.tw, 1)\n","            std = torch.std(seq, dim=1).reshape((seq.shape[0], 1, seq.shape[2])).repeat(1, self.tw, 1) + 1e-3\n","            seq = self.normalizition(x=seq, mu=mean, sigma=std)\n","\n","            seq[:, :, 2] = X3  # pk-pd bis\n","            seq[:, :, 3] = X4  # ppf cp\n","            seq[:, :, 4] = X5  # rftn cp\n","\n","            out = torch.cat((seq, body), dim=2)\n","            # out = torch.cat((out, seq[:, :, 2].reshape(seq.shape[0], 180, 1)), dim=2)\n","\n","            data_seq[i] = out.float()\n","            label = np.zeros(x_len)\n","            for j in range(0, x_len, 1):\n","                label[int(j)] = df.BIS.values[j * self.time_step]\n","\n","            data_label[i] = torch.tensor(label).float()\n","\n","        print(f\"{traindata}data load finish!\", 'case_nums = ', case_nums)\n","        return data_seq, data_label\n","\n","    def train_data_loader(self, batch=1, batch_size=1, data=\"train\", shuffle=True):\n","        train_seq, train_label = self.dataload(case_nums=batch, traindata=data)\n","        A = train_seq[0]\n","        B = train_label[0]\n","        for i in range(1, batch):\n","            A = torch.cat((A, train_seq[i]), 0)\n","            B = torch.cat((B, train_label[i]), 0)\n","\n","        torch.save(A, f\"/HDD_data/HYK/bis/database/validdata.pt\")\n","        torch.save(B, f\"/HDD_data/HYK/bis/database/validlabel.pt\")\n","\n","        # np.save(A.data.numpy(), \"/HDD_data/HYK/bis/database/traindata.npy\")\n","        # np.save(B.data.numpy(), \"/HDD_data/HYK/bis/database/trainlabel.npy\")\n","\n","        # train_data = dat.TensorDataset(A, B)\n","        # train_loader = dat.DataLoader(dataset=train_data,\n","        #                               batch_size=batch_size,\n","        #                               drop_last=True,\n","        #                               num_workers=4,\n","        #                               pin_memory=True,\n","        #                               shuffle=shuffle)\n","        # return train_loader\n","        return 0\n","\n","    def test_data_loader(self, batch=1, batch_size=1, data=\"test\"):\n","        test_seq, test_label = self.dataload(case_nums=batch, traindata=data)\n","        test_data = list(np.zeros(batch))\n","        test_loader = list(np.zeros(batch))\n","        for i in range(batch):\n","            torch.save(test_seq[i], f\"/HDD_data/HYK/bis/database/test_box/testndata{i}.pt\")\n","            torch.save(test_label[i], f\"/HDD_data/HYK/bis/database/test_box/testlabel{i}.pt\")\n","            # test_data[i] = dat.TensorDataset(test_seq[i], test_label[i])\n","            # test_loader[i] = dat.DataLoader(dataset=test_data[i],\n","            #                                 batch_size=batch_size,\n","            #                                 drop_last=True,\n","            #                                 pin_memory=True,\n","            #                                 num_workers=8)\n","        return test_loader, test_label\n","\n","    def information_deal(self, people_list, data=\"train\"):\n","        \"\"\"\n","        :param people_list: 样本的id列表，如[3, 30, 67 ...]\n","        :return: 样本在information表中的位置\n","        \"\"\"\n","        case_information = list(read_csv(f'/HDD_data/HYK/bis/database/new_{data}_clean.csv').caseid)\n","        case_location = list(np.zeros(len(people_list)))\n","        for i in range(len(people_list)):\n","            case_location[i] = case_information.index(people_list[i])\n","        return case_location  # clear3，30，36......等csv信息在information文件中的位置\n","\n","    def time_devide(self, case_nums=1, traindata=\"test\"):\n","        \"\"\"\n","        :param traindata: 测试集或验证集\n","        :param case_nums:加载的样本数\n","        :return: istart:开始注射时间 istop: 停止注射时间\n","        \"\"\"\n","        case_id = self.file_name(traindata)\n","\n","        for i in range(len(case_id)):\n","            case_id[i] = case_id[i].split('.')[0]  # 字符串转数字\n","\n","        case_id = list(map(int, case_id))\n","        case_id.sort()\n","        print(\"file_name:\", case_id)\n","        infusion_start, infusion_stop = [0] * case_nums, [0] * case_nums\n","        for i in tqdm(range(case_nums)):\n","            df = read_csv(f'/HDD_data/HYK/bis/database/{traindata}/{case_id[i]}.csv')\n","\n","            x_len = int(len(df.BIS))\n","            ppf = df.PPF20_VOL.values\n","            start_flag = True\n","            stop_flag = True\n","            for j in range(x_len):\n","                if ppf[j] > 0 and start_flag:\n","                    infusion_start[i] = j\n","                    start_flag = False\n","                if ppf[-j - 1] != ppf[-j - 2] and stop_flag:\n","                    infusion_stop[i] = x_len - j + 1\n","                    stop_flag = False\n","                if not start_flag and not stop_flag:\n","                    break\n","\n","        print(f\"{traindata}data load finish!\", 'case_nums = ', case_nums)\n","        return infusion_start, infusion_stop\n","\n","    def file_name(self, data):\n","        for root, dirs, files in os.walk(f'{self.database_wdir}/{data}'):\n","            return files  # 当前路径下所有非目录子文件,列表\n","\n","    @staticmethod\n","    def pkpd(Ec1, Ec2):\n","        ppf_ec50 = 4.47\n","        rftn_ec50 = 19.3\n","        gamma = 1.43\n","        p_gamma = (Ec1/ppf_ec50 + Ec2/rftn_ec50)**gamma\n","        bis = 98. - 98. * p_gamma / (1 + p_gamma)\n","        return bis\n","\n","    @staticmethod\n","    def normalizition(x, mu, sigma):\n","        # mu 均值 sigms 标准差\n","        x = (x - mu) / sigma\n","        return x\n","\n","    def ceload(self, case_nums=1, traindata=\"test\"):\n","        \"\"\"\n","        :param case_nums:一次性加载的样本数\n","        :return: 带有bis,生理特征,用药量信息的字典列表,列表长度为 case_nums\n","        case_id:样本id列表\n","        case_information:样本的生理信息表\n","        case_in_information:样本在信息表中的位置，如 case3:->[0], case30:->[13]\n","        x1:ppf_vol\n","        x2:rftn_vol\n","        x3:pkpd_bis\n","        X4:RFTN_CP\n","        x5-x8:body information(age, sex, height, weight)\n","        \"\"\"\n","        case_id = self.file_name(data=traindata)\n","        for i in range(len(case_id)):\n","            case_id[i] = case_id[i].split('.')[0]  # 字符串转数字\n","        case_id = list(map(int, case_id))\n","        case_id.sort()\n","\n","        PKPD_bis = []\n","        for i in tqdm(range(case_nums)):\n","            df = read_csv(f'{self.database_wdir}/{traindata}/{case_id[i]}.csv')\n","            x_len = int(len(df.BIS) / self.time_step)\n","\n","            ppf_ce = df.PPF_CE.values\n","            rftn_ce = df.RFTN20_CE.values\n","\n","            pkpd_bis = self.pkpd(ppf_ce, rftn_ce)\n","            PKPD_bis.append(pkpd_bis)\n","\n","        return PKPD_bis\n","\n","    def data_save(self, case_nums=1, traindata=\"test\"):\n","        case_information = read_csv(f'/HDD_data/HYK/bis/database/before_bodyinformation.csv')\n","        case_id = self.file_name(data=traindata)\n","        for i in range(len(case_id)):\n","            case_id[i] = case_id[i].split('.')[0]  # 字符串转数字\n","        case_id = list(map(int, case_id))\n","        case_in_information = self.information_deal(case_id, traindata)\n","        case_id.sort()\n","        X = list(range(case_nums))\n","        for i in tqdm(range(case_nums)):\n","            df = read_csv(f'{self.database_wdir}/{traindata}/{case_id[i]}.csv')\n","            age = case_information.age[case_in_information[i]]\n","            sex = case_information.sex[case_in_information[i]]\n","            height = case_information.height[case_in_information[i]]\n","            weight = case_information.weight[case_in_information[i]]\n","\n","            X[i] = [\n","                np.median(df.BIS.values),\n","                df.PPF20_VOL.values[-1]*20/1000,\n","                df.RFTN20_VOL.values[-1]*20/1000,\n","                np.median(df.PPF_CE.values),\n","                np.median(df.RFTN20_CE.values),\n","                age, sex, height, weight]\n","        file = {}\n","        X = np.asarray(X)\n","        name = [\"bis\", \"ppf_dose\", \"rftn_dose\", \"ppf_ce\", \"rftn_ce\", \"age\", \"sex\", \"height\", \"weight\"]\n","        for j in range(len(name)):\n","            file[f\"{name[j]}\"] = X[:, j]\n","\n","        import pandas as pd\n","        df = pd.DataFrame(dict([(k, pd.Series(v)) for k, v in file.items()]))\n","\n","        df.to_csv(f'/HDD_data/HYK/bis/database/{traindata}.csv')\n","        return X\n","\n","    def pt_load(self, dataset, batch_size):\n","        import gc\n","        if dataset == \"train\":\n","            A = torch.load(\"/HDD_data/HYK/bis/database/traindata.pt\")\n","            B = torch.load(\"/HDD_data/HYK/bis/database/trainlabel.pt\")\n","            train_data = dat.TensorDataset(A, B)\n","            train_loader = dat.DataLoader(dataset=train_data,\n","                                          batch_size=batch_size,\n","                                          drop_last=True,\n","                                          num_workers=4,\n","                                          pin_memory=True,\n","                                          shuffle=True)\n","            print(\"Training set loading completed\")\n","            del A, B\n","            gc.collect()\n","            return train_loader\n","        elif dataset == \"test\":\n","            test_loader = list(np.zeros(76))\n","            B = list(np.zeros(76))\n","            for i in tqdm(range(76)):\n","                A = torch.load(f\"/HDD_data/HYK/bis/database/test_box/testndata{i}.pt\")\n","                B[i] = torch.load(f\"/HDD_data/HYK/bis/database/test_box/testlabel{i}.pt\")\n","                C = dat.TensorDataset(A, B[i])\n","                test_loader[i] = dat.DataLoader(\n","                    dataset=C,\n","                    batch_size=batch_size,\n","                    drop_last=True, )\n","\n","                del A, C\n","                gc.collect()\n","\n","            print(\"Testing set loading completed\")\n","            return test_loader, B\n","        elif dataset == \"valid\":\n","            A = torch.load(\"/HDD_data/HYK/bis/database/validdata.pt\")\n","            B = torch.load(\"/HDD_data/HYK/bis/database/validlabel.pt\")\n","            train_data = dat.TensorDataset(A, B)\n","            valid_loader = dat.DataLoader(dataset=train_data,\n","                                          batch_size=batch_size,\n","                                          drop_last=True,\n","                                          num_workers=4,\n","                                          pin_memory=True,\n","                                          shuffle=True)\n","            print(\"Validation set loading completed\")\n","            return valid_loader\n","\n","    def load_all(self, vb, trb, teb):\n","        vaild_loader = self.pt_load(\n","            dataset=\"valid\",\n","            batch_size=vb\n","        )\n","\n","        train_loader = self.pt_load(\n","            dataset=\"train\",\n","            batch_size=trb,\n","        )\n","\n","        test_loader, test_label = self.pt_load(\n","            dataset=\"test\",\n","            batch_size=teb,\n","        )\n","        return vaild_loader, train_loader, test_loader, test_label\n","\n","\n","def data_distribution_bar(data, label_error=None):\n","    \"\"\"\n","    :param data: data will be plot in bar\n","    :return:\n","    \"\"\"\n","    fig = plt.figure(figsize=(24, 16))\n","\n","    da = plt.Rectangle((24, 0), 38, 50, color=\"cornsilk\")\n","    ga = plt.Rectangle((32, 0), 14.5, 50, color=\"paleturquoise\")\n","    # s = plt.Rectangle((60, 0), 30, 50, color=\"cornsilk\")\n","    w = plt.Rectangle((0, 0), 100, 50, color=\"pink\")\n","\n","    if not label_error:\n","        ax = fig.add_subplot(111)\n","        plt.xlabel('BIS', fontsize=30)\n","    else:\n","        ax_error = fig.add_subplot(212)\n","        ax_error.add_patch(w)\n","        ax_error.add_patch(da)\n","        ax_error.add_patch(ga)\n","\n","        ax_error.bar(list(range(100)), label_error[1], color='forestgreen')\n","        ax_error.bar(list(range(100)), label_error[0], color='salmon')\n","        ax_error.legend(['Few-shot region', 'Medium-shot region', 'Many-shot region', 'Baseline', 'Ours'],\n","                        fontsize=25, loc=1)\n","        plt.xlim(0, 100)\n","        plt.ylim(0, 50)\n","        plt.xticks(fontsize=30)\n","        plt.yticks(fontsize=30)\n","        plt.xlabel('BIS', fontsize=30)\n","        plt.ylabel('Test error', fontsize=30)\n","\n","        ax = fig.add_subplot(211)\n","\n","    plt.xlim(0, 100)\n","    plt.ylim(0, 6.5)\n","    plt.xticks(fontsize=30)\n","    plt.yticks(fontsize=30)\n","    plt.ylabel('Percentage(%)', fontsize=30)\n","\n","    da = plt.Rectangle((24, 0), 38, 50, color=\"cornsilk\")\n","    ga = plt.Rectangle((32.5, 0), 14, 50, color=\"paleturquoise\")\n","    # s = plt.Rectangle((60, 0), 30, 50, color=\"cornsilk\")\n","    w = plt.Rectangle((0, 0), 100, 50, color=\"pink\")\n","\n","    ax.add_patch(w)\n","    ax.add_patch(da)\n","    ax.add_patch(ga)\n","\n","    # for i in range(3):\n","    #     ax.text(15+i*30, 6.65, '%.2f%%' % sum(data[i*30:i*30+30]),\n","    #             fontsize=30, ha='center', va='bottom')\n","    ax.text(12, 6.65, '%.2f%%' % sum(data[:24]),\n","            fontsize=30, ha='center', va='bottom')\n","    ax.text(28, 6.65, '%.2f%%' % sum(data[24:32]),\n","            fontsize=30, ha='center', va='bottom')\n","    ax.text(39.75, 6.65, '%.2f%%' % sum(data[32:46]),\n","            fontsize=30, ha='center', va='bottom')\n","    ax.text(54.25, 6.65, '%.2f%%' % sum(data[46:62]),\n","            fontsize=30, ha='center', va='bottom')\n","    ax.text(81, 6.65, '%.2f%%' % sum(data[62:]),\n","            fontsize=30, ha='center', va='bottom')\n","\n","    ax.bar(list(range(100)), data, color='darkslateblue')\n","    ax.legend(['Few-shot region', 'Medium-shot region', 'Many-shot region', 'Label Percentage'],\n","              fontsize=25, loc=1)\n","\n","    plt.savefig('/HDD_data/HYK/bis/output/test error.jpg')\n","    plt.show()\n","\n","\n","def error_down(e):\n","    e1 = np.asarray(e[0][:98])\n","    e2 = np.asarray(e[1][:98])\n","    return (e1-e2)/e2\n","\n","\n","if __name__ == \"__main__\":\n","    data = 1\n","    # data_distribution_bar(data, label_error=None)\n"],"metadata":{"id":"JoOD9Ym2KGmg","executionInfo":{"status":"ok","timestamp":1705761012742,"user_tz":-360,"elapsed":3558,"user":{"displayName":"Rafsan Jany","userId":"08721334090885411304"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["# model"],"metadata":{"id":"eaT4ySNBL-jZ"}},{"cell_type":"markdown","source":["## baseline"],"metadata":{"id":"GJ_v6vsCMAIt"}},{"cell_type":"markdown","source":["### <font color='coral'>class</font> baseline"],"metadata":{"id":"R0ht2wG7MT44"}},{"cell_type":"code","source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","\n","\n","class LstmModel(nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        self.input_dim = config.input_dim\n","        self.memory_cell = config.memory_cell\n","        self.body_dim = config.body_dim\n","        self.n = config.n\n","        self.lstm1 = nn.LSTM(1, self.memory_cell, batch_first=True)\n","        self.lstm2 = nn.LSTM(1, self.memory_cell, batch_first=True)\n","\n","        self.fc = nn.Sequential(\n","            nn.Linear(self.memory_cell*2+self.body_dim, config.n),\n","            nn.ReLU(),\n","            nn.Linear(config.n, 1),\n","        )\n","\n","    def forward(self, x, b):\n","        #  self.lstm(input_seq.reshape(seq_len序列长度, batch批量大小, input_size特征维度), (h0, c0))\n","        x1, (hn, cn) = self.lstm1(x[..., 0].unsqueeze(-1))\n","        x2, (hn, cn) = self.lstm2(x[..., 1].unsqueeze(-1))\n","        x1 = x1[:, -1]\n","        x2 = x2[:, -1]\n","        x = torch.cat((x1, x2), dim=1)\n","        x = torch.cat((x, b), dim=1)\n","        x = self.fc(x)\n","\n","        return x\n"],"metadata":{"id":"Yda_o9WbNjIz","executionInfo":{"status":"ok","timestamp":1705761012743,"user_tz":-360,"elapsed":26,"user":{"displayName":"Rafsan Jany","userId":"08721334090885411304"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["### <font color='coral'>class </font>params"],"metadata":{"id":"1BvHy1qlMXvf"}},{"cell_type":"code","source":["import argparse\n","\n","\n","class Params:\n","    def __init__(self):\n","        self.x = 1\n","\n","    @staticmethod\n","    def lstm_params():\n","        parser = argparse.ArgumentParser()\n","        parser.add_argument('--input_dim',     default=2,              type=int)\n","        parser.add_argument('--memory_cell',     default=8,              type=int)\n","        parser.add_argument('--body_dim',   default=4,              type=int)\n","        parser.add_argument('--n',         default=16,              type=int)\n","\n","        args = parser.parse_args()\n","        return args\n","\n","    @staticmethod\n","    def trainparam():\n","        parser = argparse.ArgumentParser()\n","        parser.add_argument('--model_name', default=\"baseline\", type=str)\n","        parser.add_argument('--tw',           default=180,   type=int)\n","        parser.add_argument('--train_batch',  default=100,   type=int)\n","        parser.add_argument('--vaild_batch',  default=30,    type=int)\n","        parser.add_argument('--test_batch',   default=76,    type=int)\n","        parser.add_argument('--batch_size',   default=64,    type=int)\n","        parser.add_argument('--train_epoch',  default=50,    type=int)\n","        parser.add_argument('--lr',           default=3e-4,  type=float)\n","        parser.add_argument('--pre_train',    default=False,  type=bool)\n","        parser.add_argument('--pre_tr_times', default=0,     type=int)\n","        parser.add_argument('--device',       default=3,     type=int)\n","        parser.add_argument('--best_loss',    default=80000, type=int)\n","\n","        args = parser.parse_args()\n","\n","        # 预训练文件路径\n","        pre_file = f'/home/user02/HYK/bis_transformer/output/{args.model_name}/epoch{args.pre_tr_times}.pth'\n","        model_file = f'/home/user02/HYK/bis_transformer/output/{args.model_name}/model/epoch{args.pre_tr_times}.pth'\n","        best_file = f'/home/user02/HYK/bis_transformer/output/{args.model_name}/model/best_epoch.pth'\n","        # 保存文件路径\n","        save_file = f'/home/user02/HYK/bis_transformer/output/{args.model_name}/epoch{args.pre_tr_times}.pth'\n","\n","        parser.add_argument('--pre_file', default=pre_file, type=str)\n","        parser.add_argument('--model_file', default=model_file, type=str)\n","        parser.add_argument('--best_file', default=best_file, type=str)\n","        parser.add_argument('--save_file', default=save_file, type=str)\n","        args = parser.parse_args()\n","\n","        return args"],"metadata":{"id":"ZbKO8yUvOm9o","executionInfo":{"status":"ok","timestamp":1705761012744,"user_tz":-360,"elapsed":27,"user":{"displayName":"Rafsan Jany","userId":"08721334090885411304"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["### <font color='coral'> class</font> params_ni</font>"],"metadata":{"id":"NwVeZgbcMcU-"}},{"cell_type":"code","source":["import argparse\n","\n","\n","class Params_ni:\n","    def __init__(self):\n","        self.x = 1\n","\n","    @staticmethod\n","    def lstm_params():\n","        parser = argparse.ArgumentParser()\n","        parser.add_argument('--input_dim',     default=2,              type=int)\n","        parser.add_argument('--memory_cell',     default=8,              type=int)\n","        parser.add_argument('--body_dim',   default=4,              type=int)\n","        parser.add_argument('--n',         default=16,              type=int)\n","\n","        args = parser.parse_args()\n","        return args\n","\n","    @staticmethod\n","    def trainparam():\n","        parser = argparse.ArgumentParser()\n","        parser.add_argument('--model_name', default=\"baseline\", type=str)\n","        parser.add_argument('--tw',           default=180,   type=int)\n","        parser.add_argument('--train_batch',  default=100,   type=int)\n","        parser.add_argument('--vaild_batch',  default=30,    type=int)\n","        parser.add_argument('--test_batch',   default=76,    type=int)\n","        parser.add_argument('--batch_size',   default=64,    type=int)\n","        parser.add_argument('--train_epoch',  default=50,    type=int)\n","        parser.add_argument('--lr',           default=3e-4,  type=float)\n","        parser.add_argument('--pre_train',    default=True,  type=bool)\n","        parser.add_argument('--pre_tr_times', default=0,     type=int)\n","        parser.add_argument('--device',       default=1,     type=int)\n","        parser.add_argument('--best_loss',    default=80000, type=int)\n","\n","        args = parser.parse_args()\n","        root = '/data/HYK/DATASET/bis/output'\n","        # 预训练文件路径\n","        pre_file = f'{root}/{args.model_name}/epoch{args.pre_tr_times}.pth'\n","        model_file = f'{root}/{args.model_name}/model/epoch{args.pre_tr_times}.pth'\n","        best_file = f'{root}/{args.model_name}/model/best_epoch.pth'\n","        # 保存文件路径\n","        save_file = f'{root}/{args.model_name}/epoch{args.pre_tr_times}.pth'\n","\n","        parser.add_argument('--pre_file', default=pre_file, type=str)\n","        parser.add_argument('--model_file', default=model_file, type=str)\n","        parser.add_argument('--best_file', default=best_file, type=str)\n","        parser.add_argument('--save_file', default=save_file, type=str)\n","        args = parser.parse_args()\n","\n","        return args"],"metadata":{"id":"Emuan22jOxBG","executionInfo":{"status":"ok","timestamp":1705761012745,"user_tz":-360,"elapsed":27,"user":{"displayName":"Rafsan Jany","userId":"08721334090885411304"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["### <font color='coral'>class </font>class trainer"],"metadata":{"id":"bTpTUCbDMfrt"}},{"cell_type":"code","source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","from tqdm import tqdm\n","from tensorboardX import SummaryWriter\n","#from model.baseline import baseline\n","#from model.baseline import params\n","import imp\n","\n","\n","\n","class Trainer:\n","    def __init__(self, config):\n","        self.model_name = config.model_name\n","        self.device = config.device\n","        self.epoch = config.train_epoch\n","        self.pre_train = config.pre_train\n","        self.pre_tr_times = config.pre_tr_times\n","        self.save_pth = f\"/data/HYK/DATASET/bis/output/{config.model_name}\"\n","\n","\n","        args = params.Params.lstm_params()\n","\n","        self.loss_function = nn.MSELoss()\n","        self.model = baseline.LstmModel(config=args).cuda()\n","\n","        # 参数初始化\n","        # self.model.apply(weights_init)\n","\n","    def train(self, X, X2, lr, model_file, best_loss):\n","        print(\"train begin\")\n","\n","        model = self.model.train()\n","\n","        if self.pre_train:\n","            model.load_state_dict(torch.load(model_file))\n","            best_loss = np.loadtxt(f\"{self.save_pth}/loss.txt\")[0]\n","            print(best_loss)\n","            print(self.pre_tr_times)\n","\n","        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","\n","        for i in range(1, self.epoch + 1):\n","            loss = 0\n","\n","            for seq, labels in tqdm(X):\n","                optimizer.zero_grad()\n","\n","                labels = labels.cuda()\n","                seq = seq.cuda()\n","                x1 = seq[:, :, :2]\n","                # x1:(batchsize, 180, 2)\n","                x2 = seq[:, 0, 5:]\n","                rnn_out = model.forward(x1, x2)\n","                batchloss = self.loss_function(rnn_out, labels.unsqueeze(-1))\n","                # batchloss = sum(self.loss_function(rnn_out, labels.unsqueeze(-1)))\n","                batchloss.backward()\n","\n","                optimizer.step()\n","\n","                loss += batchloss.detach().item()\n","\n","            vaild_loss = self.vaild_full(X=X2, model=model)\n","            model = model.train()\n","\n","            if vaild_loss < best_loss:\n","                print(\"new\")\n","                best_loss = vaild_loss\n","                np.savetxt(f\"{self.save_pth}/loss.txt\", np.asarray([vaild_loss, vaild_loss]))\n","                torch.save(model.state_dict(), f'{self.save_pth}/model/best_epoch.pth')\n","            torch.save(model.state_dict(), f'{self.save_pth}/model/epoch{i + self.pre_tr_times}.pth')\n","            print(f\"{i} train loss: {loss}\")\n","            print(f\"eval loss: {vaild_loss}\")\n","\n","        return\n","\n","    def vaild_full(self, X, model):\n","        model = model.eval()\n","\n","        loss = 0\n","        for seq, labels in tqdm(X):\n","            seq = seq.cuda()\n","            labels = labels.cuda()\n","            x1 = seq[:, :, :2]\n","            x2 = seq[:, 0, 5:]\n","\n","            with torch.no_grad():\n","\n","                rnn_out = model.forward(x1, x2)\n","                batchloss = self.loss_function(rnn_out, labels.unsqueeze(-1))\n","                # batchloss = sum(self.loss_function(rnn_out, labels.unsqueeze(-1)))\n","                loss += batchloss.detach().item()\n","\n","        return loss\n","\n","    def test(self, X, epoch_pth, test_batch):\n","        print(\"test begin\")\n","        test_output = []\n","        for _ in range(len(X)):\n","            test_output.append([])\n","\n","        model2 = self.model.eval()\n","        model2.load_state_dict(torch.load(f'{epoch_pth}', map_location='cuda:0'))\n","\n","        for j in tqdm(range(test_batch)):\n","            for seq, labels in X[j]:\n","                seq = seq.cuda()\n","                x1 = seq[:, :, :2]\n","                x2 = seq[:, 0, 5:]\n","                with torch.no_grad():\n","                    y_pred = model2(x1, x2)\n","                    # y_pred = y_pred.view(y_pred.shape[0])\n","                    test_output[j].extend(y_pred.squeeze(-1).tolist())\n","\n","        return test_output\n","\n","\n","def weights_init(m):\n","    if isinstance(m, nn.Linear):\n","        nn.init.kaiming_normal_(m.weight, mode='fan_in', nonlinearity='relu')\n","        nn.init.constant_(m.bias, 0)\n","    # 也可以判断是否为conv2d，使用相应的初始化方式\n","    elif isinstance(m, nn.Conv2d):\n","        nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n","    # 是否为批归一化层\n","    elif isinstance(m, nn.BatchNorm2d):\n","        nn.init.constant_(m.weight, 1)\n","        nn.init.constant_(m.bias, 0)"],"metadata":{"id":"BMAvKYAOMjNa","executionInfo":{"status":"ok","timestamp":1705761012745,"user_tz":-360,"elapsed":27,"user":{"displayName":"Rafsan Jany","userId":"08721334090885411304"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["# mainer"],"metadata":{"id":"mvZqwqWxKhhf"}},{"cell_type":"markdown","source":["##<font color='coral'>class </font>evaluate"],"metadata":{"id":"6n4ukISsLK2N"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","\n","class Evalulate:\n","    def __init__(self, x, y, istart, istop, case_num):\n","        # x:预测结果 y:label len:样本长度\n","        self.len = case_num\n","        self.case_num = case_num\n","        self.x = x[:self.len]\n","        self.y = y[:self.len]\n","        self.MSE = nn.MSELoss()\n","        self.MAE = nn.L1Loss()\n","        self.istrat = istart\n","        self.istop = istop\n","\n","        for i in range(case_num):\n","            self.x[i] = torch.tensor(self.x[i])\n","            self.y[i] = torch.tensor(self.y[i])\n","            if len(x[i]) < len(y[i]):\n","                self.y[i] = self.y[i][:len(x[i])]\n","            else:\n","                self.x[i] = self.x[i][:len(y[i])]\n","\n","    def rateplot(self, i):\n","        r = self.x[i] / self.y[i]\n","        plt.plot(r)\n","\n","    def ratelist(self):\n","        r = [0] * self.len\n","        for i in range(self.len):\n","            r[i] = self.x[i] / self.y[i]\n","            plt.plot(r[i])\n","        plt.show()\n","\n","    def loss(self, period=0):\n","        # 0, 1, 2, 3 全阶段,引导期，维持期，复苏期\n","        t1, t2 = 0, 0\n","\n","        PE = [0] * self.len\n","        MSE = [0] * self.len\n","        MAE = [0] * self.len\n","\n","        MDPE, MDAPE, RMSE = [0] * self.len, [0] * self.len, [0] * self.len\n","        for i in range(self.len):\n","            if period == 0:\n","                t1 = self.istrat[i]\n","                t2 = -1\n","            elif period == 1:\n","                t1 = self.istrat[i]\n","                t2 = self.istrat[i] + 600\n","            elif period == 2:\n","                t1 = self.istrat[i] + 600\n","                t2 = self.istop[i]\n","            elif period == 3:\n","                t1 = self.istop[i]\n","                t2 = -1\n","            PE[i] = ((self.x[i][t1:t2] - self.y[i][t1:t2]) / self.x[i][t1:t2])\n","            MSE[i] = self.MSE(self.x[i][t1:t2].unsqueeze(-1), self.y[i][t1:t2].unsqueeze(-1))\n","            MAE[i] = self.MAE(self.x[i][t1:t2].unsqueeze(-1), self.y[i][t1:t2].unsqueeze(-1))\n","            MDPE[i], MDAPE[i], RMSE[i] = self.estimate(PE=PE[i], MSE=MSE[i])\n","\n","        out = {\"MDPE\": MDPE,\n","               \"MDAPE\": MDAPE,\n","               \"RMSE\": RMSE,\n","               \"MAE\": MAE,\n","               \"meanMDPE\": np.mean(MDPE),\n","               \"meanMDAPE\": np.mean(MDAPE),\n","               \"meanRMSE\": np.mean(RMSE),\n","               \"meanMAE\": np.mean(MAE),\n","               \"SD\": [np.std(MDPE), np.std(MDAPE), np.std(RMSE), np.std(MAE)],\n","               }\n","        return out\n","\n","    @staticmethod\n","    def estimate(PE, MSE):\n","        \"\"\"\n","        :param PE: 每个样本的bis误差（预测bis-真实bis），输入格式：list([样本误差])\n","        :param MSE: 每个样本的loss， 输入格式：list([样本loss])\n","        :return: MDPE:误差中位数， MDAPE:绝对误差中位数， RMSE:均方差\n","        \"\"\"\n","        MDPE = np.median(PE) * 100\n","        MDAPE = np.median(np.abs(PE)) * 100\n","        RMSE = np.sqrt(MSE)\n","        return MDPE, MDAPE, RMSE\n","\n","    def test_error(self, label_num):\n","        t_error = []\n","        out, label = [], []\n","        for i in range(self.case_num):\n","            out.extend(self.x[i])\n","            label.extend(self.y[i])\n","\n","        for i in range(len(t_error)):\n","            out[i] = int(out[i])\n","            label[i] = int(label[i])\n","        out = np.asarray(out)\n","        label = np.asarray(label)\n","\n","        index = np.argsort(label)\n","        label = label[index]\n","        out = out[index]\n","        # t_error = out - label\n","\n","        \"\"\"\n","            label,out: 排好序的向量\n","            t_error:每个样本点（80万个）的误差\n","            label_error:从0到100，label的误差均值\n","        \"\"\"\n","        for i in range(len(label)):\n","            label[i] = int(label[i])\n","        j = 0\n","        label_error = list(np.zeros(100))\n","\n","        for i in range(100):\n","            label_error[i] = []\n","            while label[j] == i:\n","                # label_num[i] += 1\n","                label_error[i].append(out[j]-label[j])\n","                j += 1\n","                if j == len(label)-10:\n","                    break\n","            label_error[i] = np.abs(np.mean(label_error[i]))\n","\n","        \"\"\"\n","            误差图\n","        \"\"\"\n","        plt.autoscale(axis='x', tight=True)\n","        plt.bar(list(range(100)), label_error)\n","        plt.xlabel(\"bis index\")\n","        plt.ylabel(\"label nums\")\n","        plt.show()\n","\n","        \"\"\"\n","            相关性计算\n","        \"\"\"\n","        a = np.asarray(label_num)\n","        b = np.asarray(label_error)\n","        for i in range(100):\n","            if b[i] < 0:\n","                b[i] = -b[i]\n","        plt.subplot(2, 1, 1)\n","        plt.title(f\"Pearson correlation: -{np.corrcoef(a, b)[0, 1]}\")\n","        plt.bar(range(100), a, color='lightskyblue')\n","        plt.ylabel(\"sample nums\")\n","        plt.subplot(2, 1, 2)\n","        plt.bar(range(100), b, color='lightcoral')\n","        plt.xlabel(\"label space\")\n","        plt.ylabel(\"test error\")\n","        plt.show()\n","        \"\"\"\n","            卷积\n","        \"\"\"\n","        from scipy.ndimage import convolve1d\n","        p = a/len(label)\n","        lds_kernel_window = self.get_lds_kernel_window(kernel='gaussian', ks=10, sigma=8)\n","\n","        eff_label_dist = convolve1d(p, weights=lds_kernel_window, mode='constant')\n","        cor = np.corrcoef(eff_label_dist, b)[0, 1]\n","        plt.bar(range(100), eff_label_dist, color='lightcoral')\n","        plt.show()\n","        return t_error, label_error\n","\n","    @staticmethod\n","    def get_lds_kernel_window(kernel, ks, sigma):\n","        from scipy.ndimage import gaussian_filter1d\n","        from scipy.signal.windows import triang\n","        assert kernel in ['gaussian', 'triang', 'laplace']\n","        half_ks = (ks - 1) // 2\n","        if kernel == 'gaussian':\n","            base_kernel = [0.] * half_ks + [1.] + [0.] * half_ks\n","            kernel_window = gaussian_filter1d(base_kernel, sigma=sigma) / max(gaussian_filter1d(base_kernel, sigma=sigma))\n","        elif kernel == 'triang':\n","            kernel_window = triang(ks)\n","        else:\n","            laplace = lambda x: np.exp(-abs(x) / sigma) / (2. * sigma)\n","            kernel_window = list(map(laplace, np.arange(-half_ks, half_ks + 1))) / max(map(laplace, np.arange(-half_ks, half_ks + 1)))\n","\n","        return kernel_window\n","\n","\n","\n","\"\"\"if __name__ == \"__main__\":\n","    x1 = [torch.ones(3000)*10, torch.ones(3000)*110, torch.ones(3000)*56]\n","    y1 = [torch.ones(3001), torch.ones(3001), torch.ones(3001)]\n","    e = Evalulate(x1, y1)\n","    MDPE, MDAPE, RMSE = e.loss()\n","    e.ratelist()\"\"\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"kvvnQEWgLKnI","executionInfo":{"status":"ok","timestamp":1705761013363,"user_tz":-360,"elapsed":644,"user":{"displayName":"Rafsan Jany","userId":"08721334090885411304"}},"outputId":"76bf6b14-6fe2-4936-82e2-ca3b61865dbb"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'if __name__ == \"__main__\":\\n    x1 = [torch.ones(3000)*10, torch.ones(3000)*110, torch.ones(3000)*56]\\n    y1 = [torch.ones(3001), torch.ones(3001), torch.ones(3001)]\\n    e = Evalulate(x1, y1)\\n    MDPE, MDAPE, RMSE = e.loss()\\n    e.ratelist()'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":8}]},{"cell_type":"markdown","source":["##<font color='coral'>class </font> main_baseline"],"metadata":{"id":"T06vOI9jKkFF"}},{"cell_type":"code","source":["import torch\n","import matplotlib.pyplot as plt\n","import tqdm\n","#from loader import database\n","#import evaluate\n","import numpy as np\n","import random\n","#from model.baseline import trainer, params\n","import imp\n","\n","\n","def setup_seed(seed):\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","    np.random.seed(seed)\n","    random.seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","\n","\n","# 设置随机数种子\n","setup_seed(2)\n","# 训练或测试模式\n","mode = 'test'\n","# 训练参数读取\n","args = Params.trainparam()\n","\n","\n","if __name__ == \"__main__\":\n","    with torch.cuda.device(args.device):\n","        args.device = torch.device(f'cuda:{args.device}' if torch.cuda.is_available() else 'cpu')\n","        if torch.cuda.is_available():\n","            print(f\"GPU{args.device} open\")\n","        else:\n","            print(\"cpu open\")\n","\n","        box = trainer.Trainer(args)\n","        d_box = database.Dataloader(\n","            database_wdir=\"/HDD_data/HYK/bis/database\",\n","            time_step=1,\n","            nums=1,\n","            tw=180\n","        )\n","        # 开始训练或测试\n","        if mode == \"train\":\n","\n","            test_loader, test_label = d_box.test_data_loader(\n","                data=\"test\",\n","                batch=76,\n","                batch_size=128\n","            )\n","\n","            d_box.time_step = 10\n","            vaild_loader = d_box.train_data_loader(\n","                data=\"test\",\n","                batch=30,\n","                batch_size=512\n","            )\n","\n","            train_loader = d_box.train_data_loader(\n","                batch=100,\n","                batch_size=1024,\n","            )\n","\n","            box.train(\n","                X=train_loader,\n","                X2=vaild_loader,\n","                lr=args.lr,\n","                model_file=args.best_file,\n","                best_loss=args.best_loss\n","            )\n","\n","            test_out = box.test(\n","                X=test_loader,\n","                epoch_pth=args.best_file,\n","                test_batch=76)\n","\n","            ist, isp = d_box.time_devide(case_nums=76, traindata=\"test\")\n","            access = evaluate.Evalulate(test_label, test_out, ist, isp, case_num=76)\n","            print(\"MDPE    MDAPE    RMSE\\r\")\n","            for i in range(4):\n","                print(\"%.2f     %.2f     %.2f\" % access.loss(i))\n","\n","        elif mode == \"test\":\n","            test_loader, test_label = d_box.test_data_loader(\n","                batch=args.test_batch,\n","                batch_size=76\n","            )\n","\n","            pre_tr_times = 9\n","            pre_file = f'/home/user02/HYK/bis_transformer/output/baseline/model/epoch{pre_tr_times}.pth'\n","            test_out = box.test(\n","                X=test_loader,\n","                epoch_pth=args.best_file,\n","                test_batch=76)\n","\n","            import statsmodels.api as sm\n","            lowess = sm.nonparametric.lowess\n","            new = list(range(76))\n","            for i in tqdm.tqdm(range(76)):\n","                axis = list(range(len(test_out[i])))\n","                new[i] = lowess(test_out[i], axis, frac=0.03)[:, 1]\n","            ist, isp = d_box.time_devide(case_nums=76, traindata=\"test\")\n","            access = evaluate.Evalulate(test_label, new, ist, isp, case_num=76)\n","            print(\"MDPE    MDAPE    RMSE\\r\")\n","            for i in range(4):\n","                print(\"%.2f     %.2f     %.2f\" % access.loss(i))\n","\n","\n","            plt.grid(True)\n","            plt.autoscale(axis='x', tight=True)\n","            for i in range(4,9):\n","                plt.figure()\n","                plt.plot(test_label[i])\n","                plt.plot(test_out[i])\n","                plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":300},"id":"mdGapxN2IDUQ","executionInfo":{"status":"error","timestamp":1705761013363,"user_tz":-360,"elapsed":145,"user":{"displayName":"Rafsan Jany","userId":"08721334090885411304"}},"outputId":"f03448dc-5d15-44f8-d110-9c75b3ef19a2"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stderr","text":["usage: colab_kernel_launcher.py [-h] [--model_name MODEL_NAME] [--tw TW]\n","                                [--train_batch TRAIN_BATCH] [--vaild_batch VAILD_BATCH]\n","                                [--test_batch TEST_BATCH] [--batch_size BATCH_SIZE]\n","                                [--train_epoch TRAIN_EPOCH] [--lr LR] [--pre_train PRE_TRAIN]\n","                                [--pre_tr_times PRE_TR_TIMES] [--device DEVICE]\n","                                [--best_loss BEST_LOSS]\n","colab_kernel_launcher.py: error: unrecognized arguments: -f /root/.local/share/jupyter/runtime/kernel-82714648-aaaa-4ada-81ff-a04dda4c4052.json\n"]},{"output_type":"error","ename":"SystemExit","evalue":"2","traceback":["An exception has occurred, use %tb to see the full traceback.\n","\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py:3561: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n","  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"oilhqKtpK9q1","executionInfo":{"status":"aborted","timestamp":1705761013378,"user_tz":-360,"elapsed":156,"user":{"displayName":"Rafsan Jany","userId":"08721334090885411304"}}},"execution_count":null,"outputs":[]}]}