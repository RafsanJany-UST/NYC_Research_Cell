{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09f1bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | Loss: 12.9696 | Accuracy: 0.7294\n",
      "Epoch 002 | Loss: 13.5585 | Accuracy: 0.7330\n",
      "Epoch 003 | Loss: 14.0757 | Accuracy: 0.7294\n",
      "Epoch 004 | Loss: 12.8118 | Accuracy: 0.7340\n",
      "Epoch 005 | Loss: 12.5914 | Accuracy: 0.7304\n",
      "Epoch 006 | Loss: 11.9020 | Accuracy: 0.7325\n",
      "Epoch 007 | Loss: 12.1821 | Accuracy: 0.7325\n",
      "Epoch 008 | Loss: 11.5636 | Accuracy: 0.7309\n",
      "Epoch 009 | Loss: 12.0252 | Accuracy: 0.7263\n",
      "Epoch 010 | Loss: 11.4670 | Accuracy: 0.7248\n",
      "Epoch 011 | Loss: 10.3683 | Accuracy: 0.7360\n",
      "Epoch 012 | Loss: 9.9706 | Accuracy: 0.7391\n",
      "Epoch 013 | Loss: 9.9337 | Accuracy: 0.7375\n",
      "Epoch 014 | Loss: 10.5263 | Accuracy: 0.7269\n",
      "Epoch 015 | Loss: 9.6229 | Accuracy: 0.7335\n",
      "Epoch 016 | Loss: 10.1451 | Accuracy: 0.7258\n",
      "Epoch 017 | Loss: 9.8064 | Accuracy: 0.7274\n",
      "Epoch 018 | Loss: 9.2065 | Accuracy: 0.7345\n",
      "Epoch 019 | Loss: 9.3835 | Accuracy: 0.7314\n",
      "Epoch 020 | Loss: 8.9242 | Accuracy: 0.7345\n",
      "Epoch 021 | Loss: 8.8990 | Accuracy: 0.7350\n",
      "Epoch 022 | Loss: 9.1632 | Accuracy: 0.7253\n",
      "Epoch 023 | Loss: 8.5822 | Accuracy: 0.7345\n",
      "Epoch 024 | Loss: 8.3509 | Accuracy: 0.7355\n",
      "Epoch 025 | Loss: 8.7680 | Accuracy: 0.7213\n",
      "Epoch 026 | Loss: 8.1995 | Accuracy: 0.7279\n"
     ]
    }
   ],
   "source": [
    "# âœ… Clean Baseline QoR Model with GCN + LSTM + Focal Loss + Patient-wise Evaluation\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.loader import DataLoader\n",
    "from sklearn.metrics import classification_report, brier_score_loss\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.calibration import calibration_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ðŸ”§ Config\n",
    "WINDOW_SIZE = 120\n",
    "STRIDE = 10\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 100\n",
    "LEARNING_RATE = 1e-4\n",
    "\n",
    "# ðŸ“¦ Load Data\n",
    "path = r\"D:\\Data\\NYC\\KINZ\\KINECT_dataset_with_qor15.csv\"\n",
    "df = pd.read_csv(path)\n",
    "df = df[df['walking_speed'] == 'Fast']\n",
    "df.dropna(subset=['QoR_class'], inplace=True)\n",
    "\n",
    "# ðŸ§± Graph Structure\n",
    "joints = ['PELVIS', 'SPINE_NAVAL', 'SPINE_CHEST', 'NECK', 'CLAVICLE_LEFT', 'SHOULDER_LEFT',\n",
    "          'ELBOW_LEFT', 'WRIST_LEFT', 'HAND_LEFT', 'HANDTIP_LEFT', 'THUMB_LEFT',\n",
    "          'CLAVICLE_RIGHT', 'SHOULDER_RIGHT', 'ELBOW_RIGHT', 'WRIST_RIGHT', 'HAND_RIGHT',\n",
    "          'HANDTIP_RIGHT', 'THUMB_RIGHT', 'HIP_LEFT', 'KNEE_LEFT', 'ANKLE_LEFT',\n",
    "          'FOOT_LEFT', 'HIP_RIGHT', 'KNEE_RIGHT', 'ANKLE_RIGHT', 'FOOT_RIGHT',\n",
    "          'HEAD', 'NOSE', 'EYE_LEFT', 'EAR_LEFT', 'EYE_RIGHT', 'EAR_RIGHT']\n",
    "\n",
    "edges = [('PELVIS', 'SPINE_NAVAL'), ('SPINE_NAVAL', 'SPINE_CHEST'), ('SPINE_CHEST', 'NECK'),\n",
    "         ('NECK', 'HEAD'), ('SPINE_CHEST', 'CLAVICLE_LEFT'), ('CLAVICLE_LEFT', 'SHOULDER_LEFT'),\n",
    "         ('SHOULDER_LEFT', 'ELBOW_LEFT'), ('ELBOW_LEFT', 'WRIST_LEFT'), ('WRIST_LEFT', 'HAND_LEFT'),\n",
    "         ('HAND_LEFT', 'HANDTIP_LEFT'), ('WRIST_LEFT', 'THUMB_LEFT'), ('SPINE_CHEST', 'CLAVICLE_RIGHT'),\n",
    "         ('CLAVICLE_RIGHT', 'SHOULDER_RIGHT'), ('SHOULDER_RIGHT', 'ELBOW_RIGHT'), ('ELBOW_RIGHT', 'WRIST_RIGHT'),\n",
    "         ('WRIST_RIGHT', 'HAND_RIGHT'), ('HAND_RIGHT', 'HANDTIP_RIGHT'), ('WRIST_RIGHT', 'THUMB_RIGHT'),\n",
    "         ('PELVIS', 'HIP_LEFT'), ('HIP_LEFT', 'KNEE_LEFT'), ('KNEE_LEFT', 'ANKLE_LEFT'),\n",
    "         ('ANKLE_LEFT', 'FOOT_LEFT'), ('PELVIS', 'HIP_RIGHT'), ('HIP_RIGHT', 'KNEE_RIGHT'),\n",
    "         ('KNEE_RIGHT', 'ANKLE_RIGHT'), ('ANKLE_RIGHT', 'FOOT_RIGHT'),\n",
    "         ('HEAD', 'NOSE'), ('HEAD', 'EYE_LEFT'), ('HEAD', 'EYE_RIGHT'),\n",
    "         ('HEAD', 'EAR_LEFT'), ('HEAD', 'EAR_RIGHT')]\n",
    "\n",
    "joint_to_idx = {j: i for i, j in enumerate(joints)}\n",
    "edge_index = torch.tensor([[joint_to_idx[a], joint_to_idx[b]] for a, b in edges] +\n",
    "                          [[joint_to_idx[b], joint_to_idx[a]] for a, b in edges], dtype=torch.long).t()\n",
    "\n",
    "# ðŸ“š Dataset\n",
    "class WindowedDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, window_size, stride):\n",
    "        self.samples = []\n",
    "        grouped = df.groupby(['patient_id', 'trial'])\n",
    "        for (pid, trial), group in grouped:\n",
    "            group = group.sort_values('t_uniform')\n",
    "            if len(group) < window_size:\n",
    "                continue\n",
    "            for i in range(0, len(group) - window_size + 1, stride):\n",
    "                window = group.iloc[i:i+window_size]\n",
    "                x_seq = torch.tensor([\n",
    "                    [[row[f'{j}_X'], row[f'{j}_Y'], row[f'{j}_Z'], row['t_uniform']] for j in joints]\n",
    "                    for _, row in window.iterrows()\n",
    "                ], dtype=torch.float)\n",
    "                aux_seq = torch.tensor([\n",
    "                    [row['left_foot_swing'], row['right_foot_swing'], row['pelvis_pos']] \n",
    "                    for _, row in window.iterrows()\n",
    "                ], dtype=torch.float)\n",
    "                label = torch.tensor(window['QoR_class'].mode().values[0], dtype=torch.float)\n",
    "                self.samples.append((x_seq, aux_seq, label, pid))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.samples[idx]\n",
    "\n",
    "# ðŸ”€ Split\n",
    "train_ids, test_ids = train_test_split(df['patient_id'].unique(), test_size=0.3, random_state=42)\n",
    "train_df = df[df['patient_id'].isin(train_ids)]\n",
    "test_df = df[df['patient_id'].isin(test_ids)]\n",
    "\n",
    "train_dataset = WindowedDataset(train_df, WINDOW_SIZE, STRIDE)\n",
    "test_dataset = WindowedDataset(test_df, WINDOW_SIZE, STRIDE)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "# ðŸ§  Model\n",
    "class GCN_LSTM_Model(nn.Module):\n",
    "    def __init__(self, in_channels=4, hidden_channels=128):\n",
    "        super().__init__()\n",
    "        self.gcn = GCNConv(in_channels, hidden_channels)\n",
    "        self.lstm = nn.LSTM(hidden_channels, hidden_channels, batch_first=True)\n",
    "        self.aux_fc = nn.Linear(3, hidden_channels)\n",
    "        self.classifier = nn.Linear(2 * hidden_channels, 1)\n",
    "\n",
    "    def forward(self, x_seq, aux_seq):\n",
    "        B, T, N, feat_dim = x_seq.shape\n",
    "        x_seq = x_seq.view(B * T * N, feat_dim)\n",
    "        full_edge_index = torch.cat([edge_index + b * N for b in range(B * T)], dim=1).to(x_seq.device)\n",
    "        x = F.relu(self.gcn(x_seq, full_edge_index))\n",
    "        x = x.view(B, T, N, -1).mean(2)\n",
    "        x, _ = self.lstm(x)\n",
    "        aux = F.relu(self.aux_fc(aux_seq.mean(1)))\n",
    "        return self.classifier(torch.cat([x[:, -1, :], aux], dim=-1)).view(-1)\n",
    "\n",
    "# ðŸŽ¯ Focal Loss\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        BCE = F.binary_cross_entropy_with_logits(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-BCE)\n",
    "        return (self.alpha * (1 - pt) ** self.gamma * BCE).mean()\n",
    "\n",
    "# ðŸš€ Training\n",
    "model = GCN_LSTM_Model().to('cuda')\n",
    "criterion = FocalLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss, correct, total = 0, 0, 0\n",
    "    for x_seq, aux_seq, y, _ in train_dataset:\n",
    "        x_seq, aux_seq, y = x_seq.unsqueeze(0).to('cuda'), aux_seq.unsqueeze(0).to('cuda'), y.unsqueeze(0).to('cuda')\n",
    "        optimizer.zero_grad()\n",
    "        out = model(x_seq, aux_seq)\n",
    "        loss = criterion(out, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        correct += ((torch.sigmoid(out) >= 0.5).float() == y).sum().item()\n",
    "        total += 1\n",
    "    print(f\"Epoch {epoch+1:03d} | Loss: {total_loss/total:.4f} | Accuracy: {correct/total:.4f}\")\n",
    "\n",
    "# ðŸ“Š Per-Patient Evaluation\n",
    "model.eval()\n",
    "patient_results = defaultdict(list)\n",
    "with torch.no_grad():\n",
    "    for x_seq, aux_seq, y, pid in test_dataset:\n",
    "        x_seq, aux_seq = x_seq.unsqueeze(0).to('cuda'), aux_seq.unsqueeze(0).to('cuda')\n",
    "        out = torch.sigmoid(model(x_seq, aux_seq)).cpu().item()\n",
    "        patient_results[pid].append({'pred': int(out >= 0.5), 'true': int(y.item()), 'prob': out})\n",
    "\n",
    "summary = []\n",
    "for pid, recs in patient_results.items():\n",
    "    preds = [r['pred'] for r in recs]\n",
    "    trues = [r['true'] for r in recs]\n",
    "    probs = [r['prob'] for r in recs]\n",
    "    valid = sum(p == t for p, t in zip(preds, trues))\n",
    "    summary.append({\n",
    "        'PatientID': pid,\n",
    "        'Predicted_QoR_class': max(set(preds), key=preds.count),\n",
    "        'Actual_QoR_class': max(set(trues), key=trues.count),\n",
    "        'valid_percentage': round(100 * valid / len(trues), 2),\n",
    "        'average_model_output': round(sum(probs)/len(probs), 4)\n",
    "    })\n",
    "\n",
    "report_df = pd.DataFrame(summary).sort_values('PatientID')\n",
    "print(report_df)\n",
    "\n",
    "# ðŸ“ˆ Calibration Curve\n",
    "all_probs = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for x_seq, aux_seq, y, _ in test_dataset:\n",
    "        x_seq, aux_seq = x_seq.unsqueeze(0).to('cuda'), aux_seq.unsqueeze(0).to('cuda')\n",
    "        prob = torch.sigmoid(model(x_seq, aux_seq)).cpu().item()\n",
    "        all_probs.append(prob)\n",
    "        all_labels.append(y.item())\n",
    "\n",
    "prob_true, prob_pred = calibration_curve(all_labels, all_probs, n_bins=10)\n",
    "plt.plot(prob_pred, prob_true, marker='o', label='Calibration')\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', label='Perfectly Calibrated')\n",
    "plt.xlabel('Predicted Probability')\n",
    "plt.ylabel('True Probability')\n",
    "plt.title('Calibration Curve')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9c3bd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de7d416",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_on",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
