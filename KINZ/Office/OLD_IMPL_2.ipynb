{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3ebd413",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_3472\\1392250405.py:70: DtypeWarning: Columns (108,112,113,117,151,154,161,162,164,169,180,185,198,221,228,264,267,269,270,306,307,310,311,314,315,318,319,322,323,326,328,330,331,334,335,338,339,342,343,346,348,350,352,354,356,358,362,363,393,403,404,406,418,423,430,433,436,439,444) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  dataframe = pd.read_csv(data_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train QoR_class distribution:\n",
      "QoR_class\n",
      "0.0    33\n",
      "1.0    26\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test QoR_class distribution:\n",
      "QoR_class\n",
      "0.0    9\n",
      "1.0    6\n",
      "Name: count, dtype: int64\n",
      "Epoch 001/10 | Train Loss: 0.5706, Acc: 0.5305 | Test Loss: 0.5509, Acc: 0.6098\n",
      "Epoch 002/10 | Train Loss: 0.5483, Acc: 0.5566 | Test Loss: 0.5439, Acc: 0.6365\n",
      "Epoch 003/10 | Train Loss: 0.5218, Acc: 0.5776 | Test Loss: 0.5206, Acc: 0.6588\n",
      "Epoch 004/10 | Train Loss: 0.5036, Acc: 0.6079 | Test Loss: 0.4928, Acc: 0.6981\n",
      "Epoch 005/10 | Train Loss: 0.4734, Acc: 0.6534 | Test Loss: 0.4538, Acc: 0.7236\n",
      "Epoch 006/10 | Train Loss: 0.4508, Acc: 0.6822 | Test Loss: 0.4413, Acc: 0.7374\n",
      "Epoch 007/10 | Train Loss: 0.4235, Acc: 0.7152 | Test Loss: 0.4108, Acc: 0.7669\n",
      "Epoch 008/10 | Train Loss: 0.4007, Acc: 0.7317 | Test Loss: 0.3992, Acc: 0.7847\n",
      "Epoch 009/10 | Train Loss: 0.3762, Acc: 0.7537 | Test Loss: 0.3709, Acc: 0.7881\n",
      "Epoch 010/10 | Train Loss: 0.3509, Acc: 0.7780 | Test Loss: 0.3377, Acc: 0.8168\n",
      "Final Test Accuracy: 0.8168\n",
      "F1 Score: 0.7535\n",
      "Recall: 0.6594\n",
      "Precision: 0.8788\n",
      "Specificity: 0.9329\n",
      "AUC-ROC: 0.7962\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Good (0)       0.79      0.93      0.85      4755\n",
      "Not Good (1)       0.88      0.66      0.75      3509\n",
      "\n",
      "    accuracy                           0.82      8264\n",
      "   macro avg       0.83      0.80      0.80      8264\n",
      "weighted avg       0.83      0.82      0.81      8264\n",
      "\n",
      "Model and statistics saved.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 2. Graph Definition\n",
    "joints = ['PELVIS', 'SPINE_NAVAL', 'SPINE_CHEST', 'NECK', 'CLAVICLE_LEFT', 'SHOULDER_LEFT',\n",
    "          'ELBOW_LEFT', 'WRIST_LEFT', 'HAND_LEFT', 'HANDTIP_LEFT', 'THUMB_LEFT',\n",
    "          'CLAVICLE_RIGHT', 'SHOULDER_RIGHT', 'ELBOW_RIGHT', 'WRIST_RIGHT', 'HAND_RIGHT',\n",
    "          'HANDTIP_RIGHT', 'THUMB_RIGHT', 'HIP_LEFT', 'KNEE_LEFT', 'ANKLE_LEFT',\n",
    "          'FOOT_LEFT', 'HIP_RIGHT', 'KNEE_RIGHT', 'ANKLE_RIGHT', 'FOOT_RIGHT',\n",
    "          'HEAD', 'NOSE', 'EYE_LEFT', 'EAR_LEFT', 'EYE_RIGHT', 'EAR_RIGHT']\n",
    "\n",
    "edges = [('PELVIS', 'SPINE_NAVAL'), ('SPINE_NAVAL', 'SPINE_CHEST'), ('SPINE_CHEST', 'NECK'),\n",
    "         ('NECK', 'HEAD'), ('SPINE_CHEST', 'CLAVICLE_LEFT'), ('CLAVICLE_LEFT', 'SHOULDER_LEFT'),\n",
    "         ('SHOULDER_LEFT', 'ELBOW_LEFT'), ('ELBOW_LEFT', 'WRIST_LEFT'), ('WRIST_LEFT', 'HAND_LEFT'),\n",
    "         ('HAND_LEFT', 'HANDTIP_LEFT'), ('WRIST_LEFT', 'THUMB_LEFT'), ('SPINE_CHEST', 'CLAVICLE_RIGHT'),\n",
    "         ('CLAVICLE_RIGHT', 'SHOULDER_RIGHT'), ('SHOULDER_RIGHT', 'ELBOW_RIGHT'), ('ELBOW_RIGHT', 'WRIST_RIGHT'),\n",
    "         ('WRIST_RIGHT', 'HAND_RIGHT'), ('HAND_RIGHT', 'HANDTIP_RIGHT'), ('WRIST_RIGHT', 'THUMB_RIGHT'),\n",
    "         ('PELVIS', 'HIP_LEFT'), ('HIP_LEFT', 'KNEE_LEFT'), ('KNEE_LEFT', 'ANKLE_LEFT'),\n",
    "         ('ANKLE_LEFT', 'FOOT_LEFT'), ('PELVIS', 'HIP_RIGHT'), ('HIP_RIGHT', 'KNEE_RIGHT'),\n",
    "         ('KNEE_RIGHT', 'ANKLE_RIGHT'), ('ANKLE_RIGHT', 'FOOT_RIGHT'),\n",
    "         ('HEAD', 'NOSE'), ('HEAD','EYE_LEFT'), ('HEAD', 'EYE_RIGHT'), ('HEAD', 'EAR_LEFT'), ('HEAD', 'EAR_RIGHT')]\n",
    "\n",
    "\n",
    "\n",
    "joint_to_idx = {joint: idx for idx, joint in enumerate(joints)}\n",
    "edge_index = torch.tensor([[joint_to_idx[src], joint_to_idx[dst]] for src, dst in edges] +\n",
    "                          [[joint_to_idx[dst], joint_to_idx[src]] for src, dst in edges],\n",
    "                          dtype=torch.long).t()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 3. Dataset\n",
    "class SkeletonDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.data = df\n",
    "        self.num_nodes = len(joints)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        node_features = [[row[f'{j}_X'], row[f'{j}_Y'], row[f'{j}_Z'], row['t_uniform']] for j in joints]\n",
    "        x = torch.tensor(node_features, dtype=torch.float)\n",
    "        y = torch.tensor(row['QoR_class'], dtype=torch.float)\n",
    "        return Data(x=x, edge_index=edge_index, y=y)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# Load dataset\n",
    "data_path =  r\"D:\\Data\\NYC\\KINZ\\KINECT_ACC_dataset_with_qor15_2025-05-27_14-29PM.csv\"\n",
    "dataframe = pd.read_csv(data_path)\n",
    "dataframe = dataframe[dataframe['walking_speed'] == \"Fast\"]\n",
    "dataframe = dataframe[dataframe['QoR_class'].isin([0, 1])].copy()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df = dataframe\n",
    "\n",
    "# Step 1: Create a patient-level table with QoR_class\n",
    "patient_qor = df[['patientID', 'QoR_class']].drop_duplicates(subset='patientID')\n",
    "\n",
    "# Step 2: Stratified patient-wise split\n",
    "train_patients, test_patients = train_test_split(\n",
    "    patient_qor['patientID'],\n",
    "    test_size=0.2,\n",
    "    stratify=patient_qor['QoR_class'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Step 3: Create train/test splits of the full DataFrame\n",
    "df_train = df[df['patientID'].isin(train_patients)].reset_index(drop=True)\n",
    "df_test = df[df['patientID'].isin(test_patients)].reset_index(drop=True)\n",
    "\n",
    "# Step 4: Check class balance\n",
    "print(\"Train QoR_class distribution:\")\n",
    "print(df_train[['patientID', 'QoR_class']].drop_duplicates()['QoR_class'].value_counts())\n",
    "\n",
    "print(\"\\nTest QoR_class distribution:\")\n",
    "print(df_test[['patientID', 'QoR_class']].drop_duplicates()['QoR_class'].value_counts())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dataset = SkeletonDataset(df_train)\n",
    "\n",
    "# 4. Random split\n",
    "full_dataset = SkeletonDataset(dataframe.dropna(subset=['QoR_class']))\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "test_size = len(full_dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(full_dataset, [train_size, test_size])\n",
    "\n",
    "# 5. Weighted Sampling\n",
    "train_indices = train_dataset.indices if isinstance(train_dataset, torch.utils.data.Subset) else list(range(len(train_dataset)))\n",
    "train_df = dataframe.iloc[train_indices].reset_index(drop=True)\n",
    "train_df = train_df.dropna(subset=['QoR_class'])\n",
    "class_counts = train_df['QoR_class'].value_counts().sort_index().to_numpy()\n",
    "class_weights = 1. / class_counts\n",
    "sample_weights = [class_weights[int(label)] for label in train_df['QoR_class']]\n",
    "sampler = WeightedRandomSampler(sample_weights, len(sample_weights), replacement=True)\n",
    "\n",
    "\n",
    "# 6. Dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, sampler=sampler)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "# 7. Model\n",
    "class HybridSTGCN(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, num_classes):\n",
    "        super().__init__()\n",
    "        self.gcn1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.gcn2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.temporal_conv1 = nn.Conv1d(hidden_channels, hidden_channels, kernel_size=3, padding=1)\n",
    "        self.lstm = nn.LSTM(hidden_channels, hidden_channels, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_channels, num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        batch = getattr(data, 'batch', None)\n",
    "        x = F.relu(self.gcn1(x, edge_index))\n",
    "        x = F.relu(self.gcn2(x, edge_index))\n",
    "        batch_size = batch.max().item() + 1 if batch is not None else 1\n",
    "        num_nodes = x.size(0) // batch_size\n",
    "        x = x.view(batch_size, num_nodes, -1).permute(0, 2, 1)\n",
    "        x = F.relu(self.temporal_conv1(x)).permute(0, 2, 1)\n",
    "        x, _ = self.lstm(x)\n",
    "        x = x.mean(dim=1)\n",
    "        return self.fc(x).squeeze()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 8. Training Setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = HybridSTGCN(in_channels=4, hidden_channels=128, num_classes=1).to(device)\n",
    "pos_weight = torch.tensor([class_weights[0] / class_weights[1]]).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-5, weight_decay=1e-4)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, min_delta=0.005):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = float('inf')\n",
    "        self.best_model = None\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        if val_loss < self.best_loss - self.min_delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "            self.best_model = model.state_dict()\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                if self.best_model is not None:\n",
    "                    model.load_state_dict(self.best_model)\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 9. Training Loop\n",
    "num_epochs = 10\n",
    "train_losses, test_losses, train_accuracies, test_accuracies = [], [], [], []\n",
    "early_stopping = EarlyStopping()\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    model.train()\n",
    "    total_loss, correct, total = 0, 0, 0\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        y = data.y.to(device).float()\n",
    "        loss = criterion(out, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * data.num_graphs\n",
    "        correct += ((out >= 0.5) == y).sum().item()\n",
    "        total += data.num_graphs\n",
    "    train_loss = total_loss / len(train_loader.dataset)\n",
    "    train_acc = correct / total\n",
    "\n",
    "    model.eval()\n",
    "    total_loss, correct, total, all_preds, all_labels = 0, 0, 0, [], []\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            data = data.to(device)\n",
    "            out = model(data)\n",
    "            y = data.y.to(device).float()\n",
    "            loss = criterion(out, y)\n",
    "            total_loss += loss.item() * data.num_graphs\n",
    "            pred = (torch.sigmoid(out) >= 0.5).float()\n",
    "            correct += (pred == y).sum().item()\n",
    "            total += data.num_graphs\n",
    "            all_preds.extend(pred.cpu().numpy())\n",
    "            all_labels.extend(y.cpu().numpy())\n",
    "\n",
    "    test_loss = total_loss / len(test_loader.dataset)\n",
    "    test_acc = correct / total\n",
    "    train_losses.append(train_loss)\n",
    "    test_losses.append(test_loss)\n",
    "    train_accuracies.append(train_acc)\n",
    "    test_accuracies.append(test_acc)\n",
    "\n",
    "    print(f\"Epoch {epoch:03d}/{num_epochs} | Train Loss: {train_loss:.4f}, Acc: {train_acc:.4f} | Test Loss: {test_loss:.4f}, Acc: {test_acc:.4f}\")\n",
    "\n",
    "    if early_stopping(test_loss, model):\n",
    "        print(\"Early stopping triggered.\")\n",
    "        break\n",
    "\n",
    "\n",
    "\n",
    "# 10. Final Evaluation\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "f1 = f1_score(all_labels, all_preds)\n",
    "recall = recall_score(all_labels, all_preds)\n",
    "precision = precision_score(all_labels, all_preds)\n",
    "roc_auc = roc_auc_score(all_labels, all_preds)\n",
    "tn, fp, fn, tp = confusion_matrix(all_labels, all_preds).ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Final Test Accuracy: {accuracy:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Specificity: {specificity:.4f}\")\n",
    "print(f\"AUC-ROC: {roc_auc:.4f}\")\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(all_labels, all_preds, target_names=['Good (0)', 'Not Good (1)']))\n",
    "\n",
    "\n",
    "\n",
    "# 11. Save Model + Stats\n",
    "now = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "torch.save(model.state_dict(), f\"QOR_hybrid_stgcn_model_{now}.pth\")\n",
    "with open(f\"QOR_hybrid_stgcn_model_statistics_{now}.pkl\", 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'train_losses': train_losses,\n",
    "        'test_losses': test_losses,\n",
    "        'train_accuracies': train_accuracies,\n",
    "        'test_accuracies': test_accuracies,\n",
    "        'final_metrics': {\n",
    "            'accuracy': accuracy,\n",
    "            'f1_score': f1,\n",
    "            'recall': recall,\n",
    "            'precision': precision,\n",
    "            'specificity': specificity,\n",
    "            'roc_auc': roc_auc\n",
    "        }\n",
    "    }, f)\n",
    "print(\"Model and statistics saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4ebd2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient-level classification report:\n",
      "   patientID  actual_class  predicted_class  num_frames  correct_predictions  \\\n",
      "0     009-TB             1                1         862                  734   \n",
      "1     012-JM             0                0         589                  557   \n",
      "2     018-OS             0                0         266                  245   \n",
      "3     022-ND             1                0         250                    4   \n",
      "4     024-PO             1                1         294                  293   \n",
      "5     032-GB             0                0         392                  357   \n",
      "6     033-JF             1                0         581                  282   \n",
      "7     041-JL             0                1          77                   12   \n",
      "8     044-MS             1                1         633                  555   \n",
      "9     049-RL             0                0         260                  230   \n",
      "10    054-LC             0                0         804                  804   \n",
      "11    061-JM             1                1         880                  662   \n",
      "12    069-CR             0                0         619                  543   \n",
      "13    080-TW             0                0         691                  645   \n",
      "\n",
      "    accuracy_within_patient  \n",
      "0                  0.851508  \n",
      "1                  0.945671  \n",
      "2                  0.921053  \n",
      "3                  0.016000  \n",
      "4                  0.996599  \n",
      "5                  0.910714  \n",
      "6                  0.485370  \n",
      "7                  0.155844  \n",
      "8                  0.876777  \n",
      "9                  0.884615  \n",
      "10                 1.000000  \n",
      "11                 0.752273  \n",
      "12                 0.877221  \n",
      "13                 0.933430  \n",
      "\n",
      "Overall patient-level accuracy: 0.8\n"
     ]
    }
   ],
   "source": [
    "# 1. Create test dataset from df_test\n",
    "test_dataset_by_patient = SkeletonDataset(df_test)\n",
    "\n",
    "# 2. Prepare DataLoader (no sampler)\n",
    "test_loader_by_patient = DataLoader(test_dataset_by_patient, batch_size=1, shuffle=False)\n",
    "\n",
    "# 3. Collect predictions by patient\n",
    "from collections import defaultdict\n",
    "\n",
    "model.eval()\n",
    "patient_preds = defaultdict(list)\n",
    "patient_labels = {}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(test_loader_by_patient):\n",
    "        data = data.to(device)\n",
    "        output = model(data)\n",
    "        prob = torch.sigmoid(output).item()\n",
    "        pred_class = 1 if prob >= 0.5 else 0\n",
    "\n",
    "        patient_id = df_test.iloc[i]['patientID']\n",
    "        true_class = int(df_test.iloc[i]['QoR_class'])\n",
    "\n",
    "        patient_preds[patient_id].append(pred_class)\n",
    "        patient_labels[patient_id] = true_class\n",
    "\n",
    "# 4. Aggregate to per-patient report\n",
    "report = []\n",
    "\n",
    "for pid, preds in patient_preds.items():\n",
    "    true_class = patient_labels[pid]\n",
    "    total = len(preds)\n",
    "    correct = sum([1 if p == true_class else 0 for p in preds])\n",
    "    acc = correct / total\n",
    "    final_prediction = 1 if np.mean(preds) >= 0.5 else 0  # majority via mean\n",
    "    report.append({\n",
    "        'patientID': pid,\n",
    "        'actual_class': true_class,\n",
    "        'predicted_class': final_prediction,\n",
    "        'num_frames': total,\n",
    "        'correct_predictions': correct,\n",
    "        'accuracy_within_patient': acc\n",
    "    })\n",
    "\n",
    "# 5. Create DataFrame\n",
    "patient_report_df = pd.DataFrame(report)\n",
    "\n",
    "# 6. Summary Stats\n",
    "print(\"Patient-level classification report:\")\n",
    "print(\"\\nOverall patient-level accuracy:\",\n",
    "      (patient_report_df['actual_class'] == patient_report_df['predicted_class']).mean())\n",
    "patient_report_df.head(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136d9652",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_on",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
