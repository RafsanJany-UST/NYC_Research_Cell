{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09f1bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14660\\4062919961.py:25: DtypeWarning: Columns (108,112,113,117,151,154,161,162,164,169,180,185,198,221,228,264,267,269,270,306,307,310,311,314,315,318,319,322,323,326,328,330,331,334,335,338,339,342,343,346,348,350,352,354,356,358,362,363,393,403,404,406,418,423,430,433,436,439,444) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(path)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'patient_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\torch_on\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'patient_id'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 82\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msamples[idx]\n\u001b[0;32m     81\u001b[0m \u001b[38;5;66;03m# ðŸ”€ Split\u001b[39;00m\n\u001b[1;32m---> 82\u001b[0m train_ids, test_ids \u001b[38;5;241m=\u001b[39m train_test_split(\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpatient_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39munique(), test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m     83\u001b[0m train_df \u001b[38;5;241m=\u001b[39m df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpatient_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misin(train_ids)]\n\u001b[0;32m     84\u001b[0m test_df \u001b[38;5;241m=\u001b[39m df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpatient_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misin(test_ids)]\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\torch_on\\lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\torch_on\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'patient_id'"
     ]
    }
   ],
   "source": [
    "# âœ… Clean Baseline QoR Model with GCN + LSTM + Focal Loss + Patient-wise Evaluation\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.loader import DataLoader\n",
    "from sklearn.metrics import classification_report, brier_score_loss\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.calibration import calibration_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ðŸ”§ Config\n",
    "WINDOW_SIZE = 120\n",
    "STRIDE = 10\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 100\n",
    "LEARNING_RATE = 1e-4\n",
    "\n",
    "# ðŸ“¦ Load Data\n",
    "path = r\"D:\\Data\\NYC\\KINZ\\KINECT_ACC_dataset_with_qor15_2025-05-27_14-29PM.csv\"\n",
    "df = pd.read_csv(path)\n",
    "df = df[df['walking_speed'] == 'Fast']\n",
    "df.dropna(subset=['QoR_class'], inplace=True)\n",
    "\n",
    "# ðŸ§± Graph Structure\n",
    "joints = ['PELVIS', 'SPINE_NAVAL', 'SPINE_CHEST', 'NECK', 'CLAVICLE_LEFT', 'SHOULDER_LEFT',\n",
    "          'ELBOW_LEFT', 'WRIST_LEFT', 'HAND_LEFT', 'HANDTIP_LEFT', 'THUMB_LEFT',\n",
    "          'CLAVICLE_RIGHT', 'SHOULDER_RIGHT', 'ELBOW_RIGHT', 'WRIST_RIGHT', 'HAND_RIGHT',\n",
    "          'HANDTIP_RIGHT', 'THUMB_RIGHT', 'HIP_LEFT', 'KNEE_LEFT', 'ANKLE_LEFT',\n",
    "          'FOOT_LEFT', 'HIP_RIGHT', 'KNEE_RIGHT', 'ANKLE_RIGHT', 'FOOT_RIGHT',\n",
    "          'HEAD', 'NOSE', 'EYE_LEFT', 'EAR_LEFT', 'EYE_RIGHT', 'EAR_RIGHT']\n",
    "\n",
    "edges = [('PELVIS', 'SPINE_NAVAL'), ('SPINE_NAVAL', 'SPINE_CHEST'), ('SPINE_CHEST', 'NECK'),\n",
    "         ('NECK', 'HEAD'), ('SPINE_CHEST', 'CLAVICLE_LEFT'), ('CLAVICLE_LEFT', 'SHOULDER_LEFT'),\n",
    "         ('SHOULDER_LEFT', 'ELBOW_LEFT'), ('ELBOW_LEFT', 'WRIST_LEFT'), ('WRIST_LEFT', 'HAND_LEFT'),\n",
    "         ('HAND_LEFT', 'HANDTIP_LEFT'), ('WRIST_LEFT', 'THUMB_LEFT'), ('SPINE_CHEST', 'CLAVICLE_RIGHT'),\n",
    "         ('CLAVICLE_RIGHT', 'SHOULDER_RIGHT'), ('SHOULDER_RIGHT', 'ELBOW_RIGHT'), ('ELBOW_RIGHT', 'WRIST_RIGHT'),\n",
    "         ('WRIST_RIGHT', 'HAND_RIGHT'), ('HAND_RIGHT', 'HANDTIP_RIGHT'), ('WRIST_RIGHT', 'THUMB_RIGHT'),\n",
    "         ('PELVIS', 'HIP_LEFT'), ('HIP_LEFT', 'KNEE_LEFT'), ('KNEE_LEFT', 'ANKLE_LEFT'),\n",
    "         ('ANKLE_LEFT', 'FOOT_LEFT'), ('PELVIS', 'HIP_RIGHT'), ('HIP_RIGHT', 'KNEE_RIGHT'),\n",
    "         ('KNEE_RIGHT', 'ANKLE_RIGHT'), ('ANKLE_RIGHT', 'FOOT_RIGHT'),\n",
    "         ('HEAD', 'NOSE'), ('HEAD', 'EYE_LEFT'), ('HEAD', 'EYE_RIGHT'),\n",
    "         ('HEAD', 'EAR_LEFT'), ('HEAD', 'EAR_RIGHT')]\n",
    "\n",
    "joint_to_idx = {j: i for i, j in enumerate(joints)}\n",
    "edge_index = torch.tensor([[joint_to_idx[a], joint_to_idx[b]] for a, b in edges] +\n",
    "                          [[joint_to_idx[b], joint_to_idx[a]] for a, b in edges], dtype=torch.long).t()\n",
    "\n",
    "# ðŸ“š Dataset\n",
    "class WindowedDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, window_size, stride):\n",
    "        self.samples = []\n",
    "        grouped = df.groupby(['patient_id', 'trial'])\n",
    "        for (pid, trial), group in grouped:\n",
    "            group = group.sort_values('t_uniform')\n",
    "            if len(group) < window_size:\n",
    "                continue\n",
    "            for i in range(0, len(group) - window_size + 1, stride):\n",
    "                window = group.iloc[i:i+window_size]\n",
    "                x_seq = torch.tensor([\n",
    "                    [[row[f'{j}_X'], row[f'{j}_Y'], row[f'{j}_Z'], row['t_uniform']] for j in joints]\n",
    "                    for _, row in window.iterrows()\n",
    "                ], dtype=torch.float)\n",
    "                aux_seq = torch.tensor([\n",
    "                    [row['left_foot_swing'], row['right_foot_swing'], row['pelvis_pos']] \n",
    "                    for _, row in window.iterrows()\n",
    "                ], dtype=torch.float)\n",
    "                label = torch.tensor(window['QoR_class'].mode().values[0], dtype=torch.float)\n",
    "                self.samples.append((x_seq, aux_seq, label, pid))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.samples[idx]\n",
    "\n",
    "# ðŸ”€ Split\n",
    "train_ids, test_ids = train_test_split(df['patientID'].unique(), test_size=0.3, random_state=42)\n",
    "train_df = df[df['patientID'].isin(train_ids)]\n",
    "test_df = df[df['patientID'].isin(test_ids)]\n",
    "\n",
    "train_dataset = WindowedDataset(train_df, WINDOW_SIZE, STRIDE)\n",
    "test_dataset = WindowedDataset(test_df, WINDOW_SIZE, STRIDE)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "# ðŸ§  Model\n",
    "class GCN_LSTM_Model(nn.Module):\n",
    "    def __init__(self, in_channels=4, hidden_channels=128):\n",
    "        super().__init__()\n",
    "        self.gcn = GCNConv(in_channels, hidden_channels)\n",
    "        self.lstm = nn.LSTM(hidden_channels, hidden_channels, batch_first=True)\n",
    "        self.aux_fc = nn.Linear(3, hidden_channels)\n",
    "        self.classifier = nn.Linear(2 * hidden_channels, 1)\n",
    "\n",
    "    def forward(self, x_seq, aux_seq):\n",
    "        B, T, N, feat_dim = x_seq.shape\n",
    "        x_seq = x_seq.view(B * T * N, feat_dim)\n",
    "        full_edge_index = torch.cat([edge_index + b * N for b in range(B * T)], dim=1).to(x_seq.device)\n",
    "        x = F.relu(self.gcn(x_seq, full_edge_index))\n",
    "        x = x.view(B, T, N, -1).mean(2)\n",
    "        x, _ = self.lstm(x)\n",
    "        aux = F.relu(self.aux_fc(aux_seq.mean(1)))\n",
    "        return self.classifier(torch.cat([x[:, -1, :], aux], dim=-1)).view(-1)\n",
    "\n",
    "# ðŸŽ¯ Focal Loss\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        BCE = F.binary_cross_entropy_with_logits(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-BCE)\n",
    "        return (self.alpha * (1 - pt) ** self.gamma * BCE).mean()\n",
    "\n",
    "# ðŸš€ Training\n",
    "model = GCN_LSTM_Model().to('cuda')\n",
    "criterion = FocalLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss, correct, total = 0, 0, 0\n",
    "    for x_seq, aux_seq, y, _ in train_dataset:\n",
    "        x_seq, aux_seq, y = x_seq.unsqueeze(0).to('cuda'), aux_seq.unsqueeze(0).to('cuda'), y.unsqueeze(0).to('cuda')\n",
    "        optimizer.zero_grad()\n",
    "        out = model(x_seq, aux_seq)\n",
    "        loss = criterion(out, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        correct += ((torch.sigmoid(out) >= 0.5).float() == y).sum().item()\n",
    "        total += 1\n",
    "    print(f\"Epoch {epoch+1:03d} | Loss: {total_loss/total:.4f} | Accuracy: {correct/total:.4f}\")\n",
    "\n",
    "# ðŸ“Š Per-Patient Evaluation\n",
    "model.eval()\n",
    "patient_results = defaultdict(list)\n",
    "with torch.no_grad():\n",
    "    for x_seq, aux_seq, y, pid in test_dataset:\n",
    "        x_seq, aux_seq = x_seq.unsqueeze(0).to('cuda'), aux_seq.unsqueeze(0).to('cuda')\n",
    "        out = torch.sigmoid(model(x_seq, aux_seq)).cpu().item()\n",
    "        patient_results[pid].append({'pred': int(out >= 0.5), 'true': int(y.item()), 'prob': out})\n",
    "\n",
    "summary = []\n",
    "for pid, recs in patient_results.items():\n",
    "    preds = [r['pred'] for r in recs]\n",
    "    trues = [r['true'] for r in recs]\n",
    "    probs = [r['prob'] for r in recs]\n",
    "    valid = sum(p == t for p, t in zip(preds, trues))\n",
    "    summary.append({\n",
    "        'PatientID': pid,\n",
    "        'Predicted_QoR_class': max(set(preds), key=preds.count),\n",
    "        'Actual_QoR_class': max(set(trues), key=trues.count),\n",
    "        'valid_percentage': round(100 * valid / len(trues), 2),\n",
    "        'average_model_output': round(sum(probs)/len(probs), 4)\n",
    "    })\n",
    "\n",
    "report_df = pd.DataFrame(summary).sort_values('PatientID')\n",
    "print(report_df)\n",
    "\n",
    "# ðŸ“ˆ Calibration Curve\n",
    "all_probs = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for x_seq, aux_seq, y, _ in test_dataset:\n",
    "        x_seq, aux_seq = x_seq.unsqueeze(0).to('cuda'), aux_seq.unsqueeze(0).to('cuda')\n",
    "        prob = torch.sigmoid(model(x_seq, aux_seq)).cpu().item()\n",
    "        all_probs.append(prob)\n",
    "        all_labels.append(y.item())\n",
    "\n",
    "prob_true, prob_pred = calibration_curve(all_labels, all_probs, n_bins=10)\n",
    "plt.plot(prob_pred, prob_true, marker='o', label='Calibration')\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', label='Perfectly Calibrated')\n",
    "plt.xlabel('Predicted Probability')\n",
    "plt.ylabel('True Probability')\n",
    "plt.title('Calibration Curve')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9c3bd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de7d416",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aeb6cf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e116d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752d0455",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bdb81785",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\miniconda3\\envs\\torch_on\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'relu'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 149\u001b[0m\n\u001b[0;32m    147\u001b[0m x_seq, aux_seq, y \u001b[38;5;241m=\u001b[39m x_seq\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m), aux_seq\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m), y\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    148\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m--> 149\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_seq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maux_seq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    150\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(out, y)\n\u001b[0;32m    151\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\torch_on\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\torch_on\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[8], line 118\u001b[0m, in \u001b[0;36mGCNTransformerModel.forward\u001b[1;34m(self, x_seq, aux_seq)\u001b[0m\n\u001b[0;32m    116\u001b[0m x_seq \u001b[38;5;241m=\u001b[39m x_seq\u001b[38;5;241m.\u001b[39mview(B \u001b[38;5;241m*\u001b[39m T \u001b[38;5;241m*\u001b[39m N, F)\n\u001b[0;32m    117\u001b[0m full_edge_index \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([edge_index \u001b[38;5;241m+\u001b[39m b \u001b[38;5;241m*\u001b[39m N \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(B \u001b[38;5;241m*\u001b[39m T)], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(x_seq\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m--> 118\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu\u001b[49m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgcn1(x_seq, full_edge_index))\n\u001b[0;32m    119\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgcn2(x, full_edge_index))\n\u001b[0;32m    120\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(B, T, N, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'int' object has no attribute 'relu'"
     ]
    }
   ],
   "source": [
    "# âœ… Advanced QoR Model with Multi-GCN + Transformer + Attention Fusion + Calibration\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.loader import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.calibration import calibration_curve\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "# ðŸ”§ Config\n",
    "WINDOW_SIZE = 120\n",
    "STRIDE = 10\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 100\n",
    "LEARNING_RATE = 1e-4\n",
    "\n",
    "# ðŸ“¦ Load Data\n",
    "path = r\"D:\\Data\\NYC\\KINZ\\KINECT_dataset_with_qor15.csv\"\n",
    "df = pd.read_csv(path)\n",
    "df = df[df['walking_speed'] == 'Fast']\n",
    "df.dropna(subset=['QoR_class'], inplace=True)\n",
    "\n",
    "# ðŸ§± Graph Structure\n",
    "joints = ['PELVIS', 'SPINE_NAVAL', 'SPINE_CHEST', 'NECK', 'CLAVICLE_LEFT', 'SHOULDER_LEFT',\n",
    "          'ELBOW_LEFT', 'WRIST_LEFT', 'HAND_LEFT', 'HANDTIP_LEFT', 'THUMB_LEFT',\n",
    "          'CLAVICLE_RIGHT', 'SHOULDER_RIGHT', 'ELBOW_RIGHT', 'WRIST_RIGHT', 'HAND_RIGHT',\n",
    "          'HANDTIP_RIGHT', 'THUMB_RIGHT', 'HIP_LEFT', 'KNEE_LEFT', 'ANKLE_LEFT',\n",
    "          'FOOT_LEFT', 'HIP_RIGHT', 'KNEE_RIGHT', 'ANKLE_RIGHT', 'FOOT_RIGHT',\n",
    "          'HEAD', 'NOSE', 'EYE_LEFT', 'EAR_LEFT', 'EYE_RIGHT', 'EAR_RIGHT']\n",
    "\n",
    "edges = [('PELVIS', 'SPINE_NAVAL'), ('SPINE_NAVAL', 'SPINE_CHEST'), ('SPINE_CHEST', 'NECK'),\n",
    "         ('NECK', 'HEAD'), ('SPINE_CHEST', 'CLAVICLE_LEFT'), ('CLAVICLE_LEFT', 'SHOULDER_LEFT'),\n",
    "         ('SHOULDER_LEFT', 'ELBOW_LEFT'), ('ELBOW_LEFT', 'WRIST_LEFT'), ('WRIST_LEFT', 'HAND_LEFT'),\n",
    "         ('HAND_LEFT', 'HANDTIP_LEFT'), ('WRIST_LEFT', 'THUMB_LEFT'), ('SPINE_CHEST', 'CLAVICLE_RIGHT'),\n",
    "         ('CLAVICLE_RIGHT', 'SHOULDER_RIGHT'), ('SHOULDER_RIGHT', 'ELBOW_RIGHT'), ('ELBOW_RIGHT', 'WRIST_RIGHT'),\n",
    "         ('WRIST_RIGHT', 'HAND_RIGHT'), ('HAND_RIGHT', 'HANDTIP_RIGHT'), ('WRIST_RIGHT', 'THUMB_RIGHT'),\n",
    "         ('PELVIS', 'HIP_LEFT'), ('HIP_LEFT', 'KNEE_LEFT'), ('KNEE_LEFT', 'ANKLE_LEFT'),\n",
    "         ('ANKLE_LEFT', 'FOOT_LEFT'), ('PELVIS', 'HIP_RIGHT'), ('HIP_RIGHT', 'KNEE_RIGHT'),\n",
    "         ('KNEE_RIGHT', 'ANKLE_RIGHT'), ('ANKLE_RIGHT', 'FOOT_RIGHT'),\n",
    "         ('HEAD', 'NOSE'), ('HEAD', 'EYE_LEFT'), ('HEAD', 'EYE_RIGHT'),\n",
    "         ('HEAD', 'EAR_LEFT'), ('HEAD', 'EAR_RIGHT')]\n",
    "\n",
    "joint_to_idx = {j: i for i, j in enumerate(joints)}\n",
    "edge_index = torch.tensor([[joint_to_idx[a], joint_to_idx[b]] for a, b in edges] +\n",
    "                          [[joint_to_idx[b], joint_to_idx[a]] for a, b in edges], dtype=torch.long).t()\n",
    "\n",
    "# ðŸ“š Dataset\n",
    "class WindowedDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, window_size, stride):\n",
    "        self.samples = []\n",
    "        grouped = df.groupby(['patient_id', 'trial'])\n",
    "        for (pid, trial), group in grouped:\n",
    "            group = group.sort_values('t_uniform')\n",
    "            if len(group) < window_size:\n",
    "                continue\n",
    "            for i in range(0, len(group) - window_size + 1, stride):\n",
    "                window = group.iloc[i:i+window_size]\n",
    "                x_seq = torch.tensor([\n",
    "                    [[row[f'{j}_X'], row[f'{j}_Y'], row[f'{j}_Z'], row['t_uniform']] for j in joints]\n",
    "                    for _, row in window.iterrows()\n",
    "                ], dtype=torch.float)\n",
    "                aux_seq = torch.tensor([\n",
    "                    [row['left_foot_swing'], row['right_foot_swing'], row['pelvis_pos']]\n",
    "                    for _, row in window.iterrows()\n",
    "                ], dtype=torch.float)\n",
    "                label = torch.tensor(window['QoR_class'].mode().values[0], dtype=torch.float)\n",
    "                self.samples.append((x_seq, aux_seq, label, pid))\n",
    "\n",
    "    def __len__(self): return len(self.samples)\n",
    "    def __getitem__(self, idx): return self.samples[idx]\n",
    "\n",
    "# ðŸ”€ Split\n",
    "train_ids, test_ids = train_test_split(df['patient_id'].unique(), test_size=0.3, random_state=42)\n",
    "train_df = df[df['patient_id'].isin(train_ids)]\n",
    "test_df = df[df['patient_id'].isin(test_ids)]\n",
    "train_dataset = WindowedDataset(train_df, WINDOW_SIZE, STRIDE)\n",
    "test_dataset = WindowedDataset(test_df, WINDOW_SIZE, STRIDE)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "# ðŸ”  Positional Encoding\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=500):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-np.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe.unsqueeze(0))\n",
    "\n",
    "    def forward(self, x): return x + self.pe[:, :x.size(1)]\n",
    "\n",
    "# ðŸ§  Model\n",
    "class GCNTransformerModel(nn.Module):\n",
    "    def __init__(self, in_channels=4, gcn_hidden=64, transformer_hidden=128):\n",
    "        super().__init__()\n",
    "        self.gcn1 = GCNConv(in_channels, gcn_hidden)\n",
    "        self.gcn2 = GCNConv(gcn_hidden, gcn_hidden)\n",
    "        self.transformer = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model=gcn_hidden, nhead=4, dim_feedforward=256), num_layers=2)\n",
    "        self.pos_encoder = PositionalEncoding(gcn_hidden)\n",
    "        self.aux_fc = nn.Sequential(\n",
    "            nn.Linear(3, 64), nn.ReLU(),\n",
    "            nn.Linear(64, transformer_hidden), nn.ReLU()\n",
    "        )\n",
    "        self.classifier = nn.Linear(transformer_hidden + gcn_hidden, 1)\n",
    "\n",
    "    def forward(self, x_seq, aux_seq):\n",
    "        B, T, N, F = x_seq.shape\n",
    "        x_seq = x_seq.view(B * T * N, F)\n",
    "        full_edge_index = torch.cat([edge_index + b * N for b in range(B * T)], dim=1).to(x_seq.device)\n",
    "        x = F.relu(self.gcn1(x_seq, full_edge_index))\n",
    "        x = F.relu(self.gcn2(x, full_edge_index))\n",
    "        x = x.view(B, T, N, -1).mean(2)\n",
    "        x = self.pos_encoder(x)\n",
    "        x = self.transformer(x)\n",
    "        x = x[:, -1, :]  # last token\n",
    "        aux = self.aux_fc(aux_seq.mean(1))\n",
    "        return self.classifier(torch.cat([x, aux], dim=-1)).view(-1)\n",
    "\n",
    "# ðŸŽ¯ Focal Loss\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "    def forward(self, inputs, targets):\n",
    "        BCE = F.binary_cross_entropy_with_logits(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-BCE)\n",
    "        return (self.alpha * (1 - pt) ** self.gamma * BCE).mean()\n",
    "\n",
    "# ðŸš€ Training\n",
    "model = GCNTransformerModel().to('cuda')\n",
    "criterion = FocalLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss, correct, total = 0, 0, 0\n",
    "    for x_seq, aux_seq, y, _ in train_dataset:\n",
    "        x_seq, aux_seq, y = x_seq.unsqueeze(0).to('cuda'), aux_seq.unsqueeze(0).to('cuda'), y.unsqueeze(0).to('cuda')\n",
    "        optimizer.zero_grad()\n",
    "        out = model(x_seq, aux_seq)\n",
    "        loss = criterion(out, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        correct += ((torch.sigmoid(out) >= 0.5).float() == y).sum().item()\n",
    "        total += 1\n",
    "    print(f\"Epoch {epoch+1:03d} | Loss: {total_loss/total:.4f} | Accuracy: {correct/total:.4f}\")\n",
    "\n",
    "# ðŸ“Š Evaluation\n",
    "model.eval()\n",
    "patient_results = defaultdict(list)\n",
    "with torch.no_grad():\n",
    "    for x_seq, aux_seq, y, pid in test_dataset:\n",
    "        x_seq, aux_seq = x_seq.unsqueeze(0).to('cuda'), aux_seq.unsqueeze(0).to('cuda')\n",
    "        out = torch.sigmoid(model(x_seq, aux_seq)).cpu().item()\n",
    "        patient_results[pid].append({'pred': int(out >= 0.5), 'true': int(y.item()), 'prob': out})\n",
    "\n",
    "summary = []\n",
    "for pid, recs in patient_results.items():\n",
    "    preds = [r['pred'] for r in recs]\n",
    "    trues = [r['true'] for r in recs]\n",
    "    probs = [r['prob'] for r in recs]\n",
    "    valid = sum(p == t for p, t in zip(preds, trues))\n",
    "    summary.append({\n",
    "        'PatientID': pid,\n",
    "        'Predicted_QoR_class': max(set(preds), key=preds.count),\n",
    "        'Actual_QoR_class': max(set(trues), key=trues.count),\n",
    "        'valid_percentage': round(100 * valid / len(trues), 2),\n",
    "        'average_model_output': round(sum(probs)/len(probs), 4)\n",
    "    })\n",
    "report_df = pd.DataFrame(summary).sort_values('PatientID')\n",
    "print(report_df)\n",
    "\n",
    "# ðŸ“ˆ Calibration Curve\n",
    "all_probs, all_labels = [], []\n",
    "with torch.no_grad():\n",
    "    for x_seq, aux_seq, y, _ in test_dataset:\n",
    "        x_seq, aux_seq = x_seq.unsqueeze(0).to('cuda'), aux_seq.unsqueeze(0).to('cuda')\n",
    "        prob = torch.sigmoid(model(x_seq, aux_seq)).cpu().item()\n",
    "        all_probs.append(prob)\n",
    "        all_labels.append(y.item())\n",
    "\n",
    "prob_true, prob_pred = calibration_curve(all_labels, all_probs, n_bins=10)\n",
    "plt.plot(prob_pred, prob_true, marker='o', label='Calibration')\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', label='Perfect')\n",
    "plt.xlabel('Predicted Probability')\n",
    "plt.ylabel('True Probability')\n",
    "plt.title('Calibration Curve')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ed07c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_on",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
