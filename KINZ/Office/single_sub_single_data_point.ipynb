{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cabee7e3",
   "metadata": {},
   "source": [
    "# OLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d4c2d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, No valid training samples found. Skipping epoch.\n",
      "Epoch 2, No valid training samples found. Skipping epoch.\n",
      "Epoch 3, No valid training samples found. Skipping epoch.\n",
      "Epoch 4, No valid training samples found. Skipping epoch.\n",
      "Epoch 5, No valid training samples found. Skipping epoch.\n",
      "Epoch 6, No valid training samples found. Skipping epoch.\n",
      "Epoch 7, No valid training samples found. Skipping epoch.\n",
      "Epoch 8, No valid training samples found. Skipping epoch.\n",
      "Epoch 9, No valid training samples found. Skipping epoch.\n",
      "Epoch 10, No valid training samples found. Skipping epoch.\n",
      "Epoch 11, No valid training samples found. Skipping epoch.\n",
      "Epoch 12, No valid training samples found. Skipping epoch.\n",
      "Epoch 13, No valid training samples found. Skipping epoch.\n",
      "Epoch 14, No valid training samples found. Skipping epoch.\n",
      "Epoch 15, No valid training samples found. Skipping epoch.\n",
      "Epoch 16, No valid training samples found. Skipping epoch.\n",
      "Epoch 17, No valid training samples found. Skipping epoch.\n",
      "Epoch 18, No valid training samples found. Skipping epoch.\n",
      "Epoch 19, No valid training samples found. Skipping epoch.\n",
      "Epoch 20, No valid training samples found. Skipping epoch.\n",
      "Epoch 21, No valid training samples found. Skipping epoch.\n",
      "Epoch 22, No valid training samples found. Skipping epoch.\n",
      "Epoch 23, No valid training samples found. Skipping epoch.\n",
      "Epoch 24, No valid training samples found. Skipping epoch.\n",
      "Epoch 25, No valid training samples found. Skipping epoch.\n",
      "Epoch 26, No valid training samples found. Skipping epoch.\n",
      "Epoch 27, No valid training samples found. Skipping epoch.\n",
      "Epoch 28, No valid training samples found. Skipping epoch.\n",
      "Epoch 29, No valid training samples found. Skipping epoch.\n",
      "Epoch 30, No valid training samples found. Skipping epoch.\n",
      "Epoch 31, No valid training samples found. Skipping epoch.\n",
      "Epoch 32, No valid training samples found. Skipping epoch.\n",
      "Epoch 33, No valid training samples found. Skipping epoch.\n",
      "Epoch 34, No valid training samples found. Skipping epoch.\n",
      "Epoch 35, No valid training samples found. Skipping epoch.\n",
      "Epoch 36, No valid training samples found. Skipping epoch.\n",
      "Epoch 37, No valid training samples found. Skipping epoch.\n",
      "Epoch 38, No valid training samples found. Skipping epoch.\n",
      "Epoch 39, No valid training samples found. Skipping epoch.\n",
      "Epoch 40, No valid training samples found. Skipping epoch.\n",
      "Epoch 41, No valid training samples found. Skipping epoch.\n",
      "Epoch 42, No valid training samples found. Skipping epoch.\n",
      "Epoch 43, No valid training samples found. Skipping epoch.\n",
      "Epoch 44, No valid training samples found. Skipping epoch.\n",
      "Epoch 45, No valid training samples found. Skipping epoch.\n",
      "Epoch 46, No valid training samples found. Skipping epoch.\n",
      "Epoch 47, No valid training samples found. Skipping epoch.\n",
      "Epoch 48, No valid training samples found. Skipping epoch.\n",
      "Epoch 49, No valid training samples found. Skipping epoch.\n",
      "Epoch 50, No valid training samples found. Skipping epoch.\n",
      "Epoch 51, No valid training samples found. Skipping epoch.\n",
      "Epoch 52, No valid training samples found. Skipping epoch.\n",
      "Epoch 53, No valid training samples found. Skipping epoch.\n",
      "Epoch 54, No valid training samples found. Skipping epoch.\n",
      "Epoch 55, No valid training samples found. Skipping epoch.\n",
      "Epoch 56, No valid training samples found. Skipping epoch.\n",
      "Epoch 57, No valid training samples found. Skipping epoch.\n",
      "Epoch 58, No valid training samples found. Skipping epoch.\n",
      "Epoch 59, No valid training samples found. Skipping epoch.\n",
      "Epoch 60, No valid training samples found. Skipping epoch.\n",
      "Epoch 61, No valid training samples found. Skipping epoch.\n",
      "Epoch 62, No valid training samples found. Skipping epoch.\n",
      "Epoch 63, No valid training samples found. Skipping epoch.\n",
      "Epoch 64, No valid training samples found. Skipping epoch.\n",
      "Epoch 65, No valid training samples found. Skipping epoch.\n",
      "Epoch 66, No valid training samples found. Skipping epoch.\n",
      "Epoch 67, No valid training samples found. Skipping epoch.\n",
      "Epoch 68, No valid training samples found. Skipping epoch.\n",
      "Epoch 69, No valid training samples found. Skipping epoch.\n",
      "Epoch 70, No valid training samples found. Skipping epoch.\n",
      "Epoch 71, No valid training samples found. Skipping epoch.\n",
      "Epoch 72, No valid training samples found. Skipping epoch.\n",
      "Epoch 73, No valid training samples found. Skipping epoch.\n",
      "Epoch 74, No valid training samples found. Skipping epoch.\n",
      "Epoch 75, No valid training samples found. Skipping epoch.\n",
      "Epoch 76, No valid training samples found. Skipping epoch.\n",
      "Epoch 77, No valid training samples found. Skipping epoch.\n",
      "Epoch 78, No valid training samples found. Skipping epoch.\n",
      "Epoch 79, No valid training samples found. Skipping epoch.\n",
      "Epoch 80, No valid training samples found. Skipping epoch.\n",
      "Epoch 81, No valid training samples found. Skipping epoch.\n",
      "Epoch 82, No valid training samples found. Skipping epoch.\n",
      "Epoch 83, No valid training samples found. Skipping epoch.\n",
      "Epoch 84, No valid training samples found. Skipping epoch.\n",
      "Epoch 85, No valid training samples found. Skipping epoch.\n",
      "Epoch 86, No valid training samples found. Skipping epoch.\n",
      "Epoch 87, No valid training samples found. Skipping epoch.\n",
      "Epoch 88, No valid training samples found. Skipping epoch.\n",
      "Epoch 89, No valid training samples found. Skipping epoch.\n",
      "Epoch 90, No valid training samples found. Skipping epoch.\n",
      "Epoch 91, No valid training samples found. Skipping epoch.\n",
      "Epoch 92, No valid training samples found. Skipping epoch.\n",
      "Epoch 93, No valid training samples found. Skipping epoch.\n",
      "Epoch 94, No valid training samples found. Skipping epoch.\n",
      "Epoch 95, No valid training samples found. Skipping epoch.\n",
      "Epoch 96, No valid training samples found. Skipping epoch.\n",
      "Epoch 97, No valid training samples found. Skipping epoch.\n",
      "Epoch 98, No valid training samples found. Skipping epoch.\n",
      "Epoch 99, No valid training samples found. Skipping epoch.\n",
      "Epoch 100, No valid training samples found. Skipping epoch.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'all_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 203\u001b[0m\n\u001b[0;32m    199\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEarly stopping triggered.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    200\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 203\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(\u001b[43mall_labels\u001b[49m, all_preds)\n\u001b[0;32m    204\u001b[0m f1 \u001b[38;5;241m=\u001b[39m f1_score(all_labels, all_preds)\n\u001b[0;32m    205\u001b[0m recall \u001b[38;5;241m=\u001b[39m recall_score(all_labels, all_preds)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'all_labels' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data import Dataset, Data\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, roc_auc_score, confusion_matrix\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define joints and edges\n",
    "joints = [\n",
    "    'PELVIS', 'SPINE_NAVAL', 'SPINE_CHEST', 'NECK', 'CLAVICLE_LEFT', 'SHOULDER_LEFT',\n",
    "    'ELBOW_LEFT', 'WRIST_LEFT', 'HAND_LEFT', 'HANDTIP_LEFT', 'THUMB_LEFT',\n",
    "    'CLAVICLE_RIGHT', 'SHOULDER_RIGHT', 'ELBOW_RIGHT', 'WRIST_RIGHT', 'HAND_RIGHT',\n",
    "    'HANDTIP_RIGHT', 'THUMB_RIGHT', 'HIP_LEFT', 'KNEE_LEFT', 'ANKLE_LEFT',\n",
    "    'FOOT_LEFT', 'HIP_RIGHT', 'KNEE_RIGHT', 'ANKLE_RIGHT', 'FOOT_RIGHT',\n",
    "    'HEAD', 'NOSE', 'EYE_LEFT', 'EAR_LEFT', 'EYE_RIGHT', 'EAR_RIGHT'\n",
    "]\n",
    "\n",
    "edges = [\n",
    "    ('PELVIS', 'SPINE_NAVAL'), ('SPINE_NAVAL', 'SPINE_CHEST'), ('SPINE_CHEST', 'NECK'),\n",
    "    ('NECK', 'HEAD'), ('SPINE_CHEST', 'CLAVICLE_LEFT'), ('CLAVICLE_LEFT', 'SHOULDER_LEFT'),\n",
    "    ('SHOULDER_LEFT', 'ELBOW_LEFT'), ('ELBOW_LEFT', 'WRIST_LEFT'), ('WRIST_LEFT', 'HAND_LEFT'),\n",
    "    ('HAND_LEFT', 'HANDTIP_LEFT'), ('WRIST_LEFT', 'THUMB_LEFT'), ('SPINE_CHEST', 'CLAVICLE_RIGHT'),\n",
    "    ('CLAVICLE_RIGHT', 'SHOULDER_RIGHT'), ('SHOULDER_RIGHT', 'ELBOW_RIGHT'), ('ELBOW_RIGHT', 'WRIST_RIGHT'),\n",
    "    ('WRIST_RIGHT', 'HAND_RIGHT'), ('HAND_RIGHT', 'HANDTIP_RIGHT'), ('WRIST_RIGHT', 'THUMB_RIGHT'),\n",
    "    ('PELVIS', 'HIP_LEFT'), ('HIP_LEFT', 'KNEE_LEFT'), ('KNEE_LEFT', 'ANKLE_LEFT'),\n",
    "    ('ANKLE_LEFT', 'FOOT_LEFT'), ('PELVIS', 'HIP_RIGHT'), ('HIP_RIGHT', 'KNEE_RIGHT'),\n",
    "    ('KNEE_RIGHT', 'ANKLE_RIGHT'), ('ANKLE_RIGHT', 'FOOT_RIGHT'),\n",
    "    ('HEAD', 'NOSE'), ('HEAD', 'EYE_LEFT'), ('HEAD', 'EYE_RIGHT'), ('HEAD', 'EAR_LEFT'), ('HEAD', 'EAR_RIGHT')\n",
    "]\n",
    "\n",
    "joint_to_idx = {joint: idx for idx, joint in enumerate(joints)}\n",
    "edge_index = torch.tensor(\n",
    "    [[joint_to_idx[src], joint_to_idx[dst]] for src, dst in edges] +\n",
    "    [[joint_to_idx[dst], joint_to_idx[src]] for src, dst in edges],\n",
    "    dtype=torch.long\n",
    ").t()\n",
    "\n",
    "class SubjectSequenceDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.samples = []\n",
    "        for _, patient_df in dataframe.groupby('patientID'):\n",
    "            label = patient_df['QoR_class'].iloc[0]\n",
    "            frames = []\n",
    "            for _, row in patient_df.iterrows():\n",
    "                node_features = [\n",
    "                    [row[f'{joint}_X'], row[f'{joint}_Y'], row[f'{joint}_Z'], row['t_uniform']]\n",
    "                    for joint in joints\n",
    "                ]\n",
    "                x = torch.tensor(node_features, dtype=torch.float)\n",
    "                graph = Data(x=x, edge_index=edge_index)\n",
    "                frames.append(graph)\n",
    "            self.samples.append((frames, torch.tensor(label, dtype=torch.float)))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.samples[idx]\n",
    "\n",
    "def collate_subjects(batch):\n",
    "    sequences, labels = zip(*batch)\n",
    "    return list(sequences), torch.tensor(labels, dtype=torch.float)\n",
    "\n",
    "class TemporalGCNModel(nn.Module):\n",
    "    def __init__(self, in_channels, gcn_hidden, lstm_hidden):\n",
    "        super().__init__()\n",
    "        self.gcn1 = GCNConv(in_channels, gcn_hidden)\n",
    "        self.gcn2 = GCNConv(gcn_hidden, gcn_hidden)\n",
    "        self.lstm = nn.LSTM(gcn_hidden, lstm_hidden, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(lstm_hidden * 2, 1)\n",
    "\n",
    "    def forward(self, sequences):\n",
    "        device = next(self.parameters()).device\n",
    "        batch_embeddings = []\n",
    "\n",
    "        for subject in sequences:\n",
    "            frame_embeddings = []\n",
    "            for graph in subject:\n",
    "                if isinstance(graph, (tuple, list)):\n",
    "                    graph = graph[0]\n",
    "                if not isinstance(graph, Data):\n",
    "                    continue\n",
    "                if not hasattr(graph, 'x') or graph.x is None:\n",
    "                    continue\n",
    "                x = F.relu(self.gcn1(graph.x.to(device), graph.edge_index.to(device)))\n",
    "                x = F.relu(self.gcn2(x, graph.edge_index.to(device)))\n",
    "                pooled = global_mean_pool(x, torch.zeros(x.size(0), dtype=torch.long).to(device))\n",
    "                frame_embeddings.append(pooled)\n",
    "            \n",
    "            if len(frame_embeddings) > 0:\n",
    "                sequence_tensor = torch.stack(frame_embeddings)\n",
    "                batch_embeddings.append(sequence_tensor)\n",
    "\n",
    "        if len(batch_embeddings) == 0:\n",
    "            return torch.empty((0,), device=device)  # Prevent model crash\n",
    "\n",
    "        packed = torch.nn.utils.rnn.pad_sequence(batch_embeddings, batch_first=True)\n",
    "        _, (h_n, _) = self.lstm(packed)\n",
    "        h_final = torch.cat((h_n[-2], h_n[-1]), dim=-1)\n",
    "        out = self.fc(h_final)\n",
    "        return torch.sigmoid(out).squeeze()\n",
    "\n",
    "\n",
    "csv_path = r'D:\\Data\\NYC\\KINZ\\Final_data_Balanced.csv'\n",
    "df = pd.read_csv(csv_path)\n",
    "df = df[df['walking_speed'] == \"Fast\"]\n",
    "\n",
    "train_ids, test_ids = train_test_split(df['patientID'].unique(), test_size=0.2, random_state=42)\n",
    "train_df = df[df['patientID'].isin(train_ids)]\n",
    "test_df = df[df['patientID'].isin(test_ids)]\n",
    "\n",
    "train_dataset = SubjectSequenceDataset(train_df)\n",
    "test_dataset = SubjectSequenceDataset(test_df)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=collate_subjects)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False, collate_fn=collate_subjects)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = TemporalGCNModel(in_channels=4, gcn_hidden=64, lstm_hidden=128).to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=3, min_delta=0.01):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = float('inf')\n",
    "        self.best_model = None\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        if val_loss < self.best_loss - self.min_delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "            self.best_model = model.state_dict()\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                model.load_state_dict(self.best_model)\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "early_stopping = EarlyStopping()\n",
    "\n",
    "for epoch in range(1, 101):\n",
    "    model.train()\n",
    "    total_loss, correct, total = 0, 0, 0\n",
    "    for sequences, labels in train_loader:\n",
    "        out = model(sequences)\n",
    "        if out.numel() == 0:  # Skip invalid batch\n",
    "            continue\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(out.to(device), labels.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * len(labels)\n",
    "        preds = (out.detach().cpu() >= 0.5).float()\n",
    "        correct += (preds == labels.cpu()).sum().item()\n",
    "        total += len(labels)\n",
    "\n",
    "    if total == 0:\n",
    "        print(f\"Epoch {epoch}, No valid training samples found. Skipping epoch.\")\n",
    "        continue\n",
    "\n",
    "    train_acc = correct / total\n",
    "    print(f\"Epoch {epoch}, Train Loss: {total_loss/total:.4f}, Acc: {train_acc:.4f}\")\n",
    "\n",
    "    model.eval()\n",
    "    total_loss, correct, total = 0, 0, 0\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for sequences, labels in test_loader:\n",
    "            out = model(sequences)\n",
    "            if out.numel() == 0:\n",
    "                continue\n",
    "            loss = criterion(out.to(device), labels.to(device))\n",
    "            total_loss += loss.item() * len(labels)\n",
    "            preds = (out.detach().cpu() >= 0.5).float()\n",
    "            correct += (preds == labels.cpu()).sum().item()\n",
    "            total += len(labels)\n",
    "            all_preds.extend(preds.numpy())\n",
    "            all_labels.extend(labels.numpy())\n",
    "\n",
    "    if total == 0:\n",
    "        print(f\"Epoch {epoch}, No valid validation samples found. Skipping epoch.\")\n",
    "        continue\n",
    "\n",
    "    val_loss = total_loss / total\n",
    "    val_acc = correct / total\n",
    "    print(f\"Epoch {epoch}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    if early_stopping(val_loss, model):\n",
    "        print(\"Early stopping triggered.\")\n",
    "        break\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "f1 = f1_score(all_labels, all_preds)\n",
    "recall = recall_score(all_labels, all_preds)\n",
    "precision = precision_score(all_labels, all_preds)\n",
    "roc_auc = roc_auc_score(all_labels, all_preds)\n",
    "tn, fp, fn, tp = confusion_matrix(all_labels, all_preds).ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "print(f'Final Accuracy: {accuracy:.4f}, F1: {f1:.4f}, Recall: {recall:.4f}, Precision: {precision:.4f}, Specificity: {specificity:.4f}, AUC: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdce3724",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d659fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_on",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
